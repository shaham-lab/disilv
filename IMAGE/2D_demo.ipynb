{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "__N11jFvZ7xX",
   "metadata": {
    "id": "__N11jFvZ7xX"
   },
   "source": [
    "# ICA 2D Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ibsWs0scaE6W",
   "metadata": {
    "id": "ibsWs0scaE6W"
   },
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8701403f",
   "metadata": {
    "id": "8701403f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050EmX3KaGy5",
   "metadata": {
    "id": "050EmX3KaGy5"
   },
   "source": [
    "# Input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a1da44",
   "metadata": {
    "id": "70a1da44"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--batch_size', type=int, default=128,  help='Batch size (default=128)')\n",
    "parser.add_argument('--hidden_dim', type=int, default=64,  help='Hidden layer size')\n",
    "parser.add_argument('--beta', type=float, default=5e-2,  help='independence loss coefficient')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,  help='learning_rate (default=1e-3)')\n",
    "parser.add_argument(\"--min_lr\",  type=float,  default=1e-5,  help=\"Minimal learning rate\")\n",
    "parser.add_argument(\"--decay_step_size\",  type=int,  default=100,  help=\"LR decay step size\")\n",
    "parser.add_argument(\"--lr_decay_factor\",  type=float,  default=0.1,  help=\"LR decay factor\")\n",
    "parser.add_argument(\"--drop_prob\",  type=float,  default=.0,  help=\"Dropout probability\")\n",
    "parser.add_argument(\"--weight_decay\",  type=float,  default=1e-2,  help=\"l_2 weight penalty\")\n",
    "parser.add_argument(\"--n_epochs\",  type=int,  default=1000,  help=\"Number of epochs without improvement before stopping\")\n",
    "parser.add_argument(\"--mixing\",  type=str,  default='nonlinear',  help=\"linear | nonlinear\")\n",
    "\n",
    "FLAGS = parser.parse_args(args=[])\n",
    "\n",
    "if FLAGS.mixing == 'linear':\n",
    "    ACTIVATION = nn.Identity()\n",
    "else:\n",
    "    ACTIVATION = nn.Softplus()\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q0g71rIFaYlv",
   "metadata": {
    "id": "Q0g71rIFaYlv"
   },
   "source": [
    "# Datasets\n",
    "Latent data is generated from uniform distribution on the unit square. We observe the data via two views, \n",
    "where each view is obtained by a matrix multiplication of the latent coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e51b8bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "5e51b8bb",
    "outputId": "b0f0a30d-2896-4b58-ce11-163f635effea"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 20000\n",
    "# create latent data\n",
    "U = np.random.rand(n, 2) * 2 - 1\n",
    "cond = U[:, 0]\n",
    "target = U[:, 1]\n",
    "\n",
    "# mixing matrix\n",
    "A = np.random.rand(2, 2) * 2 - 1 + np.identity(2) * 1\n",
    "\n",
    "# observed data\n",
    "X = np.matmul(U,A)\n",
    "X = ACTIVATION(torch.tensor(X)).numpy()\n",
    "\n",
    "y = np.expand_dims(cond, 1)\n",
    "\n",
    "# Standardize samples\n",
    "scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].plot(cond, target, 'o', color='blue', markersize=.1)\n",
    "axs[0].set_title('Latent data', size=12)\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=6)\n",
    "axs[1].plot(X[:, 0], X[:, 1], 'o', color='red', markersize=.1)\n",
    "axs[1].set_title('Observed data', size=12)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.15)\n",
    "train_x, val_x , train_y, val_y = train_test_split(train_x, \n",
    "                                                   train_y, \n",
    "                                                   test_size=0.1)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x).float(), torch.from_numpy(train_y).float())\n",
    "val_data = TensorDataset(torch.from_numpy(val_x).float(), torch.from_numpy(val_y).float())\n",
    "test_data = TensorDataset(torch.from_numpy(test_x).float(), torch.from_numpy(test_y).float())\n",
    "        \n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=FLAGS.batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=FLAGS.batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=FLAGS.batch_size)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wQi9-pmfajaY",
   "metadata": {
    "id": "wQi9-pmfajaY"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfd9f25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cfd9f25",
    "outputId": "14f51c30-4ebf-423c-9b01-b6ec7ad24709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ind_discriminator(\n",
       "  (activation): LeakyReLU(negative_slope=0.01)\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=16, bias=False)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):   \n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hidden_dim, \n",
    "                 drop_prob=0.5,\n",
    "                 norm_layer=nn.BatchNorm1d,\n",
    "                 activation=ACTIVATION):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = 64\n",
    "        self.drop_prob = drop_prob\n",
    "        self.norm_layer = norm_layer\n",
    "        self.activation = activation\n",
    "        \n",
    "        use_bias = norm_layer != nn.BatchNorm1d\n",
    "        \n",
    "         # Layers\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(self.drop_prob)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(self.drop_prob)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(self.drop_prob)\n",
    "        )\n",
    "        \n",
    "        self.code = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 1),\n",
    "            #self.norm_layer(1),\n",
    "        ) \n",
    "               \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Standard forward\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = x + self.layer2(x)\n",
    "        x = x + self.layer3(x)\n",
    "        code = self.code(x)\n",
    "        return code\n",
    "        \n",
    "class Decoder(nn.Module):   \n",
    "    def __init__(self, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 drop_prob=0.5,\n",
    "                 norm_layer=nn.BatchNorm1d,\n",
    "                 activation=ACTIVATION,\n",
    "                 label_embedding_dim=32):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = 64\n",
    "        self.drop_prob = drop_prob\n",
    "        self.norm_layer = norm_layer\n",
    "        self.activation = activation\n",
    "        use_bias = norm_layer != nn.BatchNorm1d\n",
    "        \n",
    "         # Layers\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(1 + 1, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(self.drop_prob)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(self.drop_prob)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(self.drop_prob)\n",
    "        )\n",
    "        \n",
    "        self.recon_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "            self.activation\n",
    "        )    \n",
    "                \n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Concats bio and batch codes, and does forward propagation to obtain recon\n",
    "        \"\"\"\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.layer1(x)\n",
    "        x = x + self.layer2(x)\n",
    "        x = x + self.layer3(x)\n",
    "        recon = self.recon_layer(x)\n",
    "        return recon\n",
    "\n",
    "class Ind_discriminator(nn.Module):   \n",
    "    def __init__(self, \n",
    "                 hidden_dim, \n",
    "                 drop_prob=0.5,\n",
    "                 norm_layer=nn.BatchNorm1d,\n",
    "                 activation=nn.LeakyReLU()):\n",
    "        \n",
    "        super(Ind_discriminator, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.drop_prob = drop_prob\n",
    "        self.norm_layer = norm_layer\n",
    "        self.activation = activation\n",
    "        use_bias = norm_layer != nn.BatchNorm1d\n",
    "        \n",
    "         # Layers\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(1, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=use_bias),\n",
    "            self.norm_layer(self.hidden_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Concats bio and batch codes, and does forward propagation to obtain recon\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = x + self.layer2(x)\n",
    "        x = x + self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        mx = torch.mean(x)\n",
    "        my = torch.mean(y)\n",
    "        \n",
    "        xc = x - mx\n",
    "        yc = y - my\n",
    "        \n",
    "        r_square =  (xc * yc).sum() ** 2 / ((xc ** 2).sum() * (yc ** 2).sum())\n",
    "        return r_square\n",
    "     \n",
    "encoder = Encoder(input_dim, \n",
    "                  hidden_dim=FLAGS.hidden_dim, \n",
    "                  drop_prob=FLAGS.drop_prob)\n",
    "\n",
    "decoder = Decoder(hidden_dim=FLAGS.hidden_dim,\n",
    "                  output_dim=input_dim,\n",
    "                  drop_prob=FLAGS.drop_prob)\n",
    "\n",
    "ind_discriminator = Ind_discriminator(hidden_dim=16,\n",
    "                                      drop_prob=FLAGS.drop_prob)\n",
    "       \n",
    "encoder.to(device=device)\n",
    "decoder.to(device=device)\n",
    "ind_discriminator.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71oceLfapNu",
   "metadata": {
    "id": "d71oceLfapNu"
   },
   "source": [
    "# Loss criterions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf2f963",
   "metadata": {
    "id": "edf2f963"
   },
   "outputs": [],
   "source": [
    "recon_criterion = nn.L1Loss()\n",
    "\n",
    "def ind_criterion (r_square, should_be_dependent=True):\n",
    "    if should_be_dependent:\n",
    "        return -r_square\n",
    "    else:\n",
    "        return r_square\n",
    "    \n",
    "\n",
    "def compute_ind_disc_R1_loss(model, x, y):\n",
    "    x = x.detach().clone()\n",
    "    x.requires_grad_()\n",
    "    pred_real = model(x, y).sum()\n",
    "    grad_real, = torch.autograd.grad(\n",
    "        outputs=pred_real,\n",
    "        inputs=[x],\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "    grad_real2 = grad_real.pow(2)\n",
    "    dims = list(range(1, grad_real2.ndim))\n",
    "    grad_penalty = grad_real2.sum(dims) * 0.5\n",
    "\n",
    "    return grad_penalty.sum()     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l58PM73FatWn",
   "metadata": {
    "id": "l58PM73FatWn"
   },
   "source": [
    " # Optimizers and Learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c7ada5",
   "metadata": {
    "id": "e6c7ada5"
   },
   "outputs": [],
   "source": [
    "def lambda_rule(epoch) -> float:\n",
    "    \"\"\" stepwise learning rate calculator \"\"\"\n",
    "    exponent = int(np.floor((epoch + 1) / FLAGS.decay_step_size))\n",
    "    return np.power(FLAGS.lr_decay_factor, exponent)\n",
    "\n",
    "def update_lr(optim, scheduler):\n",
    "        \"\"\" Learning rate updater \"\"\"\n",
    "        \n",
    "        scheduler.step()\n",
    "        lr = optim.param_groups[0]['lr']\n",
    "        if lr < FLAGS.min_lr:\n",
    "            optim.param_groups[0]['lr'] = FLAGS.min_lr\n",
    "            lr = optim.param_groups[0]['lr']\n",
    "        print('Learning rate = %.7f' % lr) \n",
    "\n",
    "ae_optim = torch.optim.Adam(list(encoder.parameters()) +\\\n",
    "                            list(decoder.parameters()),\n",
    "                            betas=(0.0, 0.999),\n",
    "                            lr=FLAGS.lr, \n",
    "                            weight_decay=FLAGS.weight_decay)\n",
    "\n",
    "ind_disc_optim = torch.optim.Adam(ind_discriminator.parameters(), \n",
    "                              lr=FLAGS.lr,\n",
    "                              betas=(0.0, 0.999),     \n",
    "                              weight_decay=FLAGS.weight_decay) \n",
    "\n",
    "ae_sched = lr_scheduler.LambdaLR(ae_optim, \n",
    "                                 lr_lambda=lambda_rule) \n",
    "\n",
    "disc_sched = lr_scheduler.LambdaLR(ind_disc_optim, \n",
    "                                   lr_lambda=lambda_rule)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cw_qn5H-ayCA",
   "metadata": {
    "id": "Cw_qn5H-ayCA"
   },
   "source": [
    "# Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be74880",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0be74880",
    "outputId": "088b45fc-f990-4b0b-e816-89776dd4fb04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_x.shape:  torch.Size([128, 2])\n",
      "batch_y.shape:  torch.Size([128, 1])\n",
      "torch.float32\n",
      "torch.float32\n",
      "discriminator_loss:  tensor(-0.0639, grad_fn=<NegBackward0>)\n",
      "recon.min():  tensor(0.0495, grad_fn=<MinBackward1>)\n",
      "recon.max():  tensor(1.2463, grad_fn=<MaxBackward1>)\n",
      "batch_x.min():  tensor(0.2527)\n",
      "batch_x.max():  tensor(1.5598)\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "    break\n",
    "            \n",
    "batch_x = batch_x.float().to(device=device)\n",
    "batch_y = batch_y.to(device=device)\n",
    "\n",
    "print('batch_x.shape: ', batch_x.shape)\n",
    "print('batch_y.shape: ', batch_y.shape)\n",
    "            \n",
    "# train discriminator\n",
    "code = encoder(batch_x)\n",
    "print(code.dtype)\n",
    "\n",
    "abs_correl = ind_discriminator(code, batch_y) \n",
    "indep_loss = abs_correl\n",
    "discriminator_loss = - abs_correl\n",
    "print(abs_correl.dtype)\n",
    "\n",
    "print('discriminator_loss: ', discriminator_loss)\n",
    "recon = decoder(code, batch_y)\n",
    "print('recon.min(): ', recon.min())\n",
    "print('recon.max(): ', recon.max())\n",
    "print('batch_x.min(): ', batch_x.min())\n",
    "print('batch_x.max(): ', batch_x.max())\n",
    "recon_loss = recon_criterion(recon, batch_x)   \n",
    "discriminator_loss.backward()\n",
    "\n",
    "print('ok')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sE9Dm_mxa3z9",
   "metadata": {
    "id": "sE9Dm_mxa3z9"
   },
   "source": [
    "# Training and test procedures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6e6353",
   "metadata": {
    "id": "0c6e6353"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    for epoch in range(FLAGS.n_epochs):\n",
    "        \n",
    "        encoder.train(True) \n",
    "        decoder.train(True) \n",
    "        ind_discriminator.train(True)    \n",
    "        \n",
    "        recon_losses = []\n",
    "        indep_losses = []\n",
    "        \n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            \n",
    "            batch_x = batch_x.float().to(device=device)\n",
    "            batch_y = batch_y.to(device=device)\n",
    "            \n",
    "            # train discriminator\n",
    "            ind_discriminator.zero_grad()\n",
    "            code = encoder(batch_x).detach()\n",
    "            r_square = ind_discriminator(code, batch_y) \n",
    "            discriminator_loss = ind_criterion(r_square, should_be_dependent=True)\n",
    "            discriminator_loss.backward()\n",
    "            ind_disc_optim.step()\n",
    "            \n",
    "            if step % 8 == 0:\n",
    "                # r1 losses \n",
    "                ind_discriminator.zero_grad()\n",
    "                ind_disc_r1_loss = compute_ind_disc_R1_loss(ind_discriminator, code, batch_y)\n",
    "                ind_disc_r1_loss.backward()\n",
    "                ind_disc_optim.step()\n",
    "            \n",
    "            if step % 5 == 0:\n",
    "                # train AE\n",
    "                encoder.zero_grad()\n",
    "                decoder.zero_grad()\n",
    "                \n",
    "                code = encoder(batch_x)\n",
    "                recon = decoder(code, batch_y)\n",
    "                recon_loss = recon_criterion(recon, batch_x)   \n",
    "                r_square = ind_discriminator(code, batch_y) \n",
    "                indep_loss = ind_criterion(r_square, should_be_dependent=False)\n",
    "\n",
    "                \n",
    "                ae_loss = recon_loss + FLAGS.beta * indep_loss\n",
    "                ae_loss.backward()\n",
    "                ae_optim.step()\n",
    "                \n",
    "                recon_losses.append(recon_loss.item())\n",
    "                indep_losses.append(indep_loss.item())\n",
    "                \n",
    "                if step % 10 == 0:\n",
    "                    print('Epoch: {}\\{}, Step: {}'.format(epoch, \n",
    "                                                          FLAGS.n_epochs,\n",
    "                                                          step))\n",
    "                    print('Recon_loss: {:.3f}, indep loss:  {:.3f}'.format(np.mean(recon_losses),\n",
    "                                                                           np.mean(indep_losses)))\n",
    "                    \n",
    "                    print('Learning rate = %.7f' % ae_optim.param_groups[0]['lr']) \n",
    "\n",
    "        print('End or epoch: {}\\{}'.format(epoch, FLAGS.n_epochs))\n",
    "        print('Recon_loss: {:.3f}, indep loss:  {:.3f}'.format(np.mean(recon_losses),\n",
    "                                                               np.mean(indep_losses)))\n",
    "        \n",
    "        update_lr(ae_optim, ae_sched)\n",
    "        update_lr(ind_disc_optim, disc_sched)\n",
    "        \n",
    "    print('Finished training ')\n",
    "    \n",
    "def test():    \n",
    "    \n",
    "    print('Running test')\n",
    "    \n",
    "    encoder.train(False) \n",
    "    decoder.train(False) \n",
    "    ind_discriminator.train(False) \n",
    "    \n",
    "    test_recon_losses = []\n",
    "    test_indep_losses = []\n",
    "    \n",
    "    for (batch_x, batch_y) in test_loader:\n",
    "        batch_x = batch_x.float().to(device=device)\n",
    "        batch_y = batch_y.to(device=device)\n",
    "              \n",
    "        code = encoder(batch_x)\n",
    "        recon = decoder(code, batch_y)\n",
    "        recon_loss = recon_criterion(recon, batch_x) \n",
    "        r_square = ind_discriminator(code, batch_y) \n",
    "        indep_loss = ind_criterion(r_square, should_be_dependent=False)\n",
    "            \n",
    "        test_recon_losses.append(recon_loss.item())\n",
    "        test_indep_losses.append(indep_loss.item())\n",
    "         \n",
    "    test_recon_loss = np.mean(test_recon_losses)\n",
    "    test_indep_loss = np.mean(test_indep_losses)\n",
    "        \n",
    "    test_loss = test_recon_loss +\\\n",
    "            FLAGS.beta * test_indep_loss   \n",
    "       \n",
    "    print('Test results: ')\n",
    "    print('Recon_loss: {:.3f}, indep loss:  {:.3f}'.format(test_recon_loss,\n",
    "                                                           test_indep_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-_Olf31qa8SW",
   "metadata": {
    "id": "-_Olf31qa8SW"
   },
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3fdf59",
   "metadata": {
    "id": "7a3fdf59"
   },
   "outputs": [],
   "source": [
    "def analyze_data():\n",
    "\n",
    "    encoder.train(False) \n",
    "    decoder.train(False) \n",
    "    ind_discriminator.train(False) \n",
    "    \n",
    "    \n",
    "    code = []\n",
    "    recon = []\n",
    "    \n",
    "    \n",
    "    for (batch_x, batch_y) in test_loader:\n",
    "        batch_x = batch_x.float().to(device=device)              \n",
    "        code_ = encoder(batch_x)\n",
    "        recon_ = decoder(code_, batch_y)\n",
    "        code.append(code_.detach().cpu().numpy())\n",
    "        recon.append(recon_.detach().cpu().numpy())\n",
    "    \n",
    "    code = np.concatenate(code)\n",
    "    recon = np.concatenate(recon)\n",
    "    \n",
    "    print('test_y.shape: ', test_y.shape)\n",
    "    print('code.shape: ', code.shape)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].plot(train_x[:, 0], train_x[:, 1], 'o', color='red', markersize=.1)\n",
    "    axs[0].plot(recon[:, 0], recon[:, 1], 'o', color='blue', markersize=.5)\n",
    "    axs[0].set_title('data (red) and recon (blue)', size=12)\n",
    "    axs[0].tick_params(axis='both', which='major', labelsize=6)\n",
    "    axs[1].plot(test_y, code, 'o', color='blue', markersize=.5)\n",
    "    axs[1].set_title('Code (y) and condition (x)', size=12)\n",
    "    axs[1].tick_params(axis='both', which='major', labelsize=6)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada149f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ada149f9",
    "outputId": "92822892-8916-48c6-ee54-398cb149a539",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\\1000, Step: 0\n",
      "Recon_loss: 0.517, indep loss:  0.081\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 10\n",
      "Recon_loss: 0.503, indep loss:  0.062\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 20\n",
      "Recon_loss: 0.494, indep loss:  0.052\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 30\n",
      "Recon_loss: 0.489, indep loss:  0.039\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 40\n",
      "Recon_loss: 0.479, indep loss:  0.031\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 50\n",
      "Recon_loss: 0.469, indep loss:  0.027\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 60\n",
      "Recon_loss: 0.464, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 70\n",
      "Recon_loss: 0.452, indep loss:  0.028\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 80\n",
      "Recon_loss: 0.442, indep loss:  0.028\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 90\n",
      "Recon_loss: 0.433, indep loss:  0.036\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 100\n",
      "Recon_loss: 0.424, indep loss:  0.049\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 0\\1000, Step: 110\n",
      "Recon_loss: 0.417, indep loss:  0.066\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 0\\1000\n",
      "Recon_loss: 0.413, indep loss:  0.073\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 0\n",
      "Recon_loss: 0.328, indep loss:  0.288\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 10\n",
      "Recon_loss: 0.317, indep loss:  0.303\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 20\n",
      "Recon_loss: 0.316, indep loss:  0.350\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 30\n",
      "Recon_loss: 0.313, indep loss:  0.373\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 40\n",
      "Recon_loss: 0.311, indep loss:  0.390\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 50\n",
      "Recon_loss: 0.313, indep loss:  0.403\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 60\n",
      "Recon_loss: 0.314, indep loss:  0.421\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 70\n",
      "Recon_loss: 0.308, indep loss:  0.442\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 80\n",
      "Recon_loss: 0.306, indep loss:  0.451\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 90\n",
      "Recon_loss: 0.302, indep loss:  0.452\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 100\n",
      "Recon_loss: 0.301, indep loss:  0.464\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 1\\1000, Step: 110\n",
      "Recon_loss: 0.299, indep loss:  0.463\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 1\\1000\n",
      "Recon_loss: 0.297, indep loss:  0.464\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 0\n",
      "Recon_loss: 0.240, indep loss:  0.427\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 10\n",
      "Recon_loss: 0.259, indep loss:  0.451\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 20\n",
      "Recon_loss: 0.261, indep loss:  0.428\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 30\n",
      "Recon_loss: 0.261, indep loss:  0.424\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 40\n",
      "Recon_loss: 0.262, indep loss:  0.421\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 50\n",
      "Recon_loss: 0.258, indep loss:  0.417\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 60\n",
      "Recon_loss: 0.256, indep loss:  0.406\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 70\n",
      "Recon_loss: 0.257, indep loss:  0.399\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 80\n",
      "Recon_loss: 0.255, indep loss:  0.396\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 90\n",
      "Recon_loss: 0.253, indep loss:  0.399\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 100\n",
      "Recon_loss: 0.252, indep loss:  0.398\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 2\\1000, Step: 110\n",
      "Recon_loss: 0.250, indep loss:  0.399\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 2\\1000\n",
      "Recon_loss: 0.250, indep loss:  0.400\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 0\n",
      "Recon_loss: 0.246, indep loss:  0.330\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 10\n",
      "Recon_loss: 0.235, indep loss:  0.356\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 20\n",
      "Recon_loss: 0.232, indep loss:  0.351\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 30\n",
      "Recon_loss: 0.230, indep loss:  0.343\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 40\n",
      "Recon_loss: 0.229, indep loss:  0.343\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 50\n",
      "Recon_loss: 0.226, indep loss:  0.335\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 60\n",
      "Recon_loss: 0.223, indep loss:  0.330\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 70\n",
      "Recon_loss: 0.221, indep loss:  0.335\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 80\n",
      "Recon_loss: 0.219, indep loss:  0.332\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 90\n",
      "Recon_loss: 0.220, indep loss:  0.333\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 100\n",
      "Recon_loss: 0.218, indep loss:  0.335\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 3\\1000, Step: 110\n",
      "Recon_loss: 0.216, indep loss:  0.331\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 3\\1000\n",
      "Recon_loss: 0.216, indep loss:  0.329\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 0\n",
      "Recon_loss: 0.197, indep loss:  0.255\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 10\n",
      "Recon_loss: 0.207, indep loss:  0.267\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 20\n",
      "Recon_loss: 0.203, indep loss:  0.286\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 30\n",
      "Recon_loss: 0.200, indep loss:  0.273\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 40\n",
      "Recon_loss: 0.196, indep loss:  0.271\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 50\n",
      "Recon_loss: 0.190, indep loss:  0.251\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 60\n",
      "Recon_loss: 0.188, indep loss:  0.251\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 70\n",
      "Recon_loss: 0.186, indep loss:  0.243\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 80\n",
      "Recon_loss: 0.185, indep loss:  0.242\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 90\n",
      "Recon_loss: 0.181, indep loss:  0.236\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 100\n",
      "Recon_loss: 0.177, indep loss:  0.228\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 4\\1000, Step: 110\n",
      "Recon_loss: 0.175, indep loss:  0.225\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 4\\1000\n",
      "Recon_loss: 0.175, indep loss:  0.226\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 0\n",
      "Recon_loss: 0.148, indep loss:  0.276\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 10\n",
      "Recon_loss: 0.139, indep loss:  0.290\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 20\n",
      "Recon_loss: 0.142, indep loss:  0.284\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 30\n",
      "Recon_loss: 0.137, indep loss:  0.282\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 40\n",
      "Recon_loss: 0.131, indep loss:  0.291\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 50\n",
      "Recon_loss: 0.129, indep loss:  0.286\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 60\n",
      "Recon_loss: 0.126, indep loss:  0.285\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 70\n",
      "Recon_loss: 0.123, indep loss:  0.282\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 80\n",
      "Recon_loss: 0.120, indep loss:  0.282\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 90\n",
      "Recon_loss: 0.114, indep loss:  0.267\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 100\n",
      "Recon_loss: 0.109, indep loss:  0.246\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 5\\1000, Step: 110\n",
      "Recon_loss: 0.104, indep loss:  0.226\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 5\\1000\n",
      "Recon_loss: 0.101, indep loss:  0.218\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 0\n",
      "Recon_loss: 0.061, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 10\n",
      "Recon_loss: 0.047, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 20\n",
      "Recon_loss: 0.045, indep loss:  0.021\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 30\n",
      "Recon_loss: 0.044, indep loss:  0.028\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 40\n",
      "Recon_loss: 0.041, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 50\n",
      "Recon_loss: 0.042, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 60\n",
      "Recon_loss: 0.039, indep loss:  0.022\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 70\n",
      "Recon_loss: 0.039, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 80\n",
      "Recon_loss: 0.037, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 90\n",
      "Recon_loss: 0.036, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 100\n",
      "Recon_loss: 0.035, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 6\\1000, Step: 110\n",
      "Recon_loss: 0.034, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 6\\1000\n",
      "Recon_loss: 0.034, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 30\n",
      "Recon_loss: 0.034, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 40\n",
      "Recon_loss: 0.033, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 50\n",
      "Recon_loss: 0.034, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 60\n",
      "Recon_loss: 0.036, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 70\n",
      "Recon_loss: 0.037, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 80\n",
      "Recon_loss: 0.035, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 90\n",
      "Recon_loss: 0.035, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 100\n",
      "Recon_loss: 0.035, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 7\\1000, Step: 110\n",
      "Recon_loss: 0.034, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 7\\1000\n",
      "Recon_loss: 0.034, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 0\n",
      "Recon_loss: 0.043, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 20\n",
      "Recon_loss: 0.036, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 30\n",
      "Recon_loss: 0.033, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 40\n",
      "Recon_loss: 0.035, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 50\n",
      "Recon_loss: 0.033, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 60\n",
      "Recon_loss: 0.031, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 70\n",
      "Recon_loss: 0.031, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 80\n",
      "Recon_loss: 0.031, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 90\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 100\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 8\\1000, Step: 110\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 8\\1000\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 20\n",
      "Recon_loss: 0.033, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 30\n",
      "Recon_loss: 0.034, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 40\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 50\n",
      "Recon_loss: 0.038, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 60\n",
      "Recon_loss: 0.036, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 70\n",
      "Recon_loss: 0.034, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 80\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 100\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 9\\1000, Step: 110\n",
      "Recon_loss: 0.031, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 9\\1000\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 10\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 10\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 10\n",
      "Recon_loss: 0.040, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 20\n",
      "Recon_loss: 0.033, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 30\n",
      "Recon_loss: 0.043, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 40\n",
      "Recon_loss: 0.037, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 50\n",
      "Recon_loss: 0.035, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 60\n",
      "Recon_loss: 0.033, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 70\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 80\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 90\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 100\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 11\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 11\\1000\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 12\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 12\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 0\n",
      "Recon_loss: 0.054, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 13\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 13\\1000\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 10\n",
      "Recon_loss: 0.034, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 30\n",
      "Recon_loss: 0.031, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 50\n",
      "Recon_loss: 0.032, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 60\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 80\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 90\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 14\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 14\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 0\n",
      "Recon_loss: 0.043, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 30\n",
      "Recon_loss: 0.035, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 40\n",
      "Recon_loss: 0.032, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 50\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 60\n",
      "Recon_loss: 0.031, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 70\n",
      "Recon_loss: 0.032, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 80\n",
      "Recon_loss: 0.031, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 90\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 100\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 15\\1000, Step: 110\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 15\\1000\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.037\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 16\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 16\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 17\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 17\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 0\n",
      "Recon_loss: 0.042, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 60\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 70\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 80\n",
      "Recon_loss: 0.032, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 90\n",
      "Recon_loss: 0.032, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 100\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 18\\1000, Step: 110\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 18\\1000\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 19\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 19\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 50\n",
      "Recon_loss: 0.031, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 60\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 70\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 80\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 100\n",
      "Recon_loss: 0.029, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 20\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 20\\1000\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\\1000, Step: 40\n",
      "Recon_loss: 0.031, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 50\n",
      "Recon_loss: 0.030, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 60\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 70\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 90\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 21\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 21\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 22\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 22\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 23\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 23\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 80\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 90\n",
      "Recon_loss: 0.029, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 24\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 24\\1000\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 0\n",
      "Recon_loss: 0.056, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 25\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 25\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 26\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 26\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 27\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 27\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 0\n",
      "Recon_loss: 0.041, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 10\n",
      "Recon_loss: 0.037, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 30\n",
      "Recon_loss: 0.033, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 40\n",
      "Recon_loss: 0.034, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28\\1000, Step: 50\n",
      "Recon_loss: 0.035, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 60\n",
      "Recon_loss: 0.033, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 70\n",
      "Recon_loss: 0.031, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 80\n",
      "Recon_loss: 0.030, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 90\n",
      "Recon_loss: 0.029, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 100\n",
      "Recon_loss: 0.029, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 28\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 28\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 0\n",
      "Recon_loss: 0.035, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 29\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 29\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.060\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.033\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.029\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.032\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.029\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.028\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.030\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.027\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.021\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 30\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 30\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.072\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.020\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 30\n",
      "Recon_loss: 0.031, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 80\n",
      "Recon_loss: 0.031, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 90\n",
      "Recon_loss: 0.030, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 100\n",
      "Recon_loss: 0.031, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 31\\1000, Step: 110\n",
      "Recon_loss: 0.031, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 31\\1000\n",
      "Recon_loss: 0.031, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 32\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 32\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 0\n",
      "Recon_loss: 0.058, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 33\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 33\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  0.026\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 50\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 60\n",
      "Recon_loss: 0.033, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 70\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 80\n",
      "Recon_loss: 0.032, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 100\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 34\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 34\\1000\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 10\n",
      "Recon_loss: 0.035, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 35\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 35\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 36\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 36\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 37\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 37\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 30\n",
      "Recon_loss: 0.039, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 40\n",
      "Recon_loss: 0.037, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 50\n",
      "Recon_loss: 0.036, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 60\n",
      "Recon_loss: 0.035, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 70\n",
      "Recon_loss: 0.033, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 80\n",
      "Recon_loss: 0.034, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 100\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 38\\1000, Step: 110\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 38\\1000\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 39\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 39\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.033\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 40\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 40\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 50\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 70\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 80\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 100\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 41\\1000, Step: 110\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 41\\1000\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.020\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42\\1000, Step: 70\n",
      "Recon_loss: 0.029, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 80\n",
      "Recon_loss: 0.030, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 90\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 42\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 42\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 43\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 43\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.024\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.020\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 80\n",
      "Recon_loss: 0.028, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 44\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 44\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 45\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 45\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 46\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 46\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 50\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 70\n",
      "Recon_loss: 0.029, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 80\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 90\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 100\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 47\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 47\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 10\n",
      "Recon_loss: 0.037, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 20\n",
      "Recon_loss: 0.035, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 30\n",
      "Recon_loss: 0.038, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 40\n",
      "Recon_loss: 0.036, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 50\n",
      "Recon_loss: 0.033, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 60\n",
      "Recon_loss: 0.033, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 70\n",
      "Recon_loss: 0.032, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 80\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 90\n",
      "Recon_loss: 0.030, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 100\n",
      "Recon_loss: 0.030, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 48\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 48\\1000\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 0\n",
      "Recon_loss: 0.035, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 50\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 49\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 49\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.022\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 50\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 50\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 51\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 51\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 52\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 52\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 53\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 53\\1000\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 50\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 60\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 70\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 80\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 90\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 100\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 54\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 54\\1000\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 55\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 55\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 20\n",
      "Recon_loss: 0.033, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 30\n",
      "Recon_loss: 0.033, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 50\n",
      "Recon_loss: 0.032, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 60\n",
      "Recon_loss: 0.032, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 70\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 80\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 90\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 56\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 56\\1000\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 57\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 57\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 58\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 58\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 30\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 50\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 59\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 59\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 60\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 60\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 61\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 61\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 62\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 62\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 63\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 63\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 64\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 64\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 65\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 65\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 10\n",
      "Recon_loss: 0.039, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 60\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 70\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 80\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 90\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 100\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 66\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 66\\1000\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.031\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 67\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 67\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 68\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 68\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.026\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 69\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 69\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 70\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 70\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recon_loss: 0.027, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 71\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 71\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.024\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 72\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 72\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 73\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 73\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.029\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.026\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.022\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.021\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.020\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 80\n",
      "Recon_loss: 0.028, indep loss:  0.020\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 74\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 74\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 10\n",
      "Recon_loss: 0.036, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 80\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 75\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 75\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 76\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 76\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 40\n",
      "Recon_loss: 0.032, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 77\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 77\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.067\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.040\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.027\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.025\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.022\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.020\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 78\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 78\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.017\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 79\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 79\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 0\n",
      "Recon_loss: 0.047, indep loss:  0.071\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 10\n",
      "Recon_loss: 0.036, indep loss:  0.027\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 20\n",
      "Recon_loss: 0.041, indep loss:  0.021\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 30\n",
      "Recon_loss: 0.034, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 40\n",
      "Recon_loss: 0.034, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 50\n",
      "Recon_loss: 0.033, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 60\n",
      "Recon_loss: 0.036, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 70\n",
      "Recon_loss: 0.035, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 80\n",
      "Recon_loss: 0.032, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 100\n",
      "Recon_loss: 0.031, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 80\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 80\\1000\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 0\n",
      "Recon_loss: 0.072, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 81\\1000, Step: 110\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 81\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 82\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 82\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 83\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 83\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 10\n",
      "Recon_loss: 0.041, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 84\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 84\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.020\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 85\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 85\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 0\n",
      "Recon_loss: 0.036, indep loss:  0.036\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 86\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 86\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 87\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 87\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 88\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 88\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 89\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 89\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 10\n",
      "Recon_loss: 0.038, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 20\n",
      "Recon_loss: 0.036, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 30\n",
      "Recon_loss: 0.032, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 90\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 90\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 0\n",
      "Recon_loss: 0.037, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 91\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 91\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.021\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 50\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92\\1000, Step: 60\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 80\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 92\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 92\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.034\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.028\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.023\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.019\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.018\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 93\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 93\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.001\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 50\n",
      "Recon_loss: 0.031, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 60\n",
      "Recon_loss: 0.031, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 70\n",
      "Recon_loss: 0.033, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 80\n",
      "Recon_loss: 0.031, indep loss:  0.014\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 100\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 94\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 94\\1000\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 70\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 80\n",
      "Recon_loss: 0.031, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 90\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 100\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 95\\1000, Step: 110\n",
      "Recon_loss: 0.032, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 95\\1000\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 96\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 96\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 97\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 97\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0001000\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 60\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 70\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 80\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 90\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 100\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "Epoch: 98\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0001000\n",
      "End or epoch: 98\\1000\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 0\n",
      "Recon_loss: 0.037, indep loss:  0.054\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 10\n",
      "Recon_loss: 0.039, indep loss:  0.030\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 99\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 99\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 100\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 100\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 101\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 101\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 102\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 102\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 103\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 103\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 104\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 104\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 105\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 105\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 106\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 106\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 107\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 107\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 108\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 108\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 50\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 109\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 109\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.064\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 10\n",
      "Recon_loss: 0.034, indep loss:  0.033\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 30\n",
      "Recon_loss: 0.034, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 110\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 110\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 111\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 111\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 20\n",
      "Recon_loss: 0.010, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 30\n",
      "Recon_loss: 0.011, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 112\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 112\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 113\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 113\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 114\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 114\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 115\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 115\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 116\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 116\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 0\n",
      "Recon_loss: 0.060, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 117\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 117\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 118\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 118\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 119\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 119\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 120\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 120\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 121\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 121\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 0\n",
      "Recon_loss: 0.052, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 10\n",
      "Recon_loss: 0.038, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 122\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 122\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.036\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 123\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 123\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 124\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 124\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 125\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 125\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 0\n",
      "Recon_loss: 0.064, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 126\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 126\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 127\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 127\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 128\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 128\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 129\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 129\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 130\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 130\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 131\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 131\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 132\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 132\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 0\n",
      "Recon_loss: 0.052, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 10\n",
      "Recon_loss: 0.034, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 50\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 133\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 133\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 134\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 134\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 135\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 135\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 0\n",
      "Recon_loss: 0.035, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 136\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 136\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 137\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 137\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 138\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 138\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 139\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 139\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 140\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 140\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 141\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 141\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 142\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 142\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 0\n",
      "Recon_loss: 0.043, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 143\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 143\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 144\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 144\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 70\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 145\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 145\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 30\n",
      "Recon_loss: 0.031, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 146\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 146\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 147\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 147\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 148\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End or epoch: 148\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.038\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 149\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 149\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 150\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 150\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 151\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 151\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 152\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 152\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 153\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 153\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 154\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 154\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 155\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 155\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 156\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 156\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 0\n",
      "Recon_loss: 0.035, indep loss:  0.029\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 157\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 157\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 158\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 158\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 159\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 159\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 160\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 160\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 161\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 161\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 0\n",
      "Recon_loss: 0.035, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 10\n",
      "Recon_loss: 0.037, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 162\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 162\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 163\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 163\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 164\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 164\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 165\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 165\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 166\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 166\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 167\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 167\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 0\n",
      "Recon_loss: 0.036, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 168\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 168\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 169\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 169\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 0\n",
      "Recon_loss: 0.047, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 170\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 170\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 171\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 171\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 172\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 172\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 173\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 173\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 174\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 174\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 175\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 175\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 176\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 176\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 177\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 177\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 177\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 178\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 178\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 179\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 179\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 180\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 180\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 181\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 181\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 182\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 182\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 183\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 183\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 184\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 184\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 185\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 185\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 186\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 186\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 187\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 187\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 188\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 188\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 189\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 189\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 190\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 190\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 70\n",
      "Recon_loss: 0.030, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 80\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 191\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 191\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 192\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 192\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 193\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 193\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 194\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 194\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 195\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 195\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 196\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 196\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 197\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 197\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 198\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 198\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 199\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 199\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 200\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 200\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 0\n",
      "Recon_loss: 0.003, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 201\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 201\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 202\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 202\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 203\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 203\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 204\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 204\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 205\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 205\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 205\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 206\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 206\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 207\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 207\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 208\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 208\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.044\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 209\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 209\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 80\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 210\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 210\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 211\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 211\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 212\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 212\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 212\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 0\n",
      "Recon_loss: 0.044, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 213\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 213\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.036\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 214\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 214\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 10\n",
      "Recon_loss: 0.039, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 20\n",
      "Recon_loss: 0.034, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 215\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 215\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 0\n",
      "Recon_loss: 0.042, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 216\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 216\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.030\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 217\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 217\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 218\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 218\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 219\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 219\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.033\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.034\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 220\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 220\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 221\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 221\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 222\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 222\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 223\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 223\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.052\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 224\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 224\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 0\n",
      "Recon_loss: 0.036, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 10\n",
      "Recon_loss: 0.034, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 225\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 225\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 226\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 226\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 226\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 227\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 227\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 228\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 228\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 0\n",
      "Recon_loss: 0.036, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 229\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 229\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.036\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 230\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 230\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 231\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 231\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 232\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 232\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 233\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 233\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 233\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 234\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 234\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 235\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 235\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 236\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 236\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 237\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 237\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 0\n",
      "Recon_loss: 0.039, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 238\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 238\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 239\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 239\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 240\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 240\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.053\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 241\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 241\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 242\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 242\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 243\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 243\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 244\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 244\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 245\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 245\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 246\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 246\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 247\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 247\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 248\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 248\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.032\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 249\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 249\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.028\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 100\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 250\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 250\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 251\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 251\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 0\n",
      "Recon_loss: 0.049, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 252\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 252\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 253\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 253\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 254\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 254\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 254\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 0\n",
      "Recon_loss: 0.035, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 255\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 255\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 256\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 256\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 257\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 257\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 10\n",
      "Recon_loss: 0.036, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 258\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 258\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 259\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 259\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 260\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 260\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 261\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 261\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 261\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 60\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 80\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 262\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 262\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 0\n",
      "Recon_loss: 0.052, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 10\n",
      "Recon_loss: 0.035, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 263\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 263\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 264\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 264\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 265\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 265\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 266\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 266\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 267\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 267\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 268\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 268\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 269\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 269\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.028\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 270\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 270\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 271\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 271\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 272\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 272\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.032\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 273\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 273\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 274\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 274\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 275\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 275\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 275\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 276\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 276\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 277\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 277\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 278\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 278\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 279\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 279\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 280\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 280\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 281\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 281\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 282\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 282\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 282\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 283\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 283\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 284\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 284\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 285\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 285\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 286\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 286\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 287\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 287\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 288\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 288\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 289\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 289\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 289\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 290\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 290\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 291\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 291\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.070\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 292\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 292\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 293\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 293\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 294\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 294\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 295\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 295\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 296\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 296\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 296\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 297\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 297\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 298\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 298\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 299\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 299\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.048\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 10\n",
      "Recon_loss: 0.008, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 20\n",
      "Recon_loss: 0.009, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 30\n",
      "Recon_loss: 0.011, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 300\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 300\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 50\n",
      "Recon_loss: 0.029, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 301\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 301\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 0\n",
      "Recon_loss: 0.040, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 302\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 302\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.044\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 303\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 303\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 303\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.030\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 304\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 304\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 305\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 305\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.036\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 306\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 306\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 0\n",
      "Recon_loss: 0.044, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 307\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 307\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 308\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 308\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 309\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 309\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 310\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 310\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 311\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 311\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 312\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 312\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 313\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 313\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 314\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 314\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 315\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 315\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 10\n",
      "Recon_loss: 0.037, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 316\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 316\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 317\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 317\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 317\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 318\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 318\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 319\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 319\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 320\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 320\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 321\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 321\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 322\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 322\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 0\n",
      "Recon_loss: 0.051, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 323\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 323\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 324\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 324\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 324\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 325\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 325\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 326\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 326\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 327\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 327\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 0\n",
      "Recon_loss: 0.041, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 328\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 328\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 329\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 329\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 330\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 330\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 0\n",
      "Recon_loss: 0.044, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 331\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 331\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 331\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 332\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 332\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 333\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 333\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 334\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 334\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 335\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 335\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 40\n",
      "Recon_loss: 0.011, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 50\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 336\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 336\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 337\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 337\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 338\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 338\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 338\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 0\n",
      "Recon_loss: 0.056, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 10\n",
      "Recon_loss: 0.034, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 339\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 339\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 340\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 340\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 341\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 341\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 342\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 342\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 343\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 343\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 344\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 344\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 345\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 345\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 345\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 346\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 346\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 347\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 347\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 348\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 348\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 349\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 349\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 350\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 350\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 351\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 351\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 352\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 352\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 352\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 353\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 353\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 354\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 354\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.039\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 355\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 355\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 10\n",
      "Recon_loss: 0.035, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 356\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 356\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 357\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 357\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.028\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 358\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 358\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.052\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 359\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 359\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 359\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.039\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 360\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 360\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 10\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 30\n",
      "Recon_loss: 0.011, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 361\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 361\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 362\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 362\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 363\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 363\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 10\n",
      "Recon_loss: 0.035, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 364\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 364\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 365\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 365\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 366\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 366\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 366\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 367\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 367\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 368\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 368\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 0\n",
      "Recon_loss: 0.045, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 369\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 369\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 370\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 370\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 371\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 371\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 372\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 372\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.048\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 20\n",
      "Recon_loss: 0.009, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 373\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 373\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 373\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 374\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 374\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 375\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 375\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 20\n",
      "Recon_loss: 0.010, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 376\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 376\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 377\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 377\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 378\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 378\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 379\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 379\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 380\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 380\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 381\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 381\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.049\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.047\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.033\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 382\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 382\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 383\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 383\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 384\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 384\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 385\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 385\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 386\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 386\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 387\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 387\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 387\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 388\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 388\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 389\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 389\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 390\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 390\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 391\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 391\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 392\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 392\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 393\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 393\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 394\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 394\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 394\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 395\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 395\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 396\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 396\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 397\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 397\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 398\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 398\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 399\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 399\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 400\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 400\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 401\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 401\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 401\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.028\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 402\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 402\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 403\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 403\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 40\n",
      "Recon_loss: 0.033, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 50\n",
      "Recon_loss: 0.031, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 60\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 70\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 404\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 404\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 405\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 405\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 10\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 406\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 406\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 407\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 407\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 0\n",
      "Recon_loss: 0.041, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 408\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 408\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 408\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 409\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 409\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 410\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 410\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 0\n",
      "Recon_loss: 0.035, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 411\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 411\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 412\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 412\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 413\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 413\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 414\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 414\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 415\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 415\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 415\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.031\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.031\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 416\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 416\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 417\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 417\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 418\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 418\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 419\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 419\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 420\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 420\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 421\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 421\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 422\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 422\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 422\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 423\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 423\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 424\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 424\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 425\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 425\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 426\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 426\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 427\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 427\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 428\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 428\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 429\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 429\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 430\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 430\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 431\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 431\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 432\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 432\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 433\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 433\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 434\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 434\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 435\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 435\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 436\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 436\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 436\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 437\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 437\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 0\n",
      "Recon_loss: 0.043, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 438\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 438\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 439\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 439\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 440\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 440\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.048\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 441\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 441\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.067\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.033\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 442\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 442\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 443\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 443\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 443\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.032\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 444\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 444\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 445\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 445\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 446\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 446\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 447\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 447\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 0\n",
      "Recon_loss: 0.036, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 448\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 448\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 449\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 449\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 100\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 450\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 450\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 0\n",
      "Recon_loss: 0.056, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 10\n",
      "Recon_loss: 0.036, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 451\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 451\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 452\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 452\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 453\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 453\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 454\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 454\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 455\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 455\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 456\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 456\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 457\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 457\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 457\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 458\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 458\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 459\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 459\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 460\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 460\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 10\n",
      "Recon_loss: 0.007, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 461\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 461\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 462\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 462\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 463\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 463\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 464\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 464\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 464\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 465\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 465\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 466\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 466\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 20\n",
      "Recon_loss: 0.010, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 467\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 467\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 0\n",
      "Recon_loss: 0.041, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 468\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 468\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 0\n",
      "Recon_loss: 0.039, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 469\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 469\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 470\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 470\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 10\n",
      "Recon_loss: 0.035, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 471\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 471\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 471\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 472\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 472\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 473\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 473\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 10\n",
      "Recon_loss: 0.037, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 474\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 474\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 475\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 475\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 476\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 476\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 477\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 477\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 478\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 478\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 478\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 479\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 479\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 480\\1000, Step: 110\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 480\\1000\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 481\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 481\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 482\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 482\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 10\n",
      "Recon_loss: 0.036, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 483\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 483\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 484\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 484\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 485\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 485\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 485\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 486\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 486\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 487\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 487\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 488\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 488\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 489\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 489\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 0\n",
      "Recon_loss: 0.043, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 490\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 490\\1000\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 491\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 491\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 10\n",
      "Recon_loss: 0.008, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 30\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 492\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 492\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 492\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.047\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 493\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 493\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 10\n",
      "Recon_loss: 0.042, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 20\n",
      "Recon_loss: 0.034, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 494\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 494\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 495\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 495\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 496\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 496\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 497\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 497\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.052\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 498\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 498\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 499\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 499\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 500\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 500\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 10\n",
      "Recon_loss: 0.037, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 501\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 501\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.029\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 502\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 502\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 503\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 503\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 504\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 504\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.044\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 505\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 505\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 506\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 506\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 506\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 507\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 507\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 508\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 508\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 509\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 509\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 510\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 510\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 511\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 511\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 512\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 512\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.029\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 513\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 513\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 513\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 514\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 514\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 515\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 515\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 516\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 516\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 517\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 517\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 518\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 518\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 519\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 519\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 520\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 520\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 520\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.036\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 521\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 521\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 522\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 522\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 523\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 523\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 524\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 524\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 525\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 525\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 526\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 526\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.034\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 527\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 527\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 527\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 528\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 528\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 0\n",
      "Recon_loss: 0.065, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 10\n",
      "Recon_loss: 0.038, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 529\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 529\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.029\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 530\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 530\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 531\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 531\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 532\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 532\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 533\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 533\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 534\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 534\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 534\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 535\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 535\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 536\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 536\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 537\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 537\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 538\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 538\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 539\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 539\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 10\n",
      "Recon_loss: 0.009, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 540\\1000, Step: 110\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 540\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 541\\1000, Step: 70\n",
      "Recon_loss: 0.013, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 541\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 541\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 542\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 542\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 0\n",
      "Recon_loss: 0.044, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 10\n",
      "Recon_loss: 0.040, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 20\n",
      "Recon_loss: 0.035, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 50\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 543\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 543\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 544\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 544\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 545\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 545\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 546\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 546\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 547\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 547\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 548\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 548\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 548\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 549\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 549\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 550\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 550\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 70\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 80\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 551\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 551\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 552\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 552\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 0\n",
      "Recon_loss: 0.055, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 10\n",
      "Recon_loss: 0.037, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 553\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 553\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 554\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 554\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 0\n",
      "Recon_loss: 0.034, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 555\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 555\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 555\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 556\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 556\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 557\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 557\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 0\n",
      "Recon_loss: 0.036, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 558\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 558\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 559\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 559\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 560\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 560\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 561\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 561\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 562\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 562\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 562\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 563\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 563\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 30\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 564\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 564\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 0\n",
      "Recon_loss: 0.058, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 10\n",
      "Recon_loss: 0.043, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 20\n",
      "Recon_loss: 0.033, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 565\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 565\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 566\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 566\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 10\n",
      "Recon_loss: 0.041, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 20\n",
      "Recon_loss: 0.034, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 567\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 567\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 10\n",
      "Recon_loss: 0.036, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 568\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 568\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 569\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 569\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 569\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.070\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 570\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 570\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 571\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 571\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 20\n",
      "Recon_loss: 0.010, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 572\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 572\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 0\n",
      "Recon_loss: 0.004, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 573\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 573\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 574\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 574\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.057\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 575\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 575\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 576\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 576\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 576\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.034\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 577\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 577\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 578\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 578\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 579\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 579\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 580\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 580\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 581\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 581\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 582\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 582\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 0\n",
      "Recon_loss: 0.039, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 583\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 583\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 583\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 584\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 584\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 585\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 585\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 586\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 586\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 587\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 587\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 588\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 588\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 0\n",
      "Recon_loss: 0.003, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 589\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 589\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 10\n",
      "Recon_loss: 0.033, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 590\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 590\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 590\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 591\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 591\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 592\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 592\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 593\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 593\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 594\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 594\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 595\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 595\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 596\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 596\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 597\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 597\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 597\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 598\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 598\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 599\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 599\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 600\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 600\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 601\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 601\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 602\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 602\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 603\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 603\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 604\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 604\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 604\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 605\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 605\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.028\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 606\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 606\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 607\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 607\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 0\n",
      "Recon_loss: 0.045, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 608\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 608\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 609\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 609\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 610\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 610\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 611\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 611\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 611\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 612\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 612\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 613\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 613\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 614\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 614\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 615\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 615\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 616\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 616\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.073\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 617\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 617\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 618\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 618\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 618\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.032\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 619\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 619\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 620\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 620\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.069\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 621\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 621\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 622\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 622\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 623\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 623\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 624\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 624\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 625\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 625\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 625\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 30\n",
      "Recon_loss: 0.011, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 50\n",
      "Recon_loss: 0.012, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 70\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 626\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 626\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 627\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 627\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 10\n",
      "Recon_loss: 0.009, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 628\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 628\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 629\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 629\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 90\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 630\\1000, Step: 110\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 630\\1000\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 631\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 631\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 632\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 632\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 632\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 633\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 633\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 634\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 634\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 635\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 635\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 636\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 636\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 637\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 637\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 30\n",
      "Recon_loss: 0.011, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 80\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 638\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 638\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 639\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 639\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 639\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 0\n",
      "Recon_loss: 0.055, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 10\n",
      "Recon_loss: 0.041, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 640\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 640\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 641\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 641\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 642\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 642\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 643\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 643\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 644\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 644\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 645\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 645\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 646\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 646\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 646\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 647\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 647\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 648\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 648\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 649\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 649\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 650\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 650\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 651\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 651\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 652\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 652\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 653\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 653\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 653\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 654\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 654\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 655\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 655\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 656\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 656\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 657\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 657\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 658\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 658\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 659\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 659\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 660\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 660\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 660\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 661\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 661\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 662\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 662\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 663\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 663\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 664\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 664\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.042\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 665\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 665\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 666\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 666\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 667\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 667\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 667\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 668\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 668\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 669\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 669\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 10\n",
      "Recon_loss: 0.009, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 670\\1000, Step: 110\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 670\\1000\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 671\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 671\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.030\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 672\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 672\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.036\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 673\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 673\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 674\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 674\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 674\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 675\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 675\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 676\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 676\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 677\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 677\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.031\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 20\n",
      "Recon_loss: 0.034, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 30\n",
      "Recon_loss: 0.032, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 40\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 50\n",
      "Recon_loss: 0.028, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 678\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 678\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 679\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 679\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 680\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 680\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 681\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 681\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 681\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 682\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 682\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 683\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 683\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 684\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 684\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 685\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 685\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.069\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.028\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.031\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 686\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 686\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 687\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 687\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 688\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 688\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 688\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 689\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 689\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 690\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 690\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 691\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 691\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 692\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 692\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 0\n",
      "Recon_loss: 0.004, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 693\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 693\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 694\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 694\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 695\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 695\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 695\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 696\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 696\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 697\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 697\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.031\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 698\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 698\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 699\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 699\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 700\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 700\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 701\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 701\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 0\n",
      "Recon_loss: 0.067, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 10\n",
      "Recon_loss: 0.038, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 702\\1000, Step: 30\n",
      "Recon_loss: 0.032, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 40\n",
      "Recon_loss: 0.034, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 50\n",
      "Recon_loss: 0.033, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 60\n",
      "Recon_loss: 0.033, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 70\n",
      "Recon_loss: 0.034, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 80\n",
      "Recon_loss: 0.032, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 90\n",
      "Recon_loss: 0.032, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 100\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 702\\1000, Step: 110\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 702\\1000\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 703\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 703\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 704\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 704\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 705\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 705\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 0\n",
      "Recon_loss: 0.037, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 706\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 706\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 707\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 707\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 10\n",
      "Recon_loss: 0.034, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 60\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 708\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 708\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 709\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 709\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 709\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 710\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 710\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 711\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 711\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 712\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 712\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 713\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 713\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 714\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 714\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 715\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 715\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 716\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 716\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 716\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 717\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 717\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 718\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 718\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 719\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 719\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 80\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 720\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 720\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 721\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 721\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 722\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 722\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 723\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 723\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 723\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 10\n",
      "Recon_loss: 0.008, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 724\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 724\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 725\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 725\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 726\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 726\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 727\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 727\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 728\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 728\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 729\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 729\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 730\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 730\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 730\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 731\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 731\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 732\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 732\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 0\n",
      "Recon_loss: 0.037, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 733\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 733\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 734\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 734\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 735\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 735\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 50\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 70\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 80\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 90\n",
      "Recon_loss: 0.012, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 736\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 736\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 737\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 737\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 737\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 738\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 738\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 739\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 739\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 740\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 740\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 741\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 741\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 742\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 742\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 80\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 100\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 743\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 743\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.057\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 744\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 744\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 744\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 745\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 745\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.054\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 746\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 746\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 747\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 747\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 748\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 748\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 749\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 749\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 750\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 750\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 751\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 751\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 751\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 752\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 752\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 753\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 753\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 754\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 754\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 755\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 755\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 756\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 756\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 757\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 757\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 758\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 758\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 758\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.029\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 759\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 759\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 760\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 760\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 761\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 761\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 762\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 762\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 763\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 763\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 764\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 764\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 765\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 765\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 765\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 766\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 766\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 767\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 767\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 768\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 768\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 769\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 769\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.034\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.032\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 770\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 770\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 771\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 771\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 772\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 772\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 772\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 773\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 773\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 774\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 774\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 775\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 775\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 776\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 776\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 777\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 777\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 778\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 778\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 779\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 779\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 779\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 780\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 780\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 781\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 781\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 782\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 782\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 783\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 783\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 784\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 784\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 785\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 785\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 786\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 786\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 786\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 787\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 787\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 788\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 788\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 0\n",
      "Recon_loss: 0.049, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 789\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 789\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 790\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 790\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 791\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 791\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 792\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 792\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 0\n",
      "Recon_loss: 0.044, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 793\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 793\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 793\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 40\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 794\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 794\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 795\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 795\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 796\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 796\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 797\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 797\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 10\n",
      "Recon_loss: 0.009, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 798\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 798\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 799\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 799\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 800\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 800\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 801\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 801\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 802\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 802\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 803\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 803\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 0\n",
      "Recon_loss: 0.043, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 10\n",
      "Recon_loss: 0.032, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 804\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 804\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 805\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 805\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 806\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 806\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 807\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 807\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 807\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 808\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 808\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 0\n",
      "Recon_loss: 0.036, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 10\n",
      "Recon_loss: 0.035, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 809\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 809\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 810\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 810\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 811\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 811\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 812\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 812\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 10\n",
      "Recon_loss: 0.029, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 20\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 50\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 813\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 813\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 814\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 814\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 814\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 815\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 815\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 816\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 816\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 817\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 817\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 818\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 818\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 819\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 819\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 820\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 820\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 821\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 821\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 821\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 822\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 822\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 823\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 823\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 824\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 824\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 825\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 825\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 826\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 826\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 827\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 827\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 828\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 90\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 828\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 828\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 829\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 829\\1000\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 50\n",
      "Recon_loss: 0.012, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 60\n",
      "Recon_loss: 0.012, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 70\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 80\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 90\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 100\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 830\\1000, Step: 110\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 830\\1000\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 831\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 831\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 0\n",
      "Recon_loss: 0.033, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 832\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 832\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 833\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 833\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 834\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 834\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 835\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 835\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 835\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 836\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 836\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 837\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 837\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 838\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 838\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 839\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 839\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 840\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 840\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 841\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 841\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 0\n",
      "Recon_loss: 0.039, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 842\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 842\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 842\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 843\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 843\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 844\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 844\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 845\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 845\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 846\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 846\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 847\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 847\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 848\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 848\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.037\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 849\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 849\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 849\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 850\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 850\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 851\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 851\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 852\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 852\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 853\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 853\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 854\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 854\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 855\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 855\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 856\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 856\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 856\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 10\n",
      "Recon_loss: 0.009, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 20\n",
      "Recon_loss: 0.011, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 857\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 857\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 858\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 858\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 859\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 859\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 50\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 860\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 860\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 861\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 861\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 862\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 862\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 863\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 40\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 70\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 80\n",
      "Recon_loss: 0.027, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 863\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 863\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 864\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 864\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 865\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 865\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 866\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 866\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 867\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 867\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 868\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 868\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.050\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 869\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 869\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 870\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 870\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 870\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 871\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 871\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 20\n",
      "Recon_loss: 0.033, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 30\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 872\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 872\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 873\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 873\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 874\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 874\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 875\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 875\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 876\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 876\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.037\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 10\n",
      "Recon_loss: 0.009, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 877\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 877\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 877\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 0\n",
      "Recon_loss: 0.041, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 878\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 878\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 879\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 879\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 880\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 880\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 881\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 881\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 882\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 882\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 80\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 883\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 883\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 884\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 884\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 884\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 885\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 885\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 886\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 886\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 887\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 887\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 888\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 888\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 889\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 889\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 0\n",
      "Recon_loss: 0.045, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 890\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 890\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 891\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 891\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 891\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 892\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 892\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.034\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 10\n",
      "Recon_loss: 0.034, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 20\n",
      "Recon_loss: 0.032, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 40\n",
      "Recon_loss: 0.029, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 60\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 70\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 80\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 893\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 893\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 0\n",
      "Recon_loss: 0.037, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 20\n",
      "Recon_loss: 0.026, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 70\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 100\n",
      "Recon_loss: 0.024, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 894\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 894\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 895\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 895\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 50\n",
      "Recon_loss: 0.012, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 70\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 80\n",
      "Recon_loss: 0.013, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 90\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 896\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 896\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 897\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 897\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 898\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 898\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 898\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 60\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 899\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 899\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 900\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 900\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 901\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 901\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 902\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 902\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 903\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 903\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 904\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 904\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 905\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 905\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 905\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 906\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 906\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 907\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 907\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 908\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 908\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 909\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 909\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 910\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 910\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.027\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 911\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 911\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 912\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 912\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 912\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 913\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 913\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 914\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 914\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.030\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 915\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 915\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 916\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 916\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 917\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 917\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 918\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 918\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 0\n",
      "Recon_loss: 0.038, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 919\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 919\\1000, Step: 110\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 919\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 30\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 920\\1000, Step: 110\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 920\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.026\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 921\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 921\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 922\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 922\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 923\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 923\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 924\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 924\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 50\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 80\n",
      "Recon_loss: 0.014, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 925\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 925\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 926\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 40\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 926\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 926\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 10\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 20\n",
      "Recon_loss: 0.010, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 30\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 40\n",
      "Recon_loss: 0.012, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 50\n",
      "Recon_loss: 0.011, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 60\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 927\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 927\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 0\n",
      "Recon_loss: 0.027, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 10\n",
      "Recon_loss: 0.031, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 30\n",
      "Recon_loss: 0.030, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 40\n",
      "Recon_loss: 0.028, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 50\n",
      "Recon_loss: 0.027, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 60\n",
      "Recon_loss: 0.026, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 80\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 90\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 100\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 928\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 928\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 70\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 80\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 929\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 929\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 930\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 930\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 0\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 931\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 931\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 20\n",
      "Recon_loss: 0.025, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 30\n",
      "Recon_loss: 0.028, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 40\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 50\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 932\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 932\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.036\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 933\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 933\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 933\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 20\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 30\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 934\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 934\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 935\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 935\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 70\n",
      "Recon_loss: 0.014, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 936\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 936\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 937\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 937\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 938\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 938\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 0\n",
      "Recon_loss: 0.010, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 939\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 939\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 940\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 940\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 940\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 60\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 80\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 90\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 100\n",
      "Recon_loss: 0.025, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 941\\1000, Step: 110\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 941\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 0\n",
      "Recon_loss: 0.047, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 40\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 942\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 942\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 943\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 943\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 944\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 944\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 0\n",
      "Recon_loss: 0.005, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 10\n",
      "Recon_loss: 0.010, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 945\\1000, Step: 110\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 945\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 20\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 946\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 946\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 947\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 947\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 947\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 0\n",
      "Recon_loss: 0.022, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 948\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 948\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 949\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 949\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 10\n",
      "Recon_loss: 0.023, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 20\n",
      "Recon_loss: 0.031, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 950\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 950\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 20\n",
      "Recon_loss: 0.013, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 951\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 951\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 952\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 952\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 10\n",
      "Recon_loss: 0.025, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 953\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 953\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 10\n",
      "Recon_loss: 0.013, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 954\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 954\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 954\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 955\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 955\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.051\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.020\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.018\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 956\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 956\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.021\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 957\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 957\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 0\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 958\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 958\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 959\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 959\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 960\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 960\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 0\n",
      "Recon_loss: 0.032, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 961\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 70\n",
      "Recon_loss: 0.023, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 90\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 961\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 961\\1000\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 60\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 962\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 962\\1000\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 0\n",
      "Recon_loss: 0.031, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 963\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 963\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 964\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 964\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 965\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 965\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 20\n",
      "Recon_loss: 0.027, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 30\n",
      "Recon_loss: 0.023, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 966\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 966\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 10\n",
      "Recon_loss: 0.022, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 967\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 967\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 0\n",
      "Recon_loss: 0.045, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 10\n",
      "Recon_loss: 0.026, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 20\n",
      "Recon_loss: 0.029, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 968\\1000, Step: 30\n",
      "Recon_loss: 0.032, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 40\n",
      "Recon_loss: 0.031, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 50\n",
      "Recon_loss: 0.032, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 60\n",
      "Recon_loss: 0.030, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 70\n",
      "Recon_loss: 0.029, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 80\n",
      "Recon_loss: 0.028, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 90\n",
      "Recon_loss: 0.027, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 100\n",
      "Recon_loss: 0.028, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 968\\1000, Step: 110\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 968\\1000\n",
      "Recon_loss: 0.026, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 969\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 969\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 970\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 970\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 0\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 971\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 971\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 0\n",
      "Recon_loss: 0.006, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 972\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 972\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 973\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 973\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 10\n",
      "Recon_loss: 0.017, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 20\n",
      "Recon_loss: 0.014, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 30\n",
      "Recon_loss: 0.012, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 40\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 50\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 60\n",
      "Recon_loss: 0.013, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 70\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 80\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 90\n",
      "Recon_loss: 0.012, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 100\n",
      "Recon_loss: 0.013, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 974\\1000, Step: 110\n",
      "Recon_loss: 0.013, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 974\\1000\n",
      "Recon_loss: 0.014, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 975\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 40\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 975\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 975\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 10\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 976\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 976\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 977\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 977\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 0\n",
      "Recon_loss: 0.024, indep loss:  0.022\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 10\n",
      "Recon_loss: 0.015, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 40\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 978\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 978\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 30\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 50\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 70\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 100\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 979\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 979\\1000\n",
      "Recon_loss: 0.023, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 0\n",
      "Recon_loss: 0.050, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 10\n",
      "Recon_loss: 0.030, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 20\n",
      "Recon_loss: 0.030, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 30\n",
      "Recon_loss: 0.024, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 40\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 60\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 980\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 980\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 0\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 50\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 70\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 80\n",
      "Recon_loss: 0.020, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 981\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 981\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 0\n",
      "Recon_loss: 0.021, indep loss:  0.040\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 20\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 982\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 40\n",
      "Recon_loss: 0.024, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 50\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 60\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 80\n",
      "Recon_loss: 0.022, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 90\n",
      "Recon_loss: 0.021, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 100\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 982\\1000, Step: 110\n",
      "Recon_loss: 0.022, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 982\\1000\n",
      "Recon_loss: 0.024, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 0\n",
      "Recon_loss: 0.029, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 30\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 983\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 983\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 0\n",
      "Recon_loss: 0.030, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 20\n",
      "Recon_loss: 0.021, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 30\n",
      "Recon_loss: 0.025, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 984\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 984\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 0\n",
      "Recon_loss: 0.007, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.017\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 50\n",
      "Recon_loss: 0.017, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 985\\1000, Step: 110\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 985\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 0\n",
      "Recon_loss: 0.025, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 10\n",
      "Recon_loss: 0.028, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 30\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 80\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 986\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 986\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 0\n",
      "Recon_loss: 0.012, indep loss:  0.040\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.024\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.019\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 90\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 987\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 987\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 0\n",
      "Recon_loss: 0.020, indep loss:  0.002\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 10\n",
      "Recon_loss: 0.024, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 988\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 988\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.023\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 20\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 989\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 70\n",
      "Recon_loss: 0.016, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 100\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 989\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 989\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 0\n",
      "Recon_loss: 0.014, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 10\n",
      "Recon_loss: 0.020, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 20\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 70\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 80\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 990\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 990\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 30\n",
      "Recon_loss: 0.017, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 50\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 60\n",
      "Recon_loss: 0.021, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 70\n",
      "Recon_loss: 0.022, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 80\n",
      "Recon_loss: 0.021, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 90\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 100\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 991\\1000, Step: 110\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 991\\1000\n",
      "Recon_loss: 0.020, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 0\n",
      "Recon_loss: 0.009, indep loss:  0.016\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 10\n",
      "Recon_loss: 0.012, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 40\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 992\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 992\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 0\n",
      "Recon_loss: 0.008, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 10\n",
      "Recon_loss: 0.006, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 20\n",
      "Recon_loss: 0.015, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 30\n",
      "Recon_loss: 0.015, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.014\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.013\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.012\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 993\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 993\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 0\n",
      "Recon_loss: 0.028, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 10\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 20\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 60\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 70\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 994\\1000, Step: 110\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 994\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 0\n",
      "Recon_loss: 0.023, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 10\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 40\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 60\n",
      "Recon_loss: 0.017, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 995\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 995\\1000\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 0\n",
      "Recon_loss: 0.011, indep loss:  0.001\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 20\n",
      "Recon_loss: 0.023, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 30\n",
      "Recon_loss: 0.022, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 50\n",
      "Recon_loss: 0.020, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 996\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.007\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 90\n",
      "Recon_loss: 0.018, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 100\n",
      "Recon_loss: 0.018, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 996\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 996\\1000\n",
      "Recon_loss: 0.017, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 0\n",
      "Recon_loss: 0.017, indep loss:  0.025\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 10\n",
      "Recon_loss: 0.014, indep loss:  0.015\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 20\n",
      "Recon_loss: 0.017, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 30\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 40\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 50\n",
      "Recon_loss: 0.015, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 60\n",
      "Recon_loss: 0.016, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.010\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 80\n",
      "Recon_loss: 0.016, indep loss:  0.009\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 90\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 100\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 997\\1000, Step: 110\n",
      "Recon_loss: 0.017, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 997\\1000\n",
      "Recon_loss: 0.016, indep loss:  0.008\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 0\n",
      "Recon_loss: 0.013, indep loss:  0.011\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 10\n",
      "Recon_loss: 0.016, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 40\n",
      "Recon_loss: 0.021, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 50\n",
      "Recon_loss: 0.019, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 60\n",
      "Recon_loss: 0.019, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 70\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 80\n",
      "Recon_loss: 0.018, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 90\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 100\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 998\\1000, Step: 110\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 998\\1000\n",
      "Recon_loss: 0.019, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 0\n",
      "Recon_loss: 0.016, indep loss:  0.000\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 10\n",
      "Recon_loss: 0.027, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 20\n",
      "Recon_loss: 0.020, indep loss:  0.003\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 30\n",
      "Recon_loss: 0.018, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 40\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 50\n",
      "Recon_loss: 0.016, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 60\n",
      "Recon_loss: 0.015, indep loss:  0.004\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 70\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 80\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 90\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 100\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "Epoch: 999\\1000, Step: 110\n",
      "Recon_loss: 0.015, indep loss:  0.005\n",
      "Learning rate = 0.0000100\n",
      "End or epoch: 999\\1000\n",
      "Recon_loss: 0.015, indep loss:  0.006\n",
      "Learning rate = 0.0000100\n",
      "Learning rate = 0.0000100\n",
      "Finished training \n",
      "Running test\n",
      "Test results: \n",
      "Recon_loss: 0.010, indep loss:  0.004\n",
      "test_y.shape:  (3000, 1)\n",
      "code.shape:  (3000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()\n",
    "test()\n",
    "analyze_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95578d",
   "metadata": {
    "id": "2b95578d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4d8b1",
   "metadata": {
    "id": "a7e4d8b1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ICA demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
