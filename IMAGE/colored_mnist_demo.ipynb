{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ2122zmOT2-"
   },
   "source": [
    "\n",
    "# Colored MNIST example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWBsYGvYOebu"
   },
   "source": [
    "The coloring is taken from https://colab.research.google.com/github/reiinakano/invariant-risk-minimization/blob/master/invariant_risk_minimization_colored_mnist.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-4GA8_kPZPb"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9tqgcYxHWE7j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAXISJ8_PbvT"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L_HQEUaTPBi0"
   },
   "outputs": [],
   "source": [
    "def color_grayscale_arr(arr, color):\n",
    "    \"\"\"Converts grayscale image to either red or green\"\"\"\n",
    "    assert arr.ndim == 2\n",
    "    dtype = arr.dtype\n",
    "    h, w = arr.shape\n",
    "    arr = np.reshape(arr, [h, w, 1])\n",
    "    if color == 'red':\n",
    "        arr = np.concatenate([arr, np.zeros((h, w, 2), dtype=dtype)], axis=2)\n",
    "    elif color == 'green':\n",
    "        arr = np.concatenate([np.zeros((h, w, 1), dtype=dtype), arr, np.zeros((h, w, 1), dtype=dtype)], axis=2)\n",
    "    else:  # color == 'blue':\n",
    "        arr = np.concatenate([np.zeros((h, w, 2), dtype=dtype), arr], axis=2)\n",
    "    return arr\n",
    "\n",
    "\n",
    "class ColoredMNIST(datasets.VisionDataset):\n",
    "    \"\"\"\n",
    "    Colored MNIST dataset for testing IRM. Prepared using procedure from https://arxiv.org/pdf/1907.02893.pdf\n",
    "\n",
    "    Args:\n",
    "      root (string): Root directory of dataset where ``ColoredMNIST/*.pt`` will exist.\n",
    "      env (string): Which environment to load. Must be 1 of 'train1', 'train2', 'test', or 'all_train'.\n",
    "      transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "      target_transform (callable, optional): A function/transform that takes in the\n",
    "        target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root='./data', env='train1', transform=None, target_transform=None):\n",
    "        super(ColoredMNIST, self).__init__(root, transform=transform,\n",
    "                                           target_transform=target_transform)\n",
    "        self.env = env\n",
    "        self.prepare_colored_mnist()\n",
    "        if env in ['train', 'test']:\n",
    "            self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', env) + '.pt')\n",
    "        elif env == 'all':\n",
    "            self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', 'train.pt')) + torch.load(os.path.join(self.root, 'ColoredMNIST', 'test.pt'))\n",
    "        else:\n",
    "            raise RuntimeError(f'{env} env unknown. Valid envs are train, test, and all')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, color_label, digit_label = self.data_label_tuples[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, color_label, digit_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_label_tuples)\n",
    "\n",
    "    def prepare_colored_mnist(self):\n",
    "        colored_mnist_dir = os.path.join(self.root, 'ColoredMNIST')\n",
    "        if os.path.exists(os.path.join(colored_mnist_dir, 'train.pt')) \\\n",
    "                and os.path.exists(os.path.join(colored_mnist_dir, 'test.pt')):\n",
    "            print('Colored MNIST dataset already exists')\n",
    "            return\n",
    "\n",
    "        print('Preparing Colored MNIST')\n",
    "        if self.env == 'train':\n",
    "            dataset = datasets.mnist.MNIST(self.root, train=True, download=True)\n",
    "        elif self.env == 'test':\n",
    "            dataset = datasets.mnist.MNIST(self.root, train=False, download=True)\n",
    "\n",
    "        data_set = []\n",
    "\n",
    "        for idx, (im, label) in enumerate(dataset):\n",
    "            if idx % 10000 == 0:\n",
    "                print(f'Converting train image {idx}/{len(dataset)}')\n",
    "            im_array = np.array(np.squeeze(im))\n",
    "            # Assign a random label\n",
    "            ternary_label = np.random.randint(3)\n",
    "            # Color the image\n",
    "            if ternary_label == 0:\n",
    "                color = 'red'\n",
    "            elif ternary_label == 1:\n",
    "                color = 'green'\n",
    "            else:\n",
    "                color = 'blue'\n",
    "            colored_arr = color_grayscale_arr(im_array, color=color)\n",
    "            data_set.append((Image.fromarray(colored_arr), ternary_label, label))\n",
    "        path = Path(colored_mnist_dir)\n",
    "        path.mkdir(exist_ok=True)\n",
    "        torch.save(data_set, os.path.join(colored_mnist_dir, self.env + '.pt'))\n",
    "\n",
    "\n",
    "def plot_dataset_digits(dataset):\n",
    "    fig = plt.figure(figsize=(13, 8))\n",
    "    columns = 6\n",
    "    rows = 3\n",
    "    # ax enables access to manipulate each of subplots\n",
    "    ax = []\n",
    "    for i in range(columns * rows):\n",
    "        ind = np.random.randint(len(dataset))\n",
    "        img, color_label, digit_label = dataset[ind]\n",
    "        # create subplot and append to ax\n",
    "        ax.append(fig.add_subplot(rows, columns, i + 1))\n",
    "        ax[-1].set_title(\"labels: \" + str(color_label) + ', ' + str(digit_label))  # set title\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "    plt.show()  # finally, render the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haIQghuuPWC9"
   },
   "source": [
    "##  Input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6jIuY06tWOwv"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--batch_size',       type=int, default=128, help='Batch size (default=128)')\n",
    "parser.add_argument('--beta_rf',          type=float, default=1e-3, help='real/fake disc loss coefficient')\n",
    "parser.add_argument('--beta_ind',         type=float, default=1e-2, help='independence disc loss coefficient')\n",
    "parser.add_argument('--ae_lr',            type=float, default=1e-3, help='learning_rate for ae (default=1e-3)')\n",
    "parser.add_argument('--d_lr',             type=float, default=1e-4, help='learning_rate for discriminators optimizers (use 1e-4 if FLAGS.loss == ''cca'')')\n",
    "parser.add_argument(\"--min_lr\",           type=float,default=1e-5,help=\"Minimal learning rate\")\n",
    "parser.add_argument(\"--decay_step_size\",  type=int,default=45, help=\"LR decay step size\")\n",
    "parser.add_argument(\"--lr_decay_factor\",  type=float,default=0.1,help=\"LR decay factor\")\n",
    "parser.add_argument(\"--weight_decay\",     type=float, default=1e-4,help=\"l_2 weight penalty\")\n",
    "parser.add_argument(\"--n_epochs\",         type=int,default=50,help=\"Number of epochs without improvement before stopping\")\n",
    "parser.add_argument(\"--train_discs_every\",type=int,default=1, help=\"Train discriminators every this number of epochs\")\n",
    "parser.add_argument(\"--train_ae_every\",   type=int,default=5,help=\"Train autoencoder every this number of epochs\")\n",
    "parser.add_argument(\"--apply_r1_every\",   type=int,default=16, help=\"Apply R1 regularization every this number of epochs\")\n",
    "parser.add_argument(\"--label\",            type=str,default='digit', help=\"color | digit\")\n",
    "\n",
    "FLAGS = parser.parse_args(args=[])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3nABY8CQLsU"
   },
   "source": [
    "# Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f1e2253f7ecf402e9b1ebaaeb4ca3e6d",
      "07c6ea46c0914961aaa09c3169138c29",
      "84875cd4269846eb9c97d5edad9f6e99",
      "2cdb4e7d07004e52a7eb5aa19bc9b1c0",
      "f81cc9c50ede4eeca01be1485bbf525a",
      "0729bb3bb62a454e97b022937b43eccd",
      "5f2ae79e6e5b4cd7bcd441cb090b304a",
      "4bf5e5bac61f4074912e07b8835a9877",
      "43664a167f1441b5acc49a977ec9f3d8",
      "1cbd5b04b52240249d575aaabf32325b",
      "86753a841f9e42dc89ba8d92859d694d",
      "3ee9005f19e1487badbca2a0fb56e926",
      "97e68bbbded248b4847dd68e671f1639",
      "7797b219acb24972bd9d3fc73a5f02eb",
      "caf7c781afb144aea11f55d00803d579",
      "88e6ced06df54b78aa4c640bd166947a",
      "0b7288a520524de08369c8195f551b83",
      "ebeb44ef3da04e879145997deb565194",
      "085e1367ef574fde834e3b3374a3c44b",
      "be485c3ab8d34f139f99f2a74ec1d167",
      "96e083b76fa347bbb31a9deced69217a",
      "9f3f030bbbbc497cafeae60a9f15ecf6",
      "06afab79fa1c442d90f6cf5087f3e036",
      "468c17e39ec94dad8adf9afdde3d5031",
      "ef5a4fdd3b394448ab6c013ee57ef751",
      "1f5684552cce4dd7b7347b347dfd9111",
      "690f7236232647edac94410517b353ed",
      "4c26850f3d224fb6a41bb2a5aab7e6ab",
      "870765b396d846ea88a82b745e150ce8",
      "241b5ac4e4bf4299916008ccd6bacd0d",
      "ea9381ea8cc54a09ba0563329b392f01",
      "e78c22417bf544d0afd8544588f6e8c8",
      "981e8216f2a642709e891f6c50afa893",
      "4c325172ff6c4fa0a3bafb3c88cb30af",
      "d879e05d49e04c759891ff856176dbc4",
      "2735329eb8604d3985c1338f15dc1485",
      "3f5c2df058ed416aab452a372d86b932",
      "ae07b1b46cad458ebed30f7abfffe81a",
      "d4e76e837a67478da414b83715fcec77",
      "7f22e059a79941cd902bc6a8d69e526d",
      "c908669a28914cd4b35d533b24b1b609",
      "cb4818042a884cd79889ac3bd870d1d9",
      "453e3f74074541a5bf7dd3107126dbdb",
      "059f8d94a03b45f4a40821f86a5e4c9f"
     ]
    },
    "id": "bXfK53iJWSSE",
    "outputId": "3700d124-f51f-4fab-e2c8-27e8db051d52",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Colored MNIST\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e2253f7ecf402e9b1ebaaeb4ca3e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee9005f19e1487badbca2a0fb56e926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06afab79fa1c442d90f6cf5087f3e036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c325172ff6c4fa0a3bafb3c88cb30af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Converting train image 0/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train image 10000/60000\n",
      "Converting train image 20000/60000\n",
      "Converting train image 30000/60000\n",
      "Converting train image 40000/60000\n",
      "Converting train image 50000/60000\n",
      "Preparing Colored MNIST\n",
      "Converting train image 0/10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_mean = [.5, .5, .5]\n",
    "norm_std = [.5, .5, .5]\n",
    "\n",
    "def inverse_normalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def plot_dataset_digits(dataset):\n",
    "    fig = plt.figure(figsize=(13, 8))\n",
    "    columns = 6\n",
    "    rows = 3\n",
    "    ax = []\n",
    "  \n",
    "    for i in range(columns * rows):\n",
    "        ind = np.random.randint(len(dataset))  \n",
    "        img, color_label, digit_label = dataset[ind]\n",
    "        img = inverse_normalize(img, mean=norm_mean, std=norm_std)  \n",
    "        ax.append(fig.add_subplot(rows, columns, i + 1))\n",
    "        ax[-1].set_title(\"labels: \" + str(color_label) + ', ' + str(digit_label))  # set title\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=norm_mean,\n",
    "                         std=norm_std),\n",
    "    ])\n",
    "\n",
    "train_data = ColoredMNIST(root='./data', \n",
    "                          env='train',\n",
    "                          transform=transform)\n",
    "\n",
    "plot_dataset_digits(train_data) \n",
    "\n",
    "test_data = ColoredMNIST(root='./data', \n",
    "                          env='test',\n",
    "                          transform=transform)\n",
    "\n",
    "plot_dataset_digits(test_data) \n",
    "\n",
    "train_kwargs = {'batch_size': FLAGS.batch_size}\n",
    "test_kwargs = {'batch_size': FLAGS.batch_size}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, **test_kwargs)\n",
    "\n",
    "input_dim = 3 * 28 ** 2\n",
    "\n",
    "n_digit_classes = 10\n",
    "n_color_classes = 3\n",
    "if FLAGS.label == 'color':\n",
    "    n_classes = n_color_classes\n",
    "elif FLAGS.label == 'digit':\n",
    "    n_classes = n_digit_classes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwOynI4iQjld"
   },
   "source": [
    "# Functions required for modulation layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFX2sdyjQqHD"
   },
   "source": [
    "(taken from https://github.com/taesungp/swapping-autoencoder-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WZwwH-ZAbkqx"
   },
   "outputs": [],
   "source": [
    "def fused_leaky_relu(input, bias, negative_slope=0.2, scale=2 ** 0.5):\n",
    "    global use_custom_kernel\n",
    "    if use_custom_kernel:\n",
    "        return FusedLeakyReLUFunction.apply(input, bias, negative_slope, scale)\n",
    "    else:\n",
    "        dims = [1, -1] + [1] * (input.dim() - 2)\n",
    "        bias = bias.view(*dims)\n",
    "        return F.leaky_relu(input + bias, negative_slope) * scale\n",
    "\n",
    "class EqualLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, bias=True, bias_init=0, lr_mul=1, activation=None):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_dim, in_dim).div_(lr_mul))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_dim).fill_(bias_init))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.activation = activation\n",
    "        self.scale = (1 / math.sqrt(in_dim)) * lr_mul\n",
    "        self.lr_mul = lr_mul\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.activation:\n",
    "            if input.dim() > 2:\n",
    "                out = F.conv2d(input, self.weight[:, :, None, None] * self.scale)\n",
    "            else:\n",
    "                out = F.linear(input, self.weight * self.scale)\n",
    "            out = fused_leaky_relu(out, self.bias * self.lr_mul)\n",
    "        else:\n",
    "            if input.dim() > 2:\n",
    "                out = F.conv2d(input, self.weight[:, :, None, None] * self.scale, bias=self.bias * self.lr_mul)\n",
    "            else:\n",
    "                out = F.linear(input, self.weight * self.scale, bias=self.bias * self.lr_mul)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'{self.__class__.__name__}({self.weight.shape[1]}, {self.weight.shape[0]})')\n",
    "\n",
    "class GeneratorModulation(torch.nn.Module):\n",
    "    def __init__(self, styledim, outch):\n",
    "        super().__init__()\n",
    "        self.scale = EqualLinear(styledim, outch)\n",
    "        self.bias = EqualLinear(styledim, outch)\n",
    "\n",
    "    def forward(self, x, style):\n",
    "        if style.ndimension() <= 2:\n",
    "            return x * (1 * self.scale(style)[:, :, None, None]) + self.bias(style)[:, :, None, None]\n",
    "        else:\n",
    "            style = F.interpolate(style, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n",
    "            return x * (1 * self.scale(style)) + self.bias(style)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYp2TgwrQ8Ls"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-puZ_hVWgNd",
    "outputId": "991c4233-ee59-4cf8-d5f8-b6156ae5a8a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RF_Discriminator(\n",
       "  (conv1): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "  (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation): ReLU()\n",
       "  (fc1): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):   \n",
    "    def __init__(self, norm_layer=nn.BatchNorm2d):\n",
    "        super(Encoder, self).__init__()\n",
    "        use_bias = norm_layer != nn.BatchNorm2d\n",
    "        # conv layer (depth from 3 --> 16), 3x3 kernels\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, stride=2, bias=use_bias)  \n",
    "        # conv layer (depth from 16 --> 32), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, stride=2, bias=use_bias)\n",
    "        # conv layer (depth from 32 --> 64), 7x7 kernels\n",
    "        self.conv3 = nn.Conv2d(32, 64, 7, bias=use_bias)\n",
    "        self.norm1 = norm_layer(16)\n",
    "        self.norm2 = norm_layer(32)\n",
    "        self.norm3 = norm_layer(64)\n",
    "        self.activation = nn.ReLU()\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.norm1(self.conv1(x)))\n",
    "        x = self.activation(self.norm2(self.conv2(x)))\n",
    "        x = self.activation(self.norm3(self.conv3(x)))\n",
    "        code = x\n",
    "        return code\n",
    "        \n",
    "class Decoder(nn.Module):   \n",
    "    def __init__(self, norm_layer=nn.InstanceNorm2d, label_embedding_dim=64):\n",
    "        super(Decoder, self).__init__()\n",
    "        use_bias = norm_layer != nn.BatchNorm2d\n",
    "        self.activation = nn.ReLU()\n",
    "        self.label_embeddings = nn.Embedding(n_classes, embedding_dim=label_embedding_dim)\n",
    "        self.modulation1 = GeneratorModulation(styledim=label_embedding_dim, outch=64)\n",
    "        self.t_conv1 = nn.ConvTranspose2d(64 , 32, 7, bias=use_bias)\n",
    "        self.modulation2 = GeneratorModulation(styledim=label_embedding_dim, outch=32)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(32, 16, 2, stride=2, bias=use_bias)\n",
    "        self.modulation3 = GeneratorModulation(styledim=label_embedding_dim, outch=16)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(16, 3, 2, stride=2)\n",
    "        self.norm1 = norm_layer(32)\n",
    "        self.norm2 = norm_layer(16)\n",
    "                \n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Style is applied via modulation before every layer\n",
    "        \"\"\"\n",
    "        style = self.label_embeddings(y)\n",
    "        # modulate x\n",
    "        x = self.modulation1(x, style)\n",
    "        # add transpose conv layers, with relu activation function\n",
    "        x = self.activation(self.norm1(self.t_conv1(x)))\n",
    "        # modulate x\n",
    "        x = self.modulation2(x, style)\n",
    "        x = self.activation(self.norm2(self.t_conv2(x)))\n",
    "        # modulate x\n",
    "        x = self.modulation3(x, style)\n",
    "        x = self.t_conv3(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        return x\n",
    "\n",
    "class Ind_Discriminator(nn.Module):   \n",
    "    def __init__(self, norm_layer=nn.BatchNorm1d):\n",
    "        super(Ind_Discriminator, self).__init__()\n",
    "        self.activation=nn.LeakyReLU()\n",
    "        self.out_dim=n_classes\n",
    "        use_bias = norm_layer != nn.BatchNorm1d\n",
    "         # Layers\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(64, 128, bias=use_bias),\n",
    "            norm_layer(128),\n",
    "            self.activation,\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(128, 128, bias=use_bias),\n",
    "            norm_layer(128),\n",
    "            self.activation,\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(nn.Linear(128, self.out_dim))\n",
    "             \n",
    "    def forward(self, code):\n",
    "        \"\"\"\n",
    "        Code goes through standard forward pass, model outputs mapped code and label embedding\n",
    "        \"\"\"\n",
    "        x = torch.flatten(code, 1)\n",
    "        x = self.layer1(x)\n",
    "        x = x + self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x \n",
    "\n",
    "class RF_Discriminator(nn.Module):   \n",
    "    def __init__(self, norm_layer=nn.BatchNorm2d):\n",
    "        \n",
    "        super(RF_Discriminator, self).__init__()\n",
    "        use_bias = norm_layer != nn.BatchNorm2d\n",
    "        self.label_embeddings = nn.Parameter(torch.randn(n_classes, 1, 28, 28))\n",
    "        # conv layer (depth from 3 --> 16), 3x3 kernels\n",
    "        self.conv1 = nn.Conv2d(4, 16, 3, padding=1, stride=2, bias=use_bias)  \n",
    "        # conv layer (depth from 16 --> 32), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, stride=2, bias=use_bias)\n",
    "        # conv layer (depth from 32 --> 64), 7x7 kernels\n",
    "        self.conv3 = nn.Conv2d(32, 64, 7, bias=use_bias)\n",
    "        self.norm1 = norm_layer(16)\n",
    "        self.norm2 = norm_layer(32)\n",
    "        self.norm3 = norm_layer(64)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Standard forward\n",
    "        \"\"\"\n",
    "        o = self.label_embeddings[y]\n",
    "        x = torch.cat([x, o], dim=1)\n",
    "        x = self.activation(self.norm1(self.conv1(x)))\n",
    "        x = self.activation(self.norm2(self.conv2(x)))\n",
    "        x = self.activation(self.norm3(self.conv3(x)))\n",
    "        x = nn.Flatten()(x)\n",
    "        out = torch.sigmoid(self.fc1(x))\n",
    "        return out\n",
    "    \n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "ind_discriminator = Ind_Discriminator()\n",
    "rf_discriminator = RF_Discriminator()\n",
    "       \n",
    "encoder.to(device=device)\n",
    "decoder.to(device=device)\n",
    "ind_discriminator.to(device=device)\n",
    "rf_discriminator.to(device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rj6eWwdRPdO"
   },
   "source": [
    "# Loss criterions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7qWo4ap0W0yz"
   },
   "outputs": [],
   "source": [
    "recon_criterion = nn.BCELoss()\n",
    "rf_criterion = nn.BCELoss()\n",
    "ind_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def indep_loss(logits, y, should_be_dependent=True):\n",
    "    if should_be_dependent:\n",
    "        return ind_criterion(logits, y)  \n",
    "    else: \n",
    "        return -ind_criterion(logits, y) \n",
    "\n",
    "def gan_loss (x, should_be_classified_as_real=True):\n",
    "    x = torch.clamp(x, min=1e-7, max=1 - 1e-7)\n",
    "    if should_be_classified_as_real:\n",
    "        label = torch.full((x.size(0), 1), 1., dtype=torch.float, device=device)\n",
    "    else: \n",
    "        label = torch.full((x.size(0), 1), 0., dtype=torch.float, device=device)\n",
    "    return rf_criterion(x, label)\n",
    "\n",
    "def compute_rf_R1_loss(model, x, y):\n",
    "    x = x.detach().clone()\n",
    "    x.requires_grad_()\n",
    "    pred_real = model(x, y).sum()\n",
    "    grad_real, = torch.autograd.grad(\n",
    "        outputs=pred_real,\n",
    "        inputs=[x],\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "    grad_real2 = grad_real.pow(2)\n",
    "    dims = list(range(1, grad_real2.ndim))\n",
    "    grad_penalty = grad_real2.sum(dims) * 0.5\n",
    "\n",
    "    return grad_penalty.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA7FR_QnRY71"
   },
   "source": [
    "# Optimizers and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i1PiDk15W-r-"
   },
   "outputs": [],
   "source": [
    "def lambda_rule(epoch) -> float:\n",
    "  \"\"\" stepwise learning rate calculator \"\"\"\n",
    "  exponent = int(np.floor((epoch + 1) / FLAGS.decay_step_size))\n",
    "  return np.power(FLAGS.lr_decay_factor, exponent)\n",
    "\n",
    "def update_lr(optim, scheduler):\n",
    "  \"\"\" Learning rate updater \"\"\"\n",
    "  scheduler.step()\n",
    "  lr = optim.param_groups[0]['lr']\n",
    "  if lr < FLAGS.min_lr:\n",
    "      optim.param_groups[0]['lr'] = FLAGS.min_lr\n",
    "      lr = optim.param_groups[0]['lr']\n",
    "  print('Learning rate = %.7f' % lr) \n",
    "\n",
    "ae_optim = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()),\n",
    "                            lr=FLAGS.ae_lr, \n",
    "                            betas=(0.5, 0.999),\n",
    "                            weight_decay=FLAGS.weight_decay)\n",
    "\n",
    "ind_disc_optim = torch.optim.Adam(ind_discriminator.parameters(), \n",
    "                                 lr=FLAGS.d_lr, \n",
    "                                 betas=(0.5, 0.999),\n",
    "                                 weight_decay=FLAGS.weight_decay) \n",
    "\n",
    "rf_disc_optim = torch.optim.Adam(rf_discriminator.parameters(), \n",
    "                                 lr=FLAGS.d_lr, \n",
    "                                 betas=(0.5, 0.999),\n",
    "                                 weight_decay=FLAGS.weight_decay)\n",
    "\n",
    "ae_sched = lr_scheduler.LambdaLR(ae_optim, lr_lambda=lambda_rule) \n",
    "\n",
    "ind_disc_sched = lr_scheduler.LambdaLR(ind_disc_optim, lr_lambda=lambda_rule)  \n",
    "\n",
    "rf_disc_sched = lr_scheduler.LambdaLR(rf_disc_optim, lr_lambda=lambda_rule)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h4J7dMbRqXU"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ifi0zO-nXAvS"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    for epoch in range(FLAGS.n_epochs):\n",
    "        \n",
    "        encoder.train(True) \n",
    "        decoder.train(True) \n",
    "        ind_discriminator.train(True)    \n",
    "        rf_discriminator.train(True)    \n",
    "        \n",
    "        recon_losses = []\n",
    "        indep_losses = []\n",
    "        rf_losses = []\n",
    "        \n",
    "\n",
    "        for step, (batch_x, batch_color, batch_digit) in enumerate(train_loader):\n",
    "            \n",
    "            if FLAGS.label == 'color':\n",
    "                batch_y = batch_color\n",
    "            elif FLAGS.label == 'digit':\n",
    "                batch_y = batch_digit\n",
    "            \n",
    "            batch_x = batch_x.float().to(device=device)\n",
    "            batch_y = batch_y.to(device=device)\n",
    "            \n",
    "            if step % FLAGS.train_discs_every == 0:\n",
    "                ind_discriminator.zero_grad()\n",
    "                rf_discriminator.zero_grad()\n",
    "                label = nn.functional.one_hot(batch_y, num_classes=n_classes).float()\n",
    "\n",
    "                code = encoder(batch_x) \n",
    "                \n",
    "                logits = ind_discriminator(code.detach())\n",
    "                ind_discriminator_loss = indep_loss(logits, batch_y, should_be_dependent=True) \n",
    "                    \n",
    "                code = encoder(batch_x)\n",
    "                n1 = batch_x.size(0) // 2\n",
    "                code_for_recon = code[:n1]\n",
    "                batch_y_for_recon = batch_y[:n1]\n",
    "\n",
    "                code_for_swap = code[n1:]\n",
    "                batch_y_for_swap = batch_y[n1:]\n",
    "                p = np.random.permutation(batch_y_for_swap.size(0))\n",
    "                batch_y_for_swap = batch_y_for_swap[p]\n",
    "\n",
    "                recon = decoder(code_for_recon, batch_y_for_recon)\n",
    "                swap = decoder(code_for_swap, batch_y_for_swap)\n",
    "                \n",
    "                rf_disc_real_out = rf_discriminator(batch_x, batch_y)\n",
    "                rf_disc_recon_out = rf_discriminator(recon.detach(), batch_y_for_recon)\n",
    "                rf_disc_swap_out = rf_discriminator(swap.detach(), batch_y_for_swap)\n",
    "\n",
    "                recon_loss = recon_criterion((recon + 1.) / 2., (batch_x[:n1] + 1.) / 2.) \n",
    "                rf_loss_real = gan_loss(rf_disc_real_out, should_be_classified_as_real=True)\n",
    "                rf_loss_fake_r = gan_loss(rf_disc_recon_out, should_be_classified_as_real=False)\n",
    "                rf_loss_fake_s = gan_loss(rf_disc_swap_out, should_be_classified_as_real=False)\n",
    "                rf_discriminator_loss = rf_loss_real + 0.5 * rf_loss_fake_r + .5 * rf_loss_fake_s\n",
    "\n",
    "                ind_discriminator_loss.backward()\n",
    "                rf_discriminator_loss.backward()\n",
    "\n",
    "                ind_disc_optim.step()\n",
    "                rf_disc_optim.step() \n",
    "            \n",
    "            if step % FLAGS.apply_r1_every == 0:\n",
    "                # r1 losses \n",
    "                rf_discriminator.zero_grad()\n",
    "                rf_disc_r1_loss = compute_rf_R1_loss(rf_discriminator, batch_x, batch_y)\n",
    "                rf_disc_r1_loss.backward()\n",
    "                rf_disc_optim.step()\n",
    "            \n",
    "            if step % FLAGS.train_ae_every == 0:\n",
    "                # train AE\n",
    "                encoder.zero_grad()\n",
    "                decoder.zero_grad()\n",
    "                \n",
    "                label = nn.functional.one_hot(batch_y, num_classes=n_classes).float()\n",
    "\n",
    "                code = encoder(batch_x)\n",
    "                logits = ind_discriminator(code)\n",
    "                independence_loss = indep_loss(logits, batch_y, should_be_dependent=False) \n",
    "                code = encoder(batch_x)\n",
    "                n1 = batch_x.size(0) // 2\n",
    "                code_for_recon = code[:n1]\n",
    "                batch_y_for_recon = batch_y[:n1]\n",
    "\n",
    "                code_for_swap = code[n1:]\n",
    "                batch_y_for_swap = batch_y[n1:]\n",
    "                p = np.random.permutation(batch_y_for_swap.size(0))\n",
    "                batch_y_for_swap = batch_y_for_swap[p]\n",
    "\n",
    "                recon = decoder(code_for_recon, batch_y_for_recon)\n",
    "                swap = decoder(code_for_swap, batch_y_for_swap)\n",
    "                \n",
    "                rf_disc_recon_out = rf_discriminator(recon, batch_y_for_recon)\n",
    "                rf_disc_swap_out = rf_discriminator(swap, batch_y_for_swap)\n",
    "                \n",
    "                recon_loss = recon_criterion((recon + 1.) / 2., (batch_x[:n1] + 1.) / 2.)   \n",
    "                rf_loss_fake_r = gan_loss(rf_disc_recon_out, should_be_classified_as_real=True)\n",
    "                rf_loss_fake_s = gan_loss(rf_disc_swap_out, should_be_classified_as_real=True)\n",
    "                rf_loss = rf_loss_fake_r + rf_loss_fake_s\n",
    "                \n",
    "                                \n",
    "                ae_loss = recon_loss + FLAGS.beta_ind * independence_loss + FLAGS.beta_rf * rf_loss\n",
    "                ae_loss.backward()\n",
    "                ae_optim.step()\n",
    "                \n",
    "                recon_losses.append(recon_loss.item())\n",
    "                indep_losses.append(independence_loss.item())\n",
    "                rf_losses.append(rf_loss.item())\n",
    "                \n",
    "                if step % 10 == 0:\n",
    "                    print('Epoch: {}/{}, Step: {}'.format(epoch + 1, FLAGS.n_epochs, step))\n",
    "                    print('Recon_loss: {:.3f}, indep loss:  {:.3f}, rf loss: {:.3f}'.format(np.mean(recon_losses),\n",
    "                                                                                              np.mean(indep_losses),\n",
    "                                                                                              np.mean(rf_losses)))\n",
    "                    \n",
    "                    print('Learning rate = %.7f' % ae_optim.param_groups[0]['lr'])        \n",
    "        \n",
    "    print('Finished training ')\n",
    "    \n",
    "def test():    \n",
    "    print('Running test')\n",
    "    encoder.train(False) \n",
    "    decoder.train(False) \n",
    "    ind_discriminator.train(False)    \n",
    "    rf_discriminator.train(False) \n",
    "    \n",
    "    test_recon_losses = []\n",
    "    test_indep_losses = []\n",
    "    test_rf_losses = []\n",
    "   \n",
    "    for (batch_x, batch_color, batch_digit) in test_loader:\n",
    "        if FLAGS.label == 'color':\n",
    "            batch_y = batch_color\n",
    "        elif FLAGS.label == 'digit':\n",
    "            batch_y = batch_digit\n",
    "            \n",
    "        batch_x = batch_x.float().to(device=device)\n",
    "        batch_y = batch_y.to(device=device)\n",
    "              \n",
    "        label = nn.functional.one_hot(batch_y, num_classes=n_classes).float()\n",
    "        code = encoder(batch_x)\n",
    "        logits = ind_discriminator(code)\n",
    "        independence_loss = indep_loss(logits, batch_y, should_be_dependent=False) \n",
    "        \n",
    "        code = encoder(batch_x)\n",
    "        n1 = batch_x.size(0) // 2\n",
    "        code_for_recon = code[:n1]\n",
    "        batch_y_for_recon = batch_y[:n1]\n",
    "\n",
    "        code_for_swap = code[n1:]\n",
    "        batch_y_for_swap = batch_y[n1:]\n",
    "        p = np.random.permutation(batch_y_for_swap.size(0))\n",
    "        batch_y_for_swap = batch_y_for_swap[p]\n",
    "\n",
    "        recon = decoder(code_for_recon, batch_y_for_recon)\n",
    "        swap = decoder(code_for_swap, batch_y_for_swap)\n",
    "        \n",
    "        rf_disc_recon_out = rf_discriminator(recon, batch_y_for_recon)\n",
    "        rf_disc_swap_out = rf_discriminator(swap, batch_y_for_swap)\n",
    "\n",
    "        recon_loss = recon_criterion((recon + 1.) / 2., (batch_x[:n1] + 1.) / 2.)      \n",
    "        rf_loss_fake_r = gan_loss(rf_disc_recon_out, should_be_classified_as_real=True)\n",
    "        rf_loss_fake_s = gan_loss(rf_disc_swap_out, should_be_classified_as_real=True)\n",
    "        rf_loss = rf_loss_fake_r + rf_loss_fake_s\n",
    "            \n",
    "        test_recon_losses.append(recon_loss.item())\n",
    "        test_indep_losses.append(independence_loss.item())\n",
    "        test_rf_losses.append(rf_loss.item())\n",
    "         \n",
    "    test_recon_loss = np.mean(test_recon_losses)\n",
    "    test_indep_loss = np.mean(test_indep_losses)\n",
    "    test_rf_loss = np.mean(test_rf_losses)\n",
    "        \n",
    "    test_loss = test_recon_loss + test_indep_loss + test_rf_loss\n",
    "       \n",
    "    print('Test results: ')\n",
    "    print('Recon_loss: {:.3f}, indep loss:  {:.3f}, rf loss:  {:.3f}'.format(test_recon_loss,\n",
    "                                                                             test_indep_loss,\n",
    "                                                                             test_rf_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooiSzhnpR5Tt"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Je3n3ijDXacf"
   },
   "outputs": [],
   "source": [
    "def analyze_data():\n",
    "       \n",
    "    encoder.train(False) \n",
    "    decoder.train(False) \n",
    "    ind_discriminator.train(False) \n",
    "    rf_discriminator.train(False) \n",
    "    \n",
    "    batch_x = []\n",
    "    batch_color = []\n",
    "    batch_digit = []\n",
    "    inds = np.random.choice(range(len(test_data)), n_classes + 2)\n",
    "    for ind in inds:\n",
    "        batch_x.append(test_data[ind][0])\n",
    "        batch_color.append(test_data[ind][1])\n",
    "        batch_digit.append(test_data[ind][2])\n",
    "    if FLAGS.label == 'color':\n",
    "        batch_y = batch_color\n",
    "    elif FLAGS.label == 'digit':\n",
    "        batch_y = batch_digit\n",
    "    batch_x = torch.stack(batch_x, 0)\n",
    "    batch_y = torch.tensor(batch_y)\n",
    "    \n",
    "    batch_x = batch_x.float().to(device=device)\n",
    "    batch_y = batch_y.to(device=device)\n",
    "        \n",
    "    label = nn.functional.one_hot(batch_y, num_classes=n_classes).float()\n",
    "    code = encoder(batch_x)\n",
    "    recon = decoder(code, batch_y)\n",
    "\n",
    "    # Modification of label \n",
    "    fig, axs = plt.subplots(n_classes + 2, n_classes + 2)\n",
    "    axs[0, 0].set_title('org', size=8)\n",
    "    axs[0, 1].set_title('recon', size=8)\n",
    "    for i in range(n_classes + 2):\n",
    "        img = inverse_normalize(batch_x[i - 2].cpu(), mean=norm_mean, std=norm_std) \n",
    "        axs[i, 0].imshow(img.reshape(3, 28, 28).permute(1, 2, 0))\n",
    "        axs[i, 0].get_xaxis().set_visible(False)\n",
    "        axs[i, 0].get_yaxis().set_visible(False)\n",
    "        axs[i, 1].imshow(recon[i - 2].cpu().detach().reshape(3, 28, 28).permute(1, 2, 0))\n",
    "        axs[i, 1].get_xaxis().set_visible(False)\n",
    "        axs[i, 1].get_yaxis().set_visible(False)\n",
    "        code1 = code[i - 2]\n",
    "        for j in range(2, n_classes + 2):\n",
    "            new_label = torch.tensor(j - 2)\n",
    "            new_label = new_label.to(device=device)                    \n",
    "            new_recon = decoder(torch.unsqueeze(code1, 0), torch.unsqueeze(new_label, 0))\n",
    "            img = inverse_normalize(new_recon[0].cpu().detach(), mean=norm_mean, std=norm_std) \n",
    "            axs[i, j].imshow(img.reshape(3, 28, 28).permute(1, 2, 0))\n",
    "            axs[i, j].get_xaxis().set_visible(False)\n",
    "            axs[i, j].get_yaxis().set_visible(False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zqDWIBv3XgMX",
    "outputId": "dfbcf76e-e206-4e02-8ff9-e114eb092930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 270\n",
      "Recon_loss: 0.061, indep loss:  -2.202, rf loss: 4.431\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 280\n",
      "Recon_loss: 0.061, indep loss:  -2.203, rf loss: 4.439\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 290\n",
      "Recon_loss: 0.061, indep loss:  -2.204, rf loss: 4.448\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 300\n",
      "Recon_loss: 0.061, indep loss:  -2.204, rf loss: 4.460\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 310\n",
      "Recon_loss: 0.061, indep loss:  -2.205, rf loss: 4.451\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 320\n",
      "Recon_loss: 0.061, indep loss:  -2.205, rf loss: 4.444\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 330\n",
      "Recon_loss: 0.060, indep loss:  -2.205, rf loss: 4.434\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 340\n",
      "Recon_loss: 0.060, indep loss:  -2.205, rf loss: 4.437\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 350\n",
      "Recon_loss: 0.060, indep loss:  -2.206, rf loss: 4.445\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 360\n",
      "Recon_loss: 0.060, indep loss:  -2.207, rf loss: 4.455\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 370\n",
      "Recon_loss: 0.061, indep loss:  -2.207, rf loss: 4.461\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 380\n",
      "Recon_loss: 0.061, indep loss:  -2.208, rf loss: 4.469\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 390\n",
      "Recon_loss: 0.061, indep loss:  -2.210, rf loss: 4.474\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 400\n",
      "Recon_loss: 0.061, indep loss:  -2.209, rf loss: 4.483\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 410\n",
      "Recon_loss: 0.061, indep loss:  -2.210, rf loss: 4.494\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 420\n",
      "Recon_loss: 0.060, indep loss:  -2.211, rf loss: 4.495\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 430\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.502\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 440\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.501\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 450\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.502\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 15/50, Step: 460\n",
      "Recon_loss: 0.060, indep loss:  -2.213, rf loss: 4.511\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 0\n",
      "Recon_loss: 0.059, indep loss:  -2.142, rf loss: 4.837\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 10\n",
      "Recon_loss: 0.059, indep loss:  -2.203, rf loss: 4.495\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 20\n",
      "Recon_loss: 0.059, indep loss:  -2.214, rf loss: 4.551\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 30\n",
      "Recon_loss: 0.058, indep loss:  -2.207, rf loss: 4.569\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 40\n",
      "Recon_loss: 0.059, indep loss:  -2.207, rf loss: 4.521\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 50\n",
      "Recon_loss: 0.059, indep loss:  -2.208, rf loss: 4.535\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 60\n",
      "Recon_loss: 0.058, indep loss:  -2.208, rf loss: 4.580\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 70\n",
      "Recon_loss: 0.058, indep loss:  -2.205, rf loss: 4.573\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 80\n",
      "Recon_loss: 0.059, indep loss:  -2.205, rf loss: 4.607\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 90\n",
      "Recon_loss: 0.059, indep loss:  -2.200, rf loss: 4.625\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 100\n",
      "Recon_loss: 0.059, indep loss:  -2.199, rf loss: 4.646\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 110\n",
      "Recon_loss: 0.059, indep loss:  -2.200, rf loss: 4.672\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 120\n",
      "Recon_loss: 0.059, indep loss:  -2.204, rf loss: 4.647\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 130\n",
      "Recon_loss: 0.059, indep loss:  -2.205, rf loss: 4.651\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 140\n",
      "Recon_loss: 0.059, indep loss:  -2.203, rf loss: 4.645\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 150\n",
      "Recon_loss: 0.060, indep loss:  -2.205, rf loss: 4.633\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 160\n",
      "Recon_loss: 0.060, indep loss:  -2.208, rf loss: 4.646\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 170\n",
      "Recon_loss: 0.060, indep loss:  -2.210, rf loss: 4.653\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 180\n",
      "Recon_loss: 0.060, indep loss:  -2.213, rf loss: 4.654\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 190\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 200\n",
      "Recon_loss: 0.060, indep loss:  -2.211, rf loss: 4.678\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 210\n",
      "Recon_loss: 0.060, indep loss:  -2.213, rf loss: 4.689\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 220\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.699\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 230\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.705\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 240\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.708\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 250\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.709\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 260\n",
      "Recon_loss: 0.060, indep loss:  -2.213, rf loss: 4.700\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 270\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.705\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 280\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.705\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 290\n",
      "Recon_loss: 0.060, indep loss:  -2.211, rf loss: 4.713\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 300\n",
      "Recon_loss: 0.060, indep loss:  -2.210, rf loss: 4.726\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 310\n",
      "Recon_loss: 0.060, indep loss:  -2.210, rf loss: 4.722\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 320\n",
      "Recon_loss: 0.060, indep loss:  -2.211, rf loss: 4.723\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 330\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.712\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 340\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.709\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 350\n",
      "Recon_loss: 0.060, indep loss:  -2.210, rf loss: 4.716\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 360\n",
      "Recon_loss: 0.060, indep loss:  -2.211, rf loss: 4.719\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 370\n",
      "Recon_loss: 0.060, indep loss:  -2.210, rf loss: 4.721\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 380\n",
      "Recon_loss: 0.060, indep loss:  -2.210, rf loss: 4.724\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 390\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.728\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 400\n",
      "Recon_loss: 0.060, indep loss:  -2.211, rf loss: 4.736\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 410\n",
      "Recon_loss: 0.060, indep loss:  -2.212, rf loss: 4.744\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 420\n",
      "Recon_loss: 0.059, indep loss:  -2.213, rf loss: 4.746\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 430\n",
      "Recon_loss: 0.059, indep loss:  -2.214, rf loss: 4.750\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 440\n",
      "Recon_loss: 0.059, indep loss:  -2.215, rf loss: 4.745\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 450\n",
      "Recon_loss: 0.059, indep loss:  -2.215, rf loss: 4.742\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 16/50, Step: 460\n",
      "Recon_loss: 0.059, indep loss:  -2.216, rf loss: 4.746\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 0\n",
      "Recon_loss: 0.058, indep loss:  -2.170, rf loss: 4.469\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 10\n",
      "Recon_loss: 0.058, indep loss:  -2.213, rf loss: 4.415\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 20\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 4.631\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 30\n",
      "Recon_loss: 0.057, indep loss:  -2.215, rf loss: 4.758\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 40\n",
      "Recon_loss: 0.058, indep loss:  -2.208, rf loss: 4.731\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 50\n",
      "Recon_loss: 0.058, indep loss:  -2.205, rf loss: 4.756\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 60\n",
      "Recon_loss: 0.057, indep loss:  -2.205, rf loss: 4.815\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 70\n",
      "Recon_loss: 0.057, indep loss:  -2.201, rf loss: 4.833\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 80\n",
      "Recon_loss: 0.058, indep loss:  -2.202, rf loss: 4.872\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 90\n",
      "Recon_loss: 0.058, indep loss:  -2.199, rf loss: 4.888\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 100\n",
      "Recon_loss: 0.058, indep loss:  -2.197, rf loss: 4.911\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 110\n",
      "Recon_loss: 0.058, indep loss:  -2.199, rf loss: 4.932\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 120\n",
      "Recon_loss: 0.058, indep loss:  -2.202, rf loss: 4.919\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 130\n",
      "Recon_loss: 0.058, indep loss:  -2.202, rf loss: 4.920\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 140\n",
      "Recon_loss: 0.058, indep loss:  -2.201, rf loss: 4.909\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 150\n",
      "Recon_loss: 0.059, indep loss:  -2.202, rf loss: 4.907\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 160\n",
      "Recon_loss: 0.059, indep loss:  -2.205, rf loss: 4.923\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 170\n",
      "Recon_loss: 0.059, indep loss:  -2.207, rf loss: 4.942\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 180\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.944\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 190\n",
      "Recon_loss: 0.059, indep loss:  -2.208, rf loss: 4.948\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 200\n",
      "Recon_loss: 0.059, indep loss:  -2.207, rf loss: 4.966\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 210\n",
      "Recon_loss: 0.059, indep loss:  -2.208, rf loss: 4.974\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 220\n",
      "Recon_loss: 0.059, indep loss:  -2.207, rf loss: 4.978\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 230\n",
      "Recon_loss: 0.059, indep loss:  -2.207, rf loss: 4.985\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 240\n",
      "Recon_loss: 0.059, indep loss:  -2.208, rf loss: 4.982\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 250\n",
      "Recon_loss: 0.059, indep loss:  -2.209, rf loss: 4.984\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 260\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.970\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 270\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.971\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 280\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.979\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 290\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.980\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 300\n",
      "Recon_loss: 0.059, indep loss:  -2.209, rf loss: 4.994\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 310\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.981\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 320\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.982\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 330\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.971\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 340\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.969\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 350\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.968\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 360\n",
      "Recon_loss: 0.059, indep loss:  -2.211, rf loss: 4.969\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 370\n",
      "Recon_loss: 0.059, indep loss:  -2.210, rf loss: 4.964\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 380\n",
      "Recon_loss: 0.059, indep loss:  -2.211, rf loss: 4.967\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 390\n",
      "Recon_loss: 0.059, indep loss:  -2.212, rf loss: 4.970\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 400\n",
      "Recon_loss: 0.059, indep loss:  -2.211, rf loss: 4.979\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 410\n",
      "Recon_loss: 0.059, indep loss:  -2.212, rf loss: 4.987\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 420\n",
      "Recon_loss: 0.059, indep loss:  -2.213, rf loss: 4.987\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 430\n",
      "Recon_loss: 0.058, indep loss:  -2.213, rf loss: 4.989\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 440\n",
      "Recon_loss: 0.058, indep loss:  -2.213, rf loss: 4.985\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 450\n",
      "Recon_loss: 0.058, indep loss:  -2.213, rf loss: 4.983\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 17/50, Step: 460\n",
      "Recon_loss: 0.058, indep loss:  -2.214, rf loss: 4.988\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 0\n",
      "Recon_loss: 0.058, indep loss:  -2.137, rf loss: 4.899\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 10\n",
      "Recon_loss: 0.058, indep loss:  -2.199, rf loss: 4.820\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 20\n",
      "Recon_loss: 0.057, indep loss:  -2.199, rf loss: 4.931\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 30\n",
      "Recon_loss: 0.056, indep loss:  -2.195, rf loss: 5.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 40\n",
      "Recon_loss: 0.057, indep loss:  -2.196, rf loss: 5.009\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 50\n",
      "Recon_loss: 0.057, indep loss:  -2.200, rf loss: 5.030\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 60\n",
      "Recon_loss: 0.057, indep loss:  -2.207, rf loss: 5.088\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 70\n",
      "Recon_loss: 0.056, indep loss:  -2.207, rf loss: 5.100\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 80\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.108\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 90\n",
      "Recon_loss: 0.057, indep loss:  -2.208, rf loss: 5.144\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 100\n",
      "Recon_loss: 0.057, indep loss:  -2.208, rf loss: 5.173\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 110\n",
      "Recon_loss: 0.057, indep loss:  -2.209, rf loss: 5.208\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 120\n",
      "Recon_loss: 0.057, indep loss:  -2.212, rf loss: 5.224\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 130\n",
      "Recon_loss: 0.057, indep loss:  -2.212, rf loss: 5.234\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 140\n",
      "Recon_loss: 0.058, indep loss:  -2.210, rf loss: 5.234\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 150\n",
      "Recon_loss: 0.058, indep loss:  -2.210, rf loss: 5.239\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 160\n",
      "Recon_loss: 0.058, indep loss:  -2.212, rf loss: 5.251\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 170\n",
      "Recon_loss: 0.058, indep loss:  -2.213, rf loss: 5.265\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 180\n",
      "Recon_loss: 0.058, indep loss:  -2.216, rf loss: 5.270\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 190\n",
      "Recon_loss: 0.058, indep loss:  -2.217, rf loss: 5.280\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 200\n",
      "Recon_loss: 0.058, indep loss:  -2.215, rf loss: 5.297\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 210\n",
      "Recon_loss: 0.058, indep loss:  -2.217, rf loss: 5.308\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 220\n",
      "Recon_loss: 0.058, indep loss:  -2.216, rf loss: 5.308\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 230\n",
      "Recon_loss: 0.058, indep loss:  -2.218, rf loss: 5.315\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 240\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.312\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 250\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.322\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 260\n",
      "Recon_loss: 0.058, indep loss:  -2.222, rf loss: 5.316\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 270\n",
      "Recon_loss: 0.058, indep loss:  -2.222, rf loss: 5.328\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 280\n",
      "Recon_loss: 0.058, indep loss:  -2.221, rf loss: 5.341\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 290\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.352\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 300\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.364\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 310\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.358\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 320\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.362\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 330\n",
      "Recon_loss: 0.058, indep loss:  -2.219, rf loss: 5.345\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 340\n",
      "Recon_loss: 0.058, indep loss:  -2.218, rf loss: 5.341\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 350\n",
      "Recon_loss: 0.058, indep loss:  -2.219, rf loss: 5.343\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 360\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.344\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 370\n",
      "Recon_loss: 0.058, indep loss:  -2.219, rf loss: 5.339\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 380\n",
      "Recon_loss: 0.058, indep loss:  -2.219, rf loss: 5.337\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 390\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.334\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 400\n",
      "Recon_loss: 0.058, indep loss:  -2.219, rf loss: 5.337\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 410\n",
      "Recon_loss: 0.058, indep loss:  -2.219, rf loss: 5.342\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 420\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.342\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 430\n",
      "Recon_loss: 0.058, indep loss:  -2.220, rf loss: 5.343\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 440\n",
      "Recon_loss: 0.058, indep loss:  -2.221, rf loss: 5.333\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 450\n",
      "Recon_loss: 0.058, indep loss:  -2.221, rf loss: 5.328\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 18/50, Step: 460\n",
      "Recon_loss: 0.058, indep loss:  -2.222, rf loss: 5.329\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 0\n",
      "Recon_loss: 0.057, indep loss:  -2.183, rf loss: 4.965\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 10\n",
      "Recon_loss: 0.057, indep loss:  -2.226, rf loss: 4.932\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 20\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.034\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 30\n",
      "Recon_loss: 0.056, indep loss:  -2.219, rf loss: 5.142\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 40\n",
      "Recon_loss: 0.057, indep loss:  -2.213, rf loss: 5.091\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 50\n",
      "Recon_loss: 0.056, indep loss:  -2.211, rf loss: 5.096\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 60\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.152\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 70\n",
      "Recon_loss: 0.056, indep loss:  -2.210, rf loss: 5.151\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 80\n",
      "Recon_loss: 0.057, indep loss:  -2.211, rf loss: 5.164\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 90\n",
      "Recon_loss: 0.056, indep loss:  -2.207, rf loss: 5.198\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 100\n",
      "Recon_loss: 0.056, indep loss:  -2.208, rf loss: 5.235\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 110\n",
      "Recon_loss: 0.057, indep loss:  -2.208, rf loss: 5.267\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 120\n",
      "Recon_loss: 0.057, indep loss:  -2.209, rf loss: 5.267\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 130\n",
      "Recon_loss: 0.057, indep loss:  -2.206, rf loss: 5.265\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 140\n",
      "Recon_loss: 0.057, indep loss:  -2.202, rf loss: 5.264\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 150\n",
      "Recon_loss: 0.057, indep loss:  -2.202, rf loss: 5.265\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 160\n",
      "Recon_loss: 0.058, indep loss:  -2.205, rf loss: 5.281\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 170\n",
      "Recon_loss: 0.058, indep loss:  -2.207, rf loss: 5.289\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 180\n",
      "Recon_loss: 0.058, indep loss:  -2.212, rf loss: 5.292\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 190\n",
      "Recon_loss: 0.058, indep loss:  -2.213, rf loss: 5.290\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 200\n",
      "Recon_loss: 0.058, indep loss:  -2.213, rf loss: 5.306\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 210\n",
      "Recon_loss: 0.057, indep loss:  -2.215, rf loss: 5.310\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 220\n",
      "Recon_loss: 0.057, indep loss:  -2.214, rf loss: 5.318\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 230\n",
      "Recon_loss: 0.057, indep loss:  -2.216, rf loss: 5.327\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 240\n",
      "Recon_loss: 0.057, indep loss:  -2.217, rf loss: 5.325\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 250\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.324\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 260\n",
      "Recon_loss: 0.057, indep loss:  -2.221, rf loss: 5.310\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 270\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.314\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 280\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.329\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 290\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.332\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 300\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.346\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 310\n",
      "Recon_loss: 0.057, indep loss:  -2.221, rf loss: 5.332\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 320\n",
      "Recon_loss: 0.057, indep loss:  -2.221, rf loss: 5.327\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 330\n",
      "Recon_loss: 0.057, indep loss:  -2.222, rf loss: 5.313\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 340\n",
      "Recon_loss: 0.057, indep loss:  -2.222, rf loss: 5.313\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 350\n",
      "Recon_loss: 0.057, indep loss:  -2.223, rf loss: 5.310\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 360\n",
      "Recon_loss: 0.057, indep loss:  -2.223, rf loss: 5.314\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 370\n",
      "Recon_loss: 0.057, indep loss:  -2.222, rf loss: 5.311\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 380\n",
      "Recon_loss: 0.057, indep loss:  -2.221, rf loss: 5.318\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 390\n",
      "Recon_loss: 0.057, indep loss:  -2.221, rf loss: 5.319\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 400\n",
      "Recon_loss: 0.057, indep loss:  -2.219, rf loss: 5.327\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 410\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.336\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 420\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.334\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 430\n",
      "Recon_loss: 0.057, indep loss:  -2.220, rf loss: 5.338\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 440\n",
      "Recon_loss: 0.057, indep loss:  -2.221, rf loss: 5.332\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 450\n",
      "Recon_loss: 0.057, indep loss:  -2.221, rf loss: 5.331\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 19/50, Step: 460\n",
      "Recon_loss: 0.057, indep loss:  -2.222, rf loss: 5.334\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 0\n",
      "Recon_loss: 0.056, indep loss:  -2.178, rf loss: 5.148\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 10\n",
      "Recon_loss: 0.056, indep loss:  -2.221, rf loss: 5.031\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 20\n",
      "Recon_loss: 0.056, indep loss:  -2.222, rf loss: 5.162\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 30\n",
      "Recon_loss: 0.055, indep loss:  -2.215, rf loss: 5.279\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 40\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.300\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 50\n",
      "Recon_loss: 0.056, indep loss:  -2.212, rf loss: 5.302\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 60\n",
      "Recon_loss: 0.055, indep loss:  -2.213, rf loss: 5.351\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 70\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.321\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 80\n",
      "Recon_loss: 0.056, indep loss:  -2.215, rf loss: 5.316\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 90\n",
      "Recon_loss: 0.056, indep loss:  -2.210, rf loss: 5.358\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 100\n",
      "Recon_loss: 0.056, indep loss:  -2.210, rf loss: 5.391\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 110\n",
      "Recon_loss: 0.056, indep loss:  -2.209, rf loss: 5.418\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 120\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.414\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 130\n",
      "Recon_loss: 0.056, indep loss:  -2.210, rf loss: 5.419\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 140\n",
      "Recon_loss: 0.056, indep loss:  -2.206, rf loss: 5.417\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 150\n",
      "Recon_loss: 0.057, indep loss:  -2.205, rf loss: 5.411\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 160\n",
      "Recon_loss: 0.057, indep loss:  -2.206, rf loss: 5.427\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 170\n",
      "Recon_loss: 0.057, indep loss:  -2.208, rf loss: 5.439\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 180\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.438\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 190\n",
      "Recon_loss: 0.057, indep loss:  -2.211, rf loss: 5.441\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 200\n",
      "Recon_loss: 0.057, indep loss:  -2.209, rf loss: 5.456\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 210\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.449\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 220\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.454\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 230\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.456\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 240\n",
      "Recon_loss: 0.057, indep loss:  -2.211, rf loss: 5.451\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 250\n",
      "Recon_loss: 0.057, indep loss:  -2.212, rf loss: 5.450\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 260\n",
      "Recon_loss: 0.057, indep loss:  -2.212, rf loss: 5.438\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 270\n",
      "Recon_loss: 0.057, indep loss:  -2.212, rf loss: 5.442\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 280\n",
      "Recon_loss: 0.057, indep loss:  -2.212, rf loss: 5.443\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 290\n",
      "Recon_loss: 0.057, indep loss:  -2.212, rf loss: 5.445\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 300\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.456\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 310\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.443\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 320\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.441\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 330\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.427\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 340\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.430\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 350\n",
      "Recon_loss: 0.057, indep loss:  -2.211, rf loss: 5.432\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 360\n",
      "Recon_loss: 0.057, indep loss:  -2.211, rf loss: 5.426\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 370\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.414\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 380\n",
      "Recon_loss: 0.057, indep loss:  -2.209, rf loss: 5.416\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 390\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.406\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 400\n",
      "Recon_loss: 0.057, indep loss:  -2.208, rf loss: 5.406\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 410\n",
      "Recon_loss: 0.057, indep loss:  -2.208, rf loss: 5.409\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 420\n",
      "Recon_loss: 0.057, indep loss:  -2.209, rf loss: 5.402\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 430\n",
      "Recon_loss: 0.057, indep loss:  -2.209, rf loss: 5.405\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 440\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.398\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 450\n",
      "Recon_loss: 0.057, indep loss:  -2.210, rf loss: 5.395\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 20/50, Step: 460\n",
      "Recon_loss: 0.057, indep loss:  -2.211, rf loss: 5.398\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 0\n",
      "Recon_loss: 0.056, indep loss:  -2.166, rf loss: 5.309\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 10\n",
      "Recon_loss: 0.056, indep loss:  -2.215, rf loss: 5.117\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 20\n",
      "Recon_loss: 0.056, indep loss:  -2.222, rf loss: 5.250\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 30\n",
      "Recon_loss: 0.055, indep loss:  -2.213, rf loss: 5.373\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 40\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 5.381\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 50\n",
      "Recon_loss: 0.055, indep loss:  -2.203, rf loss: 5.391\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 60\n",
      "Recon_loss: 0.055, indep loss:  -2.203, rf loss: 5.423\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 70\n",
      "Recon_loss: 0.055, indep loss:  -2.202, rf loss: 5.405\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 80\n",
      "Recon_loss: 0.055, indep loss:  -2.203, rf loss: 5.417\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 90\n",
      "Recon_loss: 0.055, indep loss:  -2.202, rf loss: 5.441\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 100\n",
      "Recon_loss: 0.055, indep loss:  -2.205, rf loss: 5.476\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 110\n",
      "Recon_loss: 0.056, indep loss:  -2.207, rf loss: 5.502\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 120\n",
      "Recon_loss: 0.056, indep loss:  -2.211, rf loss: 5.496\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 130\n",
      "Recon_loss: 0.056, indep loss:  -2.212, rf loss: 5.485\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 140\n",
      "Recon_loss: 0.056, indep loss:  -2.210, rf loss: 5.477\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 150\n",
      "Recon_loss: 0.056, indep loss:  -2.209, rf loss: 5.487\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 160\n",
      "Recon_loss: 0.056, indep loss:  -2.211, rf loss: 5.485\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 170\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.505\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 180\n",
      "Recon_loss: 0.057, indep loss:  -2.215, rf loss: 5.514\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 190\n",
      "Recon_loss: 0.057, indep loss:  -2.215, rf loss: 5.522\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 200\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.535\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 210\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.531\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 220\n",
      "Recon_loss: 0.056, indep loss:  -2.212, rf loss: 5.533\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 230\n",
      "Recon_loss: 0.056, indep loss:  -2.211, rf loss: 5.533\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 240\n",
      "Recon_loss: 0.056, indep loss:  -2.212, rf loss: 5.535\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 250\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.539\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 260\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.536\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 270\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.543\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 280\n",
      "Recon_loss: 0.056, indep loss:  -2.215, rf loss: 5.558\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 290\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.575\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 300\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.588\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 310\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.581\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 320\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.572\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 330\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.556\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 340\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.562\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 350\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.571\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 360\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.572\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 370\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.574\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 380\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.584\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 390\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.585\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 400\n",
      "Recon_loss: 0.056, indep loss:  -2.212, rf loss: 5.592\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 410\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.601\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 420\n",
      "Recon_loss: 0.056, indep loss:  -2.215, rf loss: 5.602\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 430\n",
      "Recon_loss: 0.056, indep loss:  -2.216, rf loss: 5.609\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 440\n",
      "Recon_loss: 0.056, indep loss:  -2.216, rf loss: 5.608\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 450\n",
      "Recon_loss: 0.056, indep loss:  -2.217, rf loss: 5.612\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 21/50, Step: 460\n",
      "Recon_loss: 0.056, indep loss:  -2.217, rf loss: 5.620\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 0\n",
      "Recon_loss: 0.055, indep loss:  -2.153, rf loss: 5.296\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 10\n",
      "Recon_loss: 0.056, indep loss:  -2.210, rf loss: 5.304\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 20\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 5.516\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 30\n",
      "Recon_loss: 0.054, indep loss:  -2.205, rf loss: 5.607\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 40\n",
      "Recon_loss: 0.055, indep loss:  -2.203, rf loss: 5.640\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 50\n",
      "Recon_loss: 0.055, indep loss:  -2.196, rf loss: 5.681\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 60\n",
      "Recon_loss: 0.055, indep loss:  -2.203, rf loss: 5.736\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 70\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 5.757\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 80\n",
      "Recon_loss: 0.055, indep loss:  -2.205, rf loss: 5.779\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 90\n",
      "Recon_loss: 0.055, indep loss:  -2.205, rf loss: 5.815\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 100\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 5.844\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 110\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 5.881\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 120\n",
      "Recon_loss: 0.055, indep loss:  -2.215, rf loss: 5.894\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 130\n",
      "Recon_loss: 0.055, indep loss:  -2.215, rf loss: 5.892\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 140\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.890\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 150\n",
      "Recon_loss: 0.056, indep loss:  -2.212, rf loss: 5.898\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 160\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.896\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 170\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.922\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 180\n",
      "Recon_loss: 0.056, indep loss:  -2.216, rf loss: 5.944\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 190\n",
      "Recon_loss: 0.056, indep loss:  -2.216, rf loss: 5.954\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 200\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.970\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 210\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.975\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 220\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 5.982\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 230\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.992\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 240\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 5.987\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 250\n",
      "Recon_loss: 0.056, indep loss:  -2.215, rf loss: 5.990\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 260\n",
      "Recon_loss: 0.056, indep loss:  -2.216, rf loss: 5.981\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 270\n",
      "Recon_loss: 0.056, indep loss:  -2.216, rf loss: 5.989\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 280\n",
      "Recon_loss: 0.056, indep loss:  -2.215, rf loss: 6.000\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 290\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 6.008\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 300\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 6.019\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 310\n",
      "Recon_loss: 0.055, indep loss:  -2.213, rf loss: 6.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 320\n",
      "Recon_loss: 0.055, indep loss:  -2.213, rf loss: 6.010\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 330\n",
      "Recon_loss: 0.055, indep loss:  -2.213, rf loss: 5.995\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 340\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 6.005\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 350\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 6.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 360\n",
      "Recon_loss: 0.055, indep loss:  -2.215, rf loss: 6.019\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 370\n",
      "Recon_loss: 0.056, indep loss:  -2.214, rf loss: 6.021\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 380\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 6.031\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 390\n",
      "Recon_loss: 0.056, indep loss:  -2.213, rf loss: 6.035\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 400\n",
      "Recon_loss: 0.056, indep loss:  -2.212, rf loss: 6.046\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 410\n",
      "Recon_loss: 0.056, indep loss:  -2.211, rf loss: 6.057\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 420\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 6.061\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 430\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 6.071\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 440\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 6.068\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 450\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 6.067\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 22/50, Step: 460\n",
      "Recon_loss: 0.055, indep loss:  -2.213, rf loss: 6.074\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 0\n",
      "Recon_loss: 0.054, indep loss:  -2.149, rf loss: 5.631\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 10\n",
      "Recon_loss: 0.054, indep loss:  -2.211, rf loss: 5.878\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 20\n",
      "Recon_loss: 0.054, indep loss:  -2.215, rf loss: 6.054\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 30\n",
      "Recon_loss: 0.053, indep loss:  -2.219, rf loss: 6.130\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 40\n",
      "Recon_loss: 0.054, indep loss:  -2.219, rf loss: 6.120\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 50\n",
      "Recon_loss: 0.054, indep loss:  -2.210, rf loss: 6.122\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 60\n",
      "Recon_loss: 0.054, indep loss:  -2.215, rf loss: 6.130\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 70\n",
      "Recon_loss: 0.053, indep loss:  -2.211, rf loss: 6.099\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 80\n",
      "Recon_loss: 0.054, indep loss:  -2.211, rf loss: 6.098\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 90\n",
      "Recon_loss: 0.054, indep loss:  -2.207, rf loss: 6.112\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 100\n",
      "Recon_loss: 0.054, indep loss:  -2.208, rf loss: 6.130\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 110\n",
      "Recon_loss: 0.054, indep loss:  -2.210, rf loss: 6.162\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 120\n",
      "Recon_loss: 0.055, indep loss:  -2.216, rf loss: 6.178\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 130\n",
      "Recon_loss: 0.054, indep loss:  -2.216, rf loss: 6.162\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 140\n",
      "Recon_loss: 0.055, indep loss:  -2.215, rf loss: 6.156\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 150\n",
      "Recon_loss: 0.055, indep loss:  -2.216, rf loss: 6.143\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 160\n",
      "Recon_loss: 0.055, indep loss:  -2.217, rf loss: 6.140\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 170\n",
      "Recon_loss: 0.055, indep loss:  -2.219, rf loss: 6.150\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 180\n",
      "Recon_loss: 0.055, indep loss:  -2.221, rf loss: 6.162\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 190\n",
      "Recon_loss: 0.055, indep loss:  -2.221, rf loss: 6.164\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 200\n",
      "Recon_loss: 0.055, indep loss:  -2.217, rf loss: 6.167\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 210\n",
      "Recon_loss: 0.055, indep loss:  -2.217, rf loss: 6.148\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 220\n",
      "Recon_loss: 0.055, indep loss:  -2.216, rf loss: 6.142\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 230\n",
      "Recon_loss: 0.055, indep loss:  -2.218, rf loss: 6.117\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 240\n",
      "Recon_loss: 0.055, indep loss:  -2.218, rf loss: 6.095\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 250\n",
      "Recon_loss: 0.055, indep loss:  -2.219, rf loss: 6.084\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 260\n",
      "Recon_loss: 0.055, indep loss:  -2.220, rf loss: 6.042\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 270\n",
      "Recon_loss: 0.055, indep loss:  -2.220, rf loss: 6.005\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 280\n",
      "Recon_loss: 0.055, indep loss:  -2.220, rf loss: 5.966\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 290\n",
      "Recon_loss: 0.055, indep loss:  -2.220, rf loss: 5.949\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 300\n",
      "Recon_loss: 0.055, indep loss:  -2.219, rf loss: 5.918\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 310\n",
      "Recon_loss: 0.055, indep loss:  -2.218, rf loss: 5.837\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 320\n",
      "Recon_loss: 0.055, indep loss:  -2.217, rf loss: 5.792\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 330\n",
      "Recon_loss: 0.055, indep loss:  -2.216, rf loss: 5.666\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 340\n",
      "Recon_loss: 0.055, indep loss:  -2.217, rf loss: 5.572\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 350\n",
      "Recon_loss: 0.055, indep loss:  -2.217, rf loss: 5.504\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 360\n",
      "Recon_loss: 0.055, indep loss:  -2.217, rf loss: 5.444\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 370\n",
      "Recon_loss: 0.055, indep loss:  -2.216, rf loss: 5.382\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 380\n",
      "Recon_loss: 0.055, indep loss:  -2.215, rf loss: 5.340\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 390\n",
      "Recon_loss: 0.055, indep loss:  -2.215, rf loss: 5.284\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 400\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.264\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 410\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.241\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 420\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.195\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 430\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.178\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 440\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.133\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 450\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.105\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 23/50, Step: 460\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 5.094\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 0\n",
      "Recon_loss: 0.054, indep loss:  -2.123, rf loss: 3.368\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 10\n",
      "Recon_loss: 0.054, indep loss:  -2.211, rf loss: 3.865\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 20\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.933\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 30\n",
      "Recon_loss: 0.053, indep loss:  -2.209, rf loss: 4.042\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 40\n",
      "Recon_loss: 0.054, indep loss:  -2.207, rf loss: 3.921\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 50\n",
      "Recon_loss: 0.054, indep loss:  -2.202, rf loss: 3.927\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 60\n",
      "Recon_loss: 0.054, indep loss:  -2.209, rf loss: 3.957\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 70\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.846\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 80\n",
      "Recon_loss: 0.054, indep loss:  -2.203, rf loss: 3.889\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 90\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 3.958\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 100\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 3.979\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 110\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 4.034\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 120\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.039\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 130\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.040\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 140\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.049\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 150\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.060\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 160\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.087\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 170\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.099\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 180\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.122\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 190\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.148\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 200\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.154\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 210\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.126\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 220\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.110\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 230\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.119\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 240\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.134\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 250\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.147\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 260\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.142\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 270\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.151\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 280\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.163\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 290\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.170\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 300\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.184\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 310\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.172\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 320\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.177\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 330\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.166\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 340\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.172\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 350\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.175\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 360\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.168\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 370\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.168\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 380\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.173\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 390\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.180\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 400\n",
      "Recon_loss: 0.055, indep loss:  -2.206, rf loss: 4.193\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 410\n",
      "Recon_loss: 0.055, indep loss:  -2.206, rf loss: 4.203\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 420\n",
      "Recon_loss: 0.055, indep loss:  -2.207, rf loss: 4.201\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 430\n",
      "Recon_loss: 0.055, indep loss:  -2.207, rf loss: 4.209\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 440\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.200\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 450\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.196\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 24/50, Step: 460\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.199\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 0\n",
      "Recon_loss: 0.054, indep loss:  -2.174, rf loss: 3.446\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 10\n",
      "Recon_loss: 0.055, indep loss:  -2.236, rf loss: 3.788\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 20\n",
      "Recon_loss: 0.054, indep loss:  -2.233, rf loss: 3.847\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 30\n",
      "Recon_loss: 0.053, indep loss:  -2.225, rf loss: 3.931\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 40\n",
      "Recon_loss: 0.054, indep loss:  -2.215, rf loss: 3.861\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 50\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.905\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 60\n",
      "Recon_loss: 0.054, indep loss:  -2.212, rf loss: 3.987\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 70\n",
      "Recon_loss: 0.054, indep loss:  -2.209, rf loss: 3.963\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 80\n",
      "Recon_loss: 0.054, indep loss:  -2.210, rf loss: 3.957\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 90\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 4.004\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 100\n",
      "Recon_loss: 0.054, indep loss:  -2.208, rf loss: 3.993\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 110\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.026\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 120\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 4.050\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 130\n",
      "Recon_loss: 0.055, indep loss:  -2.214, rf loss: 4.059\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 140\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.061\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 150\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.040\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 160\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.070\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 170\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.083\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 180\n",
      "Recon_loss: 0.055, indep loss:  -2.213, rf loss: 4.079\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 190\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.115\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 200\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.127\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 210\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.106\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 220\n",
      "Recon_loss: 0.055, indep loss:  -2.209, rf loss: 4.091\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 230\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.091\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 240\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.096\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 250\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.092\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 260\n",
      "Recon_loss: 0.055, indep loss:  -2.212, rf loss: 4.080\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 270\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.095\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 280\n",
      "Recon_loss: 0.055, indep loss:  -2.211, rf loss: 4.103\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 290\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 4.096\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 300\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.103\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 310\n",
      "Recon_loss: 0.055, indep loss:  -2.207, rf loss: 4.057\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 320\n",
      "Recon_loss: 0.055, indep loss:  -2.207, rf loss: 4.050\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 330\n",
      "Recon_loss: 0.055, indep loss:  -2.207, rf loss: 4.023\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 340\n",
      "Recon_loss: 0.055, indep loss:  -2.207, rf loss: 4.011\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 350\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.018\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 360\n",
      "Recon_loss: 0.055, indep loss:  -2.208, rf loss: 4.005\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 370\n",
      "Recon_loss: 0.055, indep loss:  -2.206, rf loss: 3.998\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 380\n",
      "Recon_loss: 0.055, indep loss:  -2.206, rf loss: 3.994\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 390\n",
      "Recon_loss: 0.055, indep loss:  -2.206, rf loss: 3.986\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 400\n",
      "Recon_loss: 0.055, indep loss:  -2.204, rf loss: 3.996\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 410\n",
      "Recon_loss: 0.055, indep loss:  -2.204, rf loss: 4.000\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 420\n",
      "Recon_loss: 0.055, indep loss:  -2.204, rf loss: 3.979\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 430\n",
      "Recon_loss: 0.055, indep loss:  -2.203, rf loss: 3.983\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 440\n",
      "Recon_loss: 0.055, indep loss:  -2.205, rf loss: 3.978\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 450\n",
      "Recon_loss: 0.055, indep loss:  -2.205, rf loss: 3.969\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 25/50, Step: 460\n",
      "Recon_loss: 0.055, indep loss:  -2.206, rf loss: 3.969\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 0\n",
      "Recon_loss: 0.054, indep loss:  -2.168, rf loss: 3.149\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 10\n",
      "Recon_loss: 0.054, indep loss:  -2.228, rf loss: 3.450\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 20\n",
      "Recon_loss: 0.054, indep loss:  -2.225, rf loss: 3.252\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 30\n",
      "Recon_loss: 0.053, indep loss:  -2.215, rf loss: 2.789\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 40\n",
      "Recon_loss: 0.054, indep loss:  -2.207, rf loss: 2.926\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 50\n",
      "Recon_loss: 0.053, indep loss:  -2.204, rf loss: 2.885\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 60\n",
      "Recon_loss: 0.053, indep loss:  -2.207, rf loss: 2.802\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 70\n",
      "Recon_loss: 0.053, indep loss:  -2.203, rf loss: 2.808\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 80\n",
      "Recon_loss: 0.054, indep loss:  -2.201, rf loss: 2.907\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 90\n",
      "Recon_loss: 0.053, indep loss:  -2.200, rf loss: 2.995\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 100\n",
      "Recon_loss: 0.053, indep loss:  -2.204, rf loss: 3.010\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 110\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.064\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 120\n",
      "Recon_loss: 0.054, indep loss:  -2.211, rf loss: 3.116\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 130\n",
      "Recon_loss: 0.054, indep loss:  -2.211, rf loss: 3.131\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 140\n",
      "Recon_loss: 0.054, indep loss:  -2.209, rf loss: 3.139\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 150\n",
      "Recon_loss: 0.054, indep loss:  -2.209, rf loss: 3.120\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 160\n",
      "Recon_loss: 0.054, indep loss:  -2.208, rf loss: 3.166\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 170\n",
      "Recon_loss: 0.054, indep loss:  -2.208, rf loss: 3.182\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 180\n",
      "Recon_loss: 0.055, indep loss:  -2.210, rf loss: 3.197\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 190\n",
      "Recon_loss: 0.054, indep loss:  -2.210, rf loss: 3.240\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 200\n",
      "Recon_loss: 0.054, indep loss:  -2.207, rf loss: 3.244\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 210\n",
      "Recon_loss: 0.054, indep loss:  -2.208, rf loss: 3.225\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 220\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.211\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 230\n",
      "Recon_loss: 0.054, indep loss:  -2.207, rf loss: 3.226\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 240\n",
      "Recon_loss: 0.054, indep loss:  -2.208, rf loss: 3.243\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 250\n",
      "Recon_loss: 0.054, indep loss:  -2.209, rf loss: 3.234\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 260\n",
      "Recon_loss: 0.054, indep loss:  -2.209, rf loss: 3.245\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 270\n",
      "Recon_loss: 0.054, indep loss:  -2.207, rf loss: 3.267\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 280\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.282\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 290\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.291\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 300\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 3.305\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 310\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 3.271\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 320\n",
      "Recon_loss: 0.054, indep loss:  -2.205, rf loss: 3.258\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 330\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 3.223\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 340\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 3.227\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 350\n",
      "Recon_loss: 0.054, indep loss:  -2.205, rf loss: 3.242\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 360\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.211\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 370\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 3.213\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 380\n",
      "Recon_loss: 0.054, indep loss:  -2.203, rf loss: 3.224\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 390\n",
      "Recon_loss: 0.054, indep loss:  -2.203, rf loss: 3.222\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 400\n",
      "Recon_loss: 0.055, indep loss:  -2.201, rf loss: 3.241\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 410\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 3.250\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 420\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 3.237\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 430\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 3.236\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 440\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 3.229\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 450\n",
      "Recon_loss: 0.054, indep loss:  -2.201, rf loss: 3.225\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 26/50, Step: 460\n",
      "Recon_loss: 0.054, indep loss:  -2.203, rf loss: 3.228\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 0\n",
      "Recon_loss: 0.054, indep loss:  -2.134, rf loss: 2.514\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 10\n",
      "Recon_loss: 0.054, indep loss:  -2.216, rf loss: 2.944\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 20\n",
      "Recon_loss: 0.054, indep loss:  -2.209, rf loss: 3.024\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 30\n",
      "Recon_loss: 0.053, indep loss:  -2.209, rf loss: 3.079\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 40\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 2.798\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 50\n",
      "Recon_loss: 0.053, indep loss:  -2.204, rf loss: 2.909\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 60\n",
      "Recon_loss: 0.053, indep loss:  -2.208, rf loss: 3.009\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 70\n",
      "Recon_loss: 0.053, indep loss:  -2.208, rf loss: 2.911\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 80\n",
      "Recon_loss: 0.054, indep loss:  -2.205, rf loss: 2.942\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 90\n",
      "Recon_loss: 0.054, indep loss:  -2.205, rf loss: 3.008\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 100\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 2.980\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 110\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 120\n",
      "Recon_loss: 0.054, indep loss:  -2.207, rf loss: 3.029\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 130\n",
      "Recon_loss: 0.054, indep loss:  -2.206, rf loss: 3.008\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 140\n",
      "Recon_loss: 0.054, indep loss:  -2.202, rf loss: 2.983\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 150\n",
      "Recon_loss: 0.055, indep loss:  -2.204, rf loss: 2.979\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 160\n",
      "Recon_loss: 0.055, indep loss:  -2.203, rf loss: 3.016\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 170\n",
      "Recon_loss: 0.055, indep loss:  -2.204, rf loss: 3.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 180\n",
      "Recon_loss: 0.055, indep loss:  -2.206, rf loss: 3.022\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 190\n",
      "Recon_loss: 0.055, indep loss:  -2.205, rf loss: 3.054\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 200\n",
      "Recon_loss: 0.055, indep loss:  -2.202, rf loss: 3.049\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 210\n",
      "Recon_loss: 0.054, indep loss:  -2.204, rf loss: 3.032\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 220\n",
      "Recon_loss: 0.054, indep loss:  -2.202, rf loss: 3.004\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 230\n",
      "Recon_loss: 0.054, indep loss:  -2.202, rf loss: 2.988\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 240\n",
      "Recon_loss: 0.054, indep loss:  -2.202, rf loss: 2.997\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 250\n",
      "Recon_loss: 0.054, indep loss:  -2.203, rf loss: 2.995\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 260\n",
      "Recon_loss: 0.054, indep loss:  -2.202, rf loss: 2.975\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 270\n",
      "Recon_loss: 0.054, indep loss:  -2.201, rf loss: 2.963\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 280\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 2.976\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 290\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 2.984\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 300\n",
      "Recon_loss: 0.054, indep loss:  -2.199, rf loss: 2.997\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 310\n",
      "Recon_loss: 0.054, indep loss:  -2.198, rf loss: 2.967\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 320\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 2.953\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 330\n",
      "Recon_loss: 0.054, indep loss:  -2.199, rf loss: 2.923\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 340\n",
      "Recon_loss: 0.054, indep loss:  -2.199, rf loss: 2.929\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 350\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 2.955\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 360\n",
      "Recon_loss: 0.054, indep loss:  -2.200, rf loss: 2.964\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 370\n",
      "Recon_loss: 0.054, indep loss:  -2.199, rf loss: 2.972\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 380\n",
      "Recon_loss: 0.054, indep loss:  -2.199, rf loss: 2.978\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 390\n",
      "Recon_loss: 0.054, indep loss:  -2.198, rf loss: 2.982\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 400\n",
      "Recon_loss: 0.054, indep loss:  -2.196, rf loss: 3.001\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 410\n",
      "Recon_loss: 0.054, indep loss:  -2.196, rf loss: 3.010\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 420\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 3.003\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 430\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 3.008\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 440\n",
      "Recon_loss: 0.054, indep loss:  -2.196, rf loss: 2.990\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 450\n",
      "Recon_loss: 0.054, indep loss:  -2.196, rf loss: 2.990\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 27/50, Step: 460\n",
      "Recon_loss: 0.054, indep loss:  -2.198, rf loss: 2.996\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 0\n",
      "Recon_loss: 0.053, indep loss:  -2.167, rf loss: 1.319\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 10\n",
      "Recon_loss: 0.054, indep loss:  -2.222, rf loss: 2.305\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 20\n",
      "Recon_loss: 0.053, indep loss:  -2.219, rf loss: 2.752\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 30\n",
      "Recon_loss: 0.052, indep loss:  -2.211, rf loss: 2.973\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 40\n",
      "Recon_loss: 0.053, indep loss:  -2.209, rf loss: 2.548\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 50\n",
      "Recon_loss: 0.053, indep loss:  -2.207, rf loss: 2.547\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 60\n",
      "Recon_loss: 0.053, indep loss:  -2.205, rf loss: 2.609\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 70\n",
      "Recon_loss: 0.052, indep loss:  -2.202, rf loss: 2.581\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 80\n",
      "Recon_loss: 0.053, indep loss:  -2.198, rf loss: 2.649\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 90\n",
      "Recon_loss: 0.053, indep loss:  -2.198, rf loss: 2.735\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 100\n",
      "Recon_loss: 0.053, indep loss:  -2.197, rf loss: 2.754\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 110\n",
      "Recon_loss: 0.053, indep loss:  -2.198, rf loss: 2.793\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 120\n",
      "Recon_loss: 0.053, indep loss:  -2.201, rf loss: 2.798\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 130\n",
      "Recon_loss: 0.053, indep loss:  -2.199, rf loss: 2.784\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 140\n",
      "Recon_loss: 0.054, indep loss:  -2.193, rf loss: 2.773\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 150\n",
      "Recon_loss: 0.054, indep loss:  -2.194, rf loss: 2.732\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 160\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.749\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 170\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.765\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 180\n",
      "Recon_loss: 0.054, indep loss:  -2.198, rf loss: 2.791\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 190\n",
      "Recon_loss: 0.054, indep loss:  -2.196, rf loss: 2.832\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 200\n",
      "Recon_loss: 0.054, indep loss:  -2.193, rf loss: 2.832\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 210\n",
      "Recon_loss: 0.054, indep loss:  -2.194, rf loss: 2.792\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 220\n",
      "Recon_loss: 0.054, indep loss:  -2.193, rf loss: 2.763\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 230\n",
      "Recon_loss: 0.054, indep loss:  -2.194, rf loss: 2.781\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 240\n",
      "Recon_loss: 0.054, indep loss:  -2.194, rf loss: 2.798\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 250\n",
      "Recon_loss: 0.054, indep loss:  -2.196, rf loss: 2.788\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 260\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.795\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 270\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.813\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 280\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.803\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 290\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.817\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 300\n",
      "Recon_loss: 0.054, indep loss:  -2.194, rf loss: 2.825\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 310\n",
      "Recon_loss: 0.054, indep loss:  -2.194, rf loss: 2.787\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 320\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.779\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 330\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.760\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 340\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.757\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 350\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.777\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 360\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.780\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 370\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.779\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 380\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.782\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 390\n",
      "Recon_loss: 0.054, indep loss:  -2.195, rf loss: 2.780\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 400\n",
      "Recon_loss: 0.054, indep loss:  -2.193, rf loss: 2.798\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 410\n",
      "Recon_loss: 0.054, indep loss:  -2.193, rf loss: 2.802\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 420\n",
      "Recon_loss: 0.054, indep loss:  -2.193, rf loss: 2.788\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 430\n",
      "Recon_loss: 0.054, indep loss:  -2.192, rf loss: 2.793\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 440\n",
      "Recon_loss: 0.054, indep loss:  -2.192, rf loss: 2.783\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 450\n",
      "Recon_loss: 0.054, indep loss:  -2.192, rf loss: 2.771\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 28/50, Step: 460\n",
      "Recon_loss: 0.054, indep loss:  -2.193, rf loss: 2.768\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 0\n",
      "Recon_loss: 0.053, indep loss:  -2.138, rf loss: 1.608\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 10\n",
      "Recon_loss: 0.053, indep loss:  -2.216, rf loss: 2.364\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 20\n",
      "Recon_loss: 0.053, indep loss:  -2.205, rf loss: 2.677\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 30\n",
      "Recon_loss: 0.052, indep loss:  -2.198, rf loss: 2.781\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 40\n",
      "Recon_loss: 0.053, indep loss:  -2.196, rf loss: 2.556\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 50\n",
      "Recon_loss: 0.053, indep loss:  -2.190, rf loss: 2.563\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 60\n",
      "Recon_loss: 0.052, indep loss:  -2.191, rf loss: 2.607\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 70\n",
      "Recon_loss: 0.052, indep loss:  -2.189, rf loss: 2.536\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 80\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.596\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 90\n",
      "Recon_loss: 0.053, indep loss:  -2.188, rf loss: 2.629\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 100\n",
      "Recon_loss: 0.053, indep loss:  -2.188, rf loss: 2.601\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 110\n",
      "Recon_loss: 0.053, indep loss:  -2.190, rf loss: 2.628\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 120\n",
      "Recon_loss: 0.053, indep loss:  -2.193, rf loss: 2.644\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 130\n",
      "Recon_loss: 0.053, indep loss:  -2.190, rf loss: 2.646\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 140\n",
      "Recon_loss: 0.053, indep loss:  -2.184, rf loss: 2.619\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 150\n",
      "Recon_loss: 0.054, indep loss:  -2.186, rf loss: 2.605\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 160\n",
      "Recon_loss: 0.054, indep loss:  -2.186, rf loss: 2.638\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 170\n",
      "Recon_loss: 0.054, indep loss:  -2.188, rf loss: 2.652\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 180\n",
      "Recon_loss: 0.054, indep loss:  -2.191, rf loss: 2.654\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 190\n",
      "Recon_loss: 0.054, indep loss:  -2.190, rf loss: 2.660\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 200\n",
      "Recon_loss: 0.054, indep loss:  -2.186, rf loss: 2.670\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 210\n",
      "Recon_loss: 0.054, indep loss:  -2.187, rf loss: 2.648\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 220\n",
      "Recon_loss: 0.054, indep loss:  -2.186, rf loss: 2.579\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 230\n",
      "Recon_loss: 0.053, indep loss:  -2.186, rf loss: 2.579\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 240\n",
      "Recon_loss: 0.053, indep loss:  -2.187, rf loss: 2.596\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 250\n",
      "Recon_loss: 0.053, indep loss:  -2.190, rf loss: 2.604\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 260\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.631\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 270\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.650\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 280\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.671\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 290\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.695\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 300\n",
      "Recon_loss: 0.053, indep loss:  -2.188, rf loss: 2.710\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 310\n",
      "Recon_loss: 0.053, indep loss:  -2.188, rf loss: 2.682\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 320\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.662\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 330\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.640\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 340\n",
      "Recon_loss: 0.053, indep loss:  -2.189, rf loss: 2.662\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 350\n",
      "Recon_loss: 0.053, indep loss:  -2.188, rf loss: 2.685\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 360\n",
      "Recon_loss: 0.053, indep loss:  -2.188, rf loss: 2.678\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 370\n",
      "Recon_loss: 0.053, indep loss:  -2.188, rf loss: 2.683\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 380\n",
      "Recon_loss: 0.053, indep loss:  -2.187, rf loss: 2.686\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 390\n",
      "Recon_loss: 0.053, indep loss:  -2.187, rf loss: 2.690\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 400\n",
      "Recon_loss: 0.053, indep loss:  -2.185, rf loss: 2.705\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 410\n",
      "Recon_loss: 0.053, indep loss:  -2.185, rf loss: 2.710\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 420\n",
      "Recon_loss: 0.053, indep loss:  -2.185, rf loss: 2.693\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 430\n",
      "Recon_loss: 0.053, indep loss:  -2.185, rf loss: 2.686\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 440\n",
      "Recon_loss: 0.053, indep loss:  -2.185, rf loss: 2.683\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 450\n",
      "Recon_loss: 0.053, indep loss:  -2.185, rf loss: 2.672\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 29/50, Step: 460\n",
      "Recon_loss: 0.053, indep loss:  -2.186, rf loss: 2.674\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 0\n",
      "Recon_loss: 0.053, indep loss:  -2.120, rf loss: 1.906\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 10\n",
      "Recon_loss: 0.053, indep loss:  -2.202, rf loss: 2.221\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 20\n",
      "Recon_loss: 0.053, indep loss:  -2.203, rf loss: 2.252\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 30\n",
      "Recon_loss: 0.051, indep loss:  -2.201, rf loss: 2.205\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 40\n",
      "Recon_loss: 0.052, indep loss:  -2.198, rf loss: 2.217\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 50\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.321\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 60\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.390\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 70\n",
      "Recon_loss: 0.052, indep loss:  -2.187, rf loss: 2.337\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 80\n",
      "Recon_loss: 0.052, indep loss:  -2.186, rf loss: 2.380\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 90\n",
      "Recon_loss: 0.052, indep loss:  -2.182, rf loss: 2.416\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 100\n",
      "Recon_loss: 0.052, indep loss:  -2.178, rf loss: 2.383\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 110\n",
      "Recon_loss: 0.052, indep loss:  -2.181, rf loss: 2.420\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 120\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.437\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 130\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.428\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 140\n",
      "Recon_loss: 0.053, indep loss:  -2.175, rf loss: 2.419\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 150\n",
      "Recon_loss: 0.053, indep loss:  -2.177, rf loss: 2.404\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 160\n",
      "Recon_loss: 0.053, indep loss:  -2.179, rf loss: 2.425\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 170\n",
      "Recon_loss: 0.053, indep loss:  -2.181, rf loss: 2.441\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 180\n",
      "Recon_loss: 0.053, indep loss:  -2.183, rf loss: 2.453\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 190\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.496\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 200\n",
      "Recon_loss: 0.053, indep loss:  -2.179, rf loss: 2.466\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 210\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.444\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 220\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.423\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 230\n",
      "Recon_loss: 0.053, indep loss:  -2.181, rf loss: 2.425\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 240\n",
      "Recon_loss: 0.053, indep loss:  -2.181, rf loss: 2.416\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 250\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.382\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 260\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.395\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 270\n",
      "Recon_loss: 0.053, indep loss:  -2.181, rf loss: 2.415\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 280\n",
      "Recon_loss: 0.053, indep loss:  -2.181, rf loss: 2.414\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 290\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.424\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 300\n",
      "Recon_loss: 0.053, indep loss:  -2.179, rf loss: 2.431\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 310\n",
      "Recon_loss: 0.053, indep loss:  -2.179, rf loss: 2.398\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 320\n",
      "Recon_loss: 0.053, indep loss:  -2.181, rf loss: 2.377\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 330\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.358\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 340\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.367\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 350\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.394\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 360\n",
      "Recon_loss: 0.053, indep loss:  -2.183, rf loss: 2.400\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 370\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.408\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 380\n",
      "Recon_loss: 0.053, indep loss:  -2.182, rf loss: 2.418\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 390\n",
      "Recon_loss: 0.053, indep loss:  -2.183, rf loss: 2.418\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 400\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.435\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 410\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.444\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 420\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.437\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 430\n",
      "Recon_loss: 0.053, indep loss:  -2.179, rf loss: 2.412\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 440\n",
      "Recon_loss: 0.053, indep loss:  -2.180, rf loss: 2.393\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 450\n",
      "Recon_loss: 0.053, indep loss:  -2.181, rf loss: 2.394\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 30/50, Step: 460\n",
      "Recon_loss: 0.053, indep loss:  -2.183, rf loss: 2.399\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 0\n",
      "Recon_loss: 0.052, indep loss:  -2.128, rf loss: 1.052\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 10\n",
      "Recon_loss: 0.052, indep loss:  -2.199, rf loss: 1.732\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 20\n",
      "Recon_loss: 0.052, indep loss:  -2.199, rf loss: 1.897\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 30\n",
      "Recon_loss: 0.051, indep loss:  -2.199, rf loss: 1.742\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 40\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.795\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 50\n",
      "Recon_loss: 0.051, indep loss:  -2.185, rf loss: 1.850\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 60\n",
      "Recon_loss: 0.051, indep loss:  -2.183, rf loss: 1.943\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 70\n",
      "Recon_loss: 0.051, indep loss:  -2.180, rf loss: 1.950\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 80\n",
      "Recon_loss: 0.051, indep loss:  -2.181, rf loss: 2.009\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 90\n",
      "Recon_loss: 0.051, indep loss:  -2.182, rf loss: 2.053\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 100\n",
      "Recon_loss: 0.051, indep loss:  -2.180, rf loss: 2.072\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 110\n",
      "Recon_loss: 0.051, indep loss:  -2.182, rf loss: 2.110\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 120\n",
      "Recon_loss: 0.052, indep loss:  -2.185, rf loss: 2.105\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 130\n",
      "Recon_loss: 0.051, indep loss:  -2.184, rf loss: 2.113\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 140\n",
      "Recon_loss: 0.052, indep loss:  -2.181, rf loss: 2.110\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 150\n",
      "Recon_loss: 0.052, indep loss:  -2.183, rf loss: 2.054\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 160\n",
      "Recon_loss: 0.052, indep loss:  -2.186, rf loss: 2.074\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 170\n",
      "Recon_loss: 0.052, indep loss:  -2.188, rf loss: 2.091\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 180\n",
      "Recon_loss: 0.052, indep loss:  -2.190, rf loss: 2.116\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 190\n",
      "Recon_loss: 0.052, indep loss:  -2.189, rf loss: 2.143\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 200\n",
      "Recon_loss: 0.052, indep loss:  -2.187, rf loss: 2.126\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 210\n",
      "Recon_loss: 0.052, indep loss:  -2.189, rf loss: 2.091\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 220\n",
      "Recon_loss: 0.052, indep loss:  -2.189, rf loss: 2.060\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 230\n",
      "Recon_loss: 0.052, indep loss:  -2.190, rf loss: 2.081\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 240\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.079\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 250\n",
      "Recon_loss: 0.052, indep loss:  -2.195, rf loss: 2.058\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 260\n",
      "Recon_loss: 0.052, indep loss:  -2.197, rf loss: 2.079\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 270\n",
      "Recon_loss: 0.052, indep loss:  -2.196, rf loss: 2.096\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 280\n",
      "Recon_loss: 0.052, indep loss:  -2.196, rf loss: 2.104\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 290\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.115\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 300\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.126\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 310\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.089\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 320\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.079\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 330\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.061\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 340\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.064\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 350\n",
      "Recon_loss: 0.052, indep loss:  -2.195, rf loss: 2.089\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 360\n",
      "Recon_loss: 0.052, indep loss:  -2.195, rf loss: 2.092\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 370\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.098\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 380\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.103\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 390\n",
      "Recon_loss: 0.052, indep loss:  -2.195, rf loss: 2.102\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 400\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.114\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 410\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.119\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 420\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.113\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 430\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.101\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 440\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.101\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 450\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.096\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 31/50, Step: 460\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.093\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 0\n",
      "Recon_loss: 0.051, indep loss:  -2.128, rf loss: 1.453\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 10\n",
      "Recon_loss: 0.052, indep loss:  -2.205, rf loss: 1.929\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 20\n",
      "Recon_loss: 0.051, indep loss:  -2.197, rf loss: 2.159\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 30\n",
      "Recon_loss: 0.051, indep loss:  -2.201, rf loss: 2.132\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 40\n",
      "Recon_loss: 0.052, indep loss:  -2.200, rf loss: 1.843\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 50\n",
      "Recon_loss: 0.051, indep loss:  -2.198, rf loss: 1.831\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 60\n",
      "Recon_loss: 0.051, indep loss:  -2.195, rf loss: 1.939\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 70\n",
      "Recon_loss: 0.051, indep loss:  -2.187, rf loss: 1.964\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 80\n",
      "Recon_loss: 0.052, indep loss:  -2.187, rf loss: 2.033\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 90\n",
      "Recon_loss: 0.051, indep loss:  -2.184, rf loss: 2.071\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 100\n",
      "Recon_loss: 0.051, indep loss:  -2.181, rf loss: 2.058\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 110\n",
      "Recon_loss: 0.052, indep loss:  -2.184, rf loss: 2.081\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 120\n",
      "Recon_loss: 0.052, indep loss:  -2.186, rf loss: 2.080\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 130\n",
      "Recon_loss: 0.052, indep loss:  -2.185, rf loss: 2.062\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 140\n",
      "Recon_loss: 0.052, indep loss:  -2.181, rf loss: 2.026\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 150\n",
      "Recon_loss: 0.052, indep loss:  -2.184, rf loss: 2.040\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 160\n",
      "Recon_loss: 0.052, indep loss:  -2.186, rf loss: 2.058\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 170\n",
      "Recon_loss: 0.052, indep loss:  -2.188, rf loss: 2.077\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 180\n",
      "Recon_loss: 0.052, indep loss:  -2.191, rf loss: 2.083\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 190\n",
      "Recon_loss: 0.052, indep loss:  -2.191, rf loss: 2.104\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 200\n",
      "Recon_loss: 0.052, indep loss:  -2.189, rf loss: 2.069\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 210\n",
      "Recon_loss: 0.052, indep loss:  -2.189, rf loss: 2.040\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 220\n",
      "Recon_loss: 0.052, indep loss:  -2.188, rf loss: 2.050\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 230\n",
      "Recon_loss: 0.052, indep loss:  -2.190, rf loss: 2.040\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 240\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.037\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 250\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.011\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 260\n",
      "Recon_loss: 0.052, indep loss:  -2.195, rf loss: 2.029\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 270\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.043\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 280\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.054\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 290\n",
      "Recon_loss: 0.052, indep loss:  -2.191, rf loss: 2.057\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 300\n",
      "Recon_loss: 0.052, indep loss:  -2.190, rf loss: 2.065\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 310\n",
      "Recon_loss: 0.052, indep loss:  -2.190, rf loss: 2.046\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 320\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.027\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 330\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 1.981\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 340\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 1.943\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 350\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 1.930\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 360\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 1.945\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 370\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 1.975\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 380\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 1.994\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 390\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 400\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.034\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 410\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.048\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 420\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.053\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 430\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.063\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 440\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.052\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 450\n",
      "Recon_loss: 0.052, indep loss:  -2.192, rf loss: 2.040\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 32/50, Step: 460\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.048\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 0\n",
      "Recon_loss: 0.051, indep loss:  -2.141, rf loss: 0.952\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 10\n",
      "Recon_loss: 0.051, indep loss:  -2.204, rf loss: 1.363\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 20\n",
      "Recon_loss: 0.051, indep loss:  -2.203, rf loss: 1.786\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 30\n",
      "Recon_loss: 0.050, indep loss:  -2.200, rf loss: 2.074\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 40\n",
      "Recon_loss: 0.051, indep loss:  -2.195, rf loss: 1.833\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 50\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.804\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 60\n",
      "Recon_loss: 0.050, indep loss:  -2.195, rf loss: 1.889\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 70\n",
      "Recon_loss: 0.050, indep loss:  -2.186, rf loss: 1.950\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 80\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 2.010\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 90\n",
      "Recon_loss: 0.051, indep loss:  -2.186, rf loss: 2.037\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 100\n",
      "Recon_loss: 0.051, indep loss:  -2.184, rf loss: 2.038\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 110\n",
      "Recon_loss: 0.051, indep loss:  -2.181, rf loss: 2.066\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 120\n",
      "Recon_loss: 0.051, indep loss:  -2.183, rf loss: 2.074\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 130\n",
      "Recon_loss: 0.051, indep loss:  -2.183, rf loss: 2.061\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 140\n",
      "Recon_loss: 0.051, indep loss:  -2.181, rf loss: 2.048\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 150\n",
      "Recon_loss: 0.052, indep loss:  -2.185, rf loss: 2.004\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 160\n",
      "Recon_loss: 0.052, indep loss:  -2.189, rf loss: 2.021\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 170\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 2.057\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 180\n",
      "Recon_loss: 0.052, indep loss:  -2.195, rf loss: 2.069\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 190\n",
      "Recon_loss: 0.052, indep loss:  -2.195, rf loss: 2.087\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 200\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 2.081\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 210\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 2.041\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 220\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 2.008\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 230\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 2.026\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 240\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 2.015\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 250\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.996\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 260\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 2.007\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 270\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 2.022\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 280\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 2.031\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 290\n",
      "Recon_loss: 0.051, indep loss:  -2.189, rf loss: 2.044\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 300\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 2.051\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 310\n",
      "Recon_loss: 0.051, indep loss:  -2.189, rf loss: 2.018\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 320\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 2.016\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 330\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 2.006\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 340\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 2.004\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 350\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 2.014\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 360\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 2.028\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 370\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 2.038\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 380\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.036\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 390\n",
      "Recon_loss: 0.052, indep loss:  -2.194, rf loss: 2.038\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 400\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.047\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 410\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.042\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 420\n",
      "Recon_loss: 0.052, indep loss:  -2.193, rf loss: 2.038\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 430\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 2.033\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 440\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 2.006\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 450\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.994\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 33/50, Step: 460\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 2.000\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 0\n",
      "Recon_loss: 0.051, indep loss:  -2.143, rf loss: 1.057\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 10\n",
      "Recon_loss: 0.051, indep loss:  -2.213, rf loss: 1.238\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 20\n",
      "Recon_loss: 0.051, indep loss:  -2.201, rf loss: 1.669\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 30\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.898\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 40\n",
      "Recon_loss: 0.051, indep loss:  -2.184, rf loss: 1.702\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 50\n",
      "Recon_loss: 0.050, indep loss:  -2.181, rf loss: 1.725\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 60\n",
      "Recon_loss: 0.050, indep loss:  -2.180, rf loss: 1.829\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 70\n",
      "Recon_loss: 0.050, indep loss:  -2.175, rf loss: 1.818\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 80\n",
      "Recon_loss: 0.050, indep loss:  -2.178, rf loss: 1.923\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 90\n",
      "Recon_loss: 0.050, indep loss:  -2.180, rf loss: 1.924\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 100\n",
      "Recon_loss: 0.050, indep loss:  -2.181, rf loss: 1.893\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 110\n",
      "Recon_loss: 0.051, indep loss:  -2.179, rf loss: 1.862\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 120\n",
      "Recon_loss: 0.051, indep loss:  -2.183, rf loss: 1.895\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 130\n",
      "Recon_loss: 0.051, indep loss:  -2.185, rf loss: 1.918\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 140\n",
      "Recon_loss: 0.051, indep loss:  -2.183, rf loss: 1.882\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 150\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.886\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 160\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.905\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 170\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.899\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 180\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.919\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 190\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.966\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 200\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.936\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 210\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.923\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 220\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.918\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 230\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.915\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 240\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.912\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 250\n",
      "Recon_loss: 0.051, indep loss:  -2.196, rf loss: 1.886\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 260\n",
      "Recon_loss: 0.051, indep loss:  -2.197, rf loss: 1.905\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 270\n",
      "Recon_loss: 0.051, indep loss:  -2.195, rf loss: 1.914\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 280\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.926\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 290\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.938\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 300\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.948\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 310\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 1.916\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 320\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.908\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 330\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 1.903\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 340\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.909\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 350\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.933\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 360\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.939\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 370\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.946\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 380\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.952\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 390\n",
      "Recon_loss: 0.051, indep loss:  -2.195, rf loss: 1.952\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 400\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.964\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 410\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.967\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 420\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.954\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 430\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.946\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 440\n",
      "Recon_loss: 0.051, indep loss:  -2.192, rf loss: 1.945\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 450\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.934\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 34/50, Step: 460\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.910\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 0\n",
      "Recon_loss: 0.050, indep loss:  -2.157, rf loss: 1.524\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 10\n",
      "Recon_loss: 0.050, indep loss:  -2.210, rf loss: 1.814\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 20\n",
      "Recon_loss: 0.050, indep loss:  -2.191, rf loss: 1.966\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 30\n",
      "Recon_loss: 0.050, indep loss:  -2.188, rf loss: 2.010\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 40\n",
      "Recon_loss: 0.050, indep loss:  -2.181, rf loss: 1.929\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 50\n",
      "Recon_loss: 0.050, indep loss:  -2.177, rf loss: 1.872\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 60\n",
      "Recon_loss: 0.050, indep loss:  -2.179, rf loss: 1.851\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 70\n",
      "Recon_loss: 0.050, indep loss:  -2.173, rf loss: 1.830\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 80\n",
      "Recon_loss: 0.050, indep loss:  -2.177, rf loss: 1.899\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 90\n",
      "Recon_loss: 0.050, indep loss:  -2.178, rf loss: 1.931\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 100\n",
      "Recon_loss: 0.050, indep loss:  -2.178, rf loss: 1.902\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 110\n",
      "Recon_loss: 0.050, indep loss:  -2.177, rf loss: 1.898\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 120\n",
      "Recon_loss: 0.051, indep loss:  -2.182, rf loss: 1.941\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 130\n",
      "Recon_loss: 0.051, indep loss:  -2.184, rf loss: 1.916\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 140\n",
      "Recon_loss: 0.051, indep loss:  -2.182, rf loss: 1.858\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 150\n",
      "Recon_loss: 0.051, indep loss:  -2.185, rf loss: 1.856\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 160\n",
      "Recon_loss: 0.051, indep loss:  -2.187, rf loss: 1.903\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 170\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.940\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 180\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 1.945\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 190\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 1.985\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 200\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.975\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 210\n",
      "Recon_loss: 0.051, indep loss:  -2.187, rf loss: 1.942\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 220\n",
      "Recon_loss: 0.051, indep loss:  -2.184, rf loss: 1.909\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 230\n",
      "Recon_loss: 0.051, indep loss:  -2.185, rf loss: 1.925\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 240\n",
      "Recon_loss: 0.051, indep loss:  -2.186, rf loss: 1.914\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 250\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.871\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 260\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 1.890\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 270\n",
      "Recon_loss: 0.051, indep loss:  -2.189, rf loss: 1.910\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 280\n",
      "Recon_loss: 0.051, indep loss:  -2.189, rf loss: 1.926\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 290\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.941\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 300\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.948\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 310\n",
      "Recon_loss: 0.051, indep loss:  -2.188, rf loss: 1.924\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 320\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.909\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 330\n",
      "Recon_loss: 0.051, indep loss:  -2.190, rf loss: 1.865\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 340\n",
      "Recon_loss: 0.051, indep loss:  -2.191, rf loss: 1.835\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 350\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.832\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 360\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.849\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 370\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.871\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 380\n",
      "Recon_loss: 0.051, indep loss:  -2.195, rf loss: 1.879\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 390\n",
      "Recon_loss: 0.051, indep loss:  -2.196, rf loss: 1.892\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 400\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.915\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 410\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.927\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 420\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.929\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 430\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.936\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 440\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.922\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 450\n",
      "Recon_loss: 0.051, indep loss:  -2.193, rf loss: 1.913\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 35/50, Step: 460\n",
      "Recon_loss: 0.051, indep loss:  -2.194, rf loss: 1.918\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 0\n",
      "Recon_loss: 0.050, indep loss:  -2.105, rf loss: 0.925\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 10\n",
      "Recon_loss: 0.050, indep loss:  -2.179, rf loss: 1.563\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 20\n",
      "Recon_loss: 0.050, indep loss:  -2.183, rf loss: 1.674\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 30\n",
      "Recon_loss: 0.049, indep loss:  -2.182, rf loss: 1.689\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 40\n",
      "Recon_loss: 0.050, indep loss:  -2.179, rf loss: 1.834\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 50\n",
      "Recon_loss: 0.049, indep loss:  -2.181, rf loss: 1.789\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 60\n",
      "Recon_loss: 0.049, indep loss:  -2.184, rf loss: 1.753\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 70\n",
      "Recon_loss: 0.049, indep loss:  -2.179, rf loss: 1.839\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 80\n",
      "Recon_loss: 0.050, indep loss:  -2.182, rf loss: 1.941\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 90\n",
      "Recon_loss: 0.049, indep loss:  -2.181, rf loss: 1.958\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 100\n",
      "Recon_loss: 0.049, indep loss:  -2.180, rf loss: 1.918\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 110\n",
      "Recon_loss: 0.050, indep loss:  -2.179, rf loss: 1.917\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 120\n",
      "Recon_loss: 0.050, indep loss:  -2.186, rf loss: 1.963\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 130\n",
      "Recon_loss: 0.050, indep loss:  -2.188, rf loss: 1.945\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 140\n",
      "Recon_loss: 0.050, indep loss:  -2.188, rf loss: 1.897\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 150\n",
      "Recon_loss: 0.050, indep loss:  -2.191, rf loss: 1.903\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 160\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.933\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 170\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.937\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 180\n",
      "Recon_loss: 0.050, indep loss:  -2.198, rf loss: 1.958\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 190\n",
      "Recon_loss: 0.050, indep loss:  -2.197, rf loss: 1.980\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 200\n",
      "Recon_loss: 0.050, indep loss:  -2.196, rf loss: 1.967\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 210\n",
      "Recon_loss: 0.050, indep loss:  -2.196, rf loss: 1.939\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 220\n",
      "Recon_loss: 0.050, indep loss:  -2.192, rf loss: 1.896\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 230\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.905\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 240\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.907\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 250\n",
      "Recon_loss: 0.050, indep loss:  -2.195, rf loss: 1.910\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 260\n",
      "Recon_loss: 0.050, indep loss:  -2.196, rf loss: 1.895\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 270\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.866\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 280\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.888\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 290\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.907\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 300\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.915\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 310\n",
      "Recon_loss: 0.050, indep loss:  -2.192, rf loss: 1.877\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 320\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.875\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 330\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.875\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 340\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.870\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 350\n",
      "Recon_loss: 0.050, indep loss:  -2.196, rf loss: 1.889\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 360\n",
      "Recon_loss: 0.050, indep loss:  -2.197, rf loss: 1.893\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 370\n",
      "Recon_loss: 0.050, indep loss:  -2.197, rf loss: 1.893\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 380\n",
      "Recon_loss: 0.050, indep loss:  -2.197, rf loss: 1.882\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 390\n",
      "Recon_loss: 0.050, indep loss:  -2.197, rf loss: 1.888\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 400\n",
      "Recon_loss: 0.050, indep loss:  -2.196, rf loss: 1.904\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 410\n",
      "Recon_loss: 0.050, indep loss:  -2.196, rf loss: 1.898\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 420\n",
      "Recon_loss: 0.050, indep loss:  -2.195, rf loss: 1.899\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 430\n",
      "Recon_loss: 0.050, indep loss:  -2.194, rf loss: 1.905\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 440\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.873\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 450\n",
      "Recon_loss: 0.050, indep loss:  -2.193, rf loss: 1.837\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 36/50, Step: 460\n",
      "Recon_loss: 0.050, indep loss:  -2.195, rf loss: 1.805\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  -2.118, rf loss: 0.580\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 10\n",
      "Recon_loss: 0.048, indep loss:  -2.206, rf loss: 1.005\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 20\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.290\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 30\n",
      "Recon_loss: 0.048, indep loss:  -2.195, rf loss: 1.553\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 40\n",
      "Recon_loss: 0.048, indep loss:  -2.191, rf loss: 1.785\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 50\n",
      "Recon_loss: 0.048, indep loss:  -2.192, rf loss: 1.792\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 60\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.786\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 70\n",
      "Recon_loss: 0.048, indep loss:  -2.194, rf loss: 1.908\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 80\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.979\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 90\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.993\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 100\n",
      "Recon_loss: 0.048, indep loss:  -2.194, rf loss: 1.992\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 110\n",
      "Recon_loss: 0.049, indep loss:  -2.192, rf loss: 2.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 120\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 2.030\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 130\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 2.028\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 140\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.993\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 150\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.969\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 160\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.984\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 170\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 2.001\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 180\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 2.003\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 190\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 2.013\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 200\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 2.003\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 210\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.977\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 220\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.952\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 230\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.941\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 240\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.933\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 250\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.919\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 260\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.925\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 270\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.932\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 280\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.933\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 290\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.943\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 300\n",
      "Recon_loss: 0.050, indep loss:  -2.199, rf loss: 1.944\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 310\n",
      "Recon_loss: 0.049, indep loss:  -2.198, rf loss: 1.909\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 320\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.902\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 330\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.879\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 340\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.879\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 350\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.897\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 360\n",
      "Recon_loss: 0.050, indep loss:  -2.205, rf loss: 1.905\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 370\n",
      "Recon_loss: 0.050, indep loss:  -2.205, rf loss: 1.904\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 380\n",
      "Recon_loss: 0.050, indep loss:  -2.206, rf loss: 1.902\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 390\n",
      "Recon_loss: 0.050, indep loss:  -2.206, rf loss: 1.899\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 400\n",
      "Recon_loss: 0.050, indep loss:  -2.205, rf loss: 1.907\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 410\n",
      "Recon_loss: 0.050, indep loss:  -2.203, rf loss: 1.908\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 420\n",
      "Recon_loss: 0.050, indep loss:  -2.202, rf loss: 1.893\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 430\n",
      "Recon_loss: 0.050, indep loss:  -2.201, rf loss: 1.885\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 440\n",
      "Recon_loss: 0.050, indep loss:  -2.201, rf loss: 1.879\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 450\n",
      "Recon_loss: 0.050, indep loss:  -2.201, rf loss: 1.874\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 37/50, Step: 460\n",
      "Recon_loss: 0.050, indep loss:  -2.203, rf loss: 1.856\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 0\n",
      "Recon_loss: 0.049, indep loss:  -2.155, rf loss: 0.935\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 10\n",
      "Recon_loss: 0.049, indep loss:  -2.233, rf loss: 1.842\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 20\n",
      "Recon_loss: 0.049, indep loss:  -2.213, rf loss: 1.727\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 30\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.566\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 40\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.617\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 50\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.629\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 60\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.652\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 70\n",
      "Recon_loss: 0.048, indep loss:  -2.195, rf loss: 1.679\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 80\n",
      "Recon_loss: 0.049, indep loss:  -2.195, rf loss: 1.762\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 90\n",
      "Recon_loss: 0.049, indep loss:  -2.192, rf loss: 1.803\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 100\n",
      "Recon_loss: 0.049, indep loss:  -2.187, rf loss: 1.790\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 110\n",
      "Recon_loss: 0.049, indep loss:  -2.186, rf loss: 1.827\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 120\n",
      "Recon_loss: 0.049, indep loss:  -2.192, rf loss: 1.843\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 130\n",
      "Recon_loss: 0.049, indep loss:  -2.194, rf loss: 1.814\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 140\n",
      "Recon_loss: 0.049, indep loss:  -2.194, rf loss: 1.777\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 150\n",
      "Recon_loss: 0.049, indep loss:  -2.196, rf loss: 1.783\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 160\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.806\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 170\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.803\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 180\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.820\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 190\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.850\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 200\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.823\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 210\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.799\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 220\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.785\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 230\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.773\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 240\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.763\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 250\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.749\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 260\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.759\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 270\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.770\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 280\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.776\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 290\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.783\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 300\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.783\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 310\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.761\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 320\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.752\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 330\n",
      "Recon_loss: 0.049, indep loss:  -2.198, rf loss: 1.740\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 340\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.742\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 350\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.757\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 360\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.754\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 370\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.760\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 380\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.759\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 390\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.753\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 400\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.756\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 410\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.759\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 420\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.759\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 430\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.763\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 440\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.738\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 450\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.729\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 38/50, Step: 460\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.734\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 0\n",
      "Recon_loss: 0.049, indep loss:  -2.117, rf loss: 0.340\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 10\n",
      "Recon_loss: 0.048, indep loss:  -2.186, rf loss: 0.615\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 20\n",
      "Recon_loss: 0.048, indep loss:  -2.170, rf loss: 0.726\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 30\n",
      "Recon_loss: 0.048, indep loss:  -2.169, rf loss: 0.840\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 40\n",
      "Recon_loss: 0.048, indep loss:  -2.175, rf loss: 1.185\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 50\n",
      "Recon_loss: 0.048, indep loss:  -2.184, rf loss: 1.375\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 60\n",
      "Recon_loss: 0.047, indep loss:  -2.189, rf loss: 1.452\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 70\n",
      "Recon_loss: 0.047, indep loss:  -2.184, rf loss: 1.534\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 80\n",
      "Recon_loss: 0.048, indep loss:  -2.193, rf loss: 1.659\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 90\n",
      "Recon_loss: 0.048, indep loss:  -2.193, rf loss: 1.710\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 100\n",
      "Recon_loss: 0.048, indep loss:  -2.190, rf loss: 1.738\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 110\n",
      "Recon_loss: 0.048, indep loss:  -2.191, rf loss: 1.747\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 120\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.775\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 130\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.759\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 140\n",
      "Recon_loss: 0.048, indep loss:  -2.205, rf loss: 1.741\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 150\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.736\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 160\n",
      "Recon_loss: 0.049, indep loss:  -2.210, rf loss: 1.759\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 170\n",
      "Recon_loss: 0.049, indep loss:  -2.211, rf loss: 1.767\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 180\n",
      "Recon_loss: 0.049, indep loss:  -2.214, rf loss: 1.768\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 190\n",
      "Recon_loss: 0.049, indep loss:  -2.213, rf loss: 1.787\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 200\n",
      "Recon_loss: 0.049, indep loss:  -2.211, rf loss: 1.773\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 210\n",
      "Recon_loss: 0.049, indep loss:  -2.212, rf loss: 1.745\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 220\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.718\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 230\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.718\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 240\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.707\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 250\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 1.687\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 260\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.693\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 270\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.711\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 280\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.710\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 290\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.724\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 300\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.741\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 310\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.701\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 320\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.694\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 330\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.697\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 340\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.700\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 350\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.716\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 360\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.741\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 370\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.739\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 380\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 1.730\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 390\n",
      "Recon_loss: 0.049, indep loss:  -2.209, rf loss: 1.740\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 400\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 1.757\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 410\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 1.760\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 420\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.760\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 430\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.764\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 440\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.739\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 450\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.729\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 39/50, Step: 460\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.739\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 0\n",
      "Recon_loss: 0.049, indep loss:  -2.136, rf loss: 0.388\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 10\n",
      "Recon_loss: 0.049, indep loss:  -2.169, rf loss: 1.012\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 20\n",
      "Recon_loss: 0.049, indep loss:  -2.160, rf loss: 1.379\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 30\n",
      "Recon_loss: 0.048, indep loss:  -2.148, rf loss: 1.596\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 40\n",
      "Recon_loss: 0.049, indep loss:  -2.164, rf loss: 1.334\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 50\n",
      "Recon_loss: 0.048, indep loss:  -2.180, rf loss: 1.298\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 60\n",
      "Recon_loss: 0.048, indep loss:  -2.183, rf loss: 1.348\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 70\n",
      "Recon_loss: 0.048, indep loss:  -2.183, rf loss: 1.491\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 80\n",
      "Recon_loss: 0.048, indep loss:  -2.191, rf loss: 1.629\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 90\n",
      "Recon_loss: 0.048, indep loss:  -2.193, rf loss: 1.690\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 100\n",
      "Recon_loss: 0.048, indep loss:  -2.187, rf loss: 1.711\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 110\n",
      "Recon_loss: 0.048, indep loss:  -2.185, rf loss: 1.744\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 120\n",
      "Recon_loss: 0.048, indep loss:  -2.192, rf loss: 1.786\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 130\n",
      "Recon_loss: 0.048, indep loss:  -2.193, rf loss: 1.781\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 140\n",
      "Recon_loss: 0.049, indep loss:  -2.196, rf loss: 1.764\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 150\n",
      "Recon_loss: 0.049, indep loss:  -2.199, rf loss: 1.783\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 160\n",
      "Recon_loss: 0.049, indep loss:  -2.200, rf loss: 1.780\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 170\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.793\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 180\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.806\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 190\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 1.833\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 200\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.812\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 210\n",
      "Recon_loss: 0.049, indep loss:  -2.208, rf loss: 1.784\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 220\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.770\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 230\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.771\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 240\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.755\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 250\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.726\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 260\n",
      "Recon_loss: 0.049, indep loss:  -2.207, rf loss: 1.732\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 270\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.751\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 280\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.753\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 290\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.755\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 300\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.750\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 310\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.720\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 320\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.709\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 330\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.700\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 340\n",
      "Recon_loss: 0.049, indep loss:  -2.201, rf loss: 1.705\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 350\n",
      "Recon_loss: 0.049, indep loss:  -2.202, rf loss: 1.721\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 360\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.732\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 370\n",
      "Recon_loss: 0.049, indep loss:  -2.203, rf loss: 1.740\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 380\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.733\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 390\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.735\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 400\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.745\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 410\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.745\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 420\n",
      "Recon_loss: 0.049, indep loss:  -2.205, rf loss: 1.743\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 430\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.742\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 440\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.720\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 450\n",
      "Recon_loss: 0.049, indep loss:  -2.204, rf loss: 1.720\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 40/50, Step: 460\n",
      "Recon_loss: 0.049, indep loss:  -2.206, rf loss: 1.729\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  -2.127, rf loss: 0.781\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 10\n",
      "Recon_loss: 0.049, indep loss:  -2.172, rf loss: 0.975\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 20\n",
      "Recon_loss: 0.048, indep loss:  -2.167, rf loss: 1.152\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 30\n",
      "Recon_loss: 0.047, indep loss:  -2.162, rf loss: 1.162\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 40\n",
      "Recon_loss: 0.048, indep loss:  -2.170, rf loss: 1.396\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 50\n",
      "Recon_loss: 0.047, indep loss:  -2.180, rf loss: 1.374\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 60\n",
      "Recon_loss: 0.047, indep loss:  -2.181, rf loss: 1.330\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 70\n",
      "Recon_loss: 0.047, indep loss:  -2.177, rf loss: 1.387\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 80\n",
      "Recon_loss: 0.047, indep loss:  -2.184, rf loss: 1.477\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 90\n",
      "Recon_loss: 0.047, indep loss:  -2.187, rf loss: 1.517\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 100\n",
      "Recon_loss: 0.047, indep loss:  -2.182, rf loss: 1.566\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 110\n",
      "Recon_loss: 0.047, indep loss:  -2.183, rf loss: 1.617\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 120\n",
      "Recon_loss: 0.047, indep loss:  -2.190, rf loss: 1.658\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 130\n",
      "Recon_loss: 0.047, indep loss:  -2.190, rf loss: 1.656\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 140\n",
      "Recon_loss: 0.048, indep loss:  -2.189, rf loss: 1.649\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 150\n",
      "Recon_loss: 0.048, indep loss:  -2.192, rf loss: 1.622\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 160\n",
      "Recon_loss: 0.048, indep loss:  -2.194, rf loss: 1.641\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 170\n",
      "Recon_loss: 0.048, indep loss:  -2.196, rf loss: 1.670\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 180\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.680\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 190\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.707\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 200\n",
      "Recon_loss: 0.048, indep loss:  -2.199, rf loss: 1.707\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 210\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.680\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 220\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.653\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 230\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.646\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 240\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.644\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 250\n",
      "Recon_loss: 0.048, indep loss:  -2.199, rf loss: 1.646\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 260\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.650\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 270\n",
      "Recon_loss: 0.048, indep loss:  -2.197, rf loss: 1.647\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 280\n",
      "Recon_loss: 0.048, indep loss:  -2.196, rf loss: 1.670\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 290\n",
      "Recon_loss: 0.048, indep loss:  -2.197, rf loss: 1.679\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 300\n",
      "Recon_loss: 0.048, indep loss:  -2.196, rf loss: 1.682\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 310\n",
      "Recon_loss: 0.048, indep loss:  -2.196, rf loss: 1.667\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 320\n",
      "Recon_loss: 0.048, indep loss:  -2.196, rf loss: 1.658\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 330\n",
      "Recon_loss: 0.048, indep loss:  -2.195, rf loss: 1.632\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 340\n",
      "Recon_loss: 0.048, indep loss:  -2.196, rf loss: 1.617\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 350\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.619\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 360\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.637\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 370\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.648\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 380\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.639\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 390\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.640\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 400\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.655\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 410\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.664\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 420\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.656\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 430\n",
      "Recon_loss: 0.048, indep loss:  -2.199, rf loss: 1.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 440\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.654\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 450\n",
      "Recon_loss: 0.048, indep loss:  -2.199, rf loss: 1.645\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 41/50, Step: 460\n",
      "Recon_loss: 0.048, indep loss:  -2.200, rf loss: 1.645\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  -2.181, rf loss: 0.862\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 10\n",
      "Recon_loss: 0.048, indep loss:  -2.197, rf loss: 1.234\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 20\n",
      "Recon_loss: 0.048, indep loss:  -2.188, rf loss: 1.503\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 30\n",
      "Recon_loss: 0.047, indep loss:  -2.174, rf loss: 1.578\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 40\n",
      "Recon_loss: 0.048, indep loss:  -2.182, rf loss: 1.410\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 50\n",
      "Recon_loss: 0.047, indep loss:  -2.185, rf loss: 1.389\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 60\n",
      "Recon_loss: 0.047, indep loss:  -2.189, rf loss: 1.409\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 70\n",
      "Recon_loss: 0.047, indep loss:  -2.183, rf loss: 1.467\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 80\n",
      "Recon_loss: 0.047, indep loss:  -2.190, rf loss: 1.573\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 90\n",
      "Recon_loss: 0.047, indep loss:  -2.193, rf loss: 1.605\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 100\n",
      "Recon_loss: 0.047, indep loss:  -2.190, rf loss: 1.599\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 110\n",
      "Recon_loss: 0.047, indep loss:  -2.188, rf loss: 1.589\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 120\n",
      "Recon_loss: 0.048, indep loss:  -2.193, rf loss: 1.634\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 130\n",
      "Recon_loss: 0.048, indep loss:  -2.193, rf loss: 1.616\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 140\n",
      "Recon_loss: 0.048, indep loss:  -2.192, rf loss: 1.574\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 150\n",
      "Recon_loss: 0.048, indep loss:  -2.195, rf loss: 1.573\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 160\n",
      "Recon_loss: 0.048, indep loss:  -2.198, rf loss: 1.607\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 170\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.630\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 180\n",
      "Recon_loss: 0.048, indep loss:  -2.206, rf loss: 1.630\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 190\n",
      "Recon_loss: 0.048, indep loss:  -2.207, rf loss: 1.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 200\n",
      "Recon_loss: 0.048, indep loss:  -2.208, rf loss: 1.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 210\n",
      "Recon_loss: 0.048, indep loss:  -2.210, rf loss: 1.631\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 220\n",
      "Recon_loss: 0.048, indep loss:  -2.208, rf loss: 1.595\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 230\n",
      "Recon_loss: 0.048, indep loss:  -2.208, rf loss: 1.597\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 240\n",
      "Recon_loss: 0.048, indep loss:  -2.209, rf loss: 1.595\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 250\n",
      "Recon_loss: 0.048, indep loss:  -2.210, rf loss: 1.587\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 260\n",
      "Recon_loss: 0.048, indep loss:  -2.208, rf loss: 1.603\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 270\n",
      "Recon_loss: 0.048, indep loss:  -2.206, rf loss: 1.614\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 280\n",
      "Recon_loss: 0.048, indep loss:  -2.205, rf loss: 1.619\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 290\n",
      "Recon_loss: 0.048, indep loss:  -2.205, rf loss: 1.641\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 300\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.654\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 310\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.625\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 320\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.624\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 330\n",
      "Recon_loss: 0.048, indep loss:  -2.202, rf loss: 1.627\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 340\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.625\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 350\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.635\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 360\n",
      "Recon_loss: 0.048, indep loss:  -2.204, rf loss: 1.655\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 370\n",
      "Recon_loss: 0.048, indep loss:  -2.204, rf loss: 1.659\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 380\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.643\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 390\n",
      "Recon_loss: 0.048, indep loss:  -2.204, rf loss: 1.653\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 400\n",
      "Recon_loss: 0.048, indep loss:  -2.204, rf loss: 1.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 410\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.661\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 420\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.656\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 430\n",
      "Recon_loss: 0.048, indep loss:  -2.202, rf loss: 1.666\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 440\n",
      "Recon_loss: 0.048, indep loss:  -2.202, rf loss: 1.634\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 450\n",
      "Recon_loss: 0.048, indep loss:  -2.203, rf loss: 1.613\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 42/50, Step: 460\n",
      "Recon_loss: 0.048, indep loss:  -2.205, rf loss: 1.612\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  -2.152, rf loss: 1.194\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 10\n",
      "Recon_loss: 0.048, indep loss:  -2.171, rf loss: 1.589\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 20\n",
      "Recon_loss: 0.047, indep loss:  -2.159, rf loss: 1.634\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 30\n",
      "Recon_loss: 0.047, indep loss:  -2.165, rf loss: 1.667\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 40\n",
      "Recon_loss: 0.047, indep loss:  -2.177, rf loss: 1.562\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 50\n",
      "Recon_loss: 0.047, indep loss:  -2.187, rf loss: 1.519\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 60\n",
      "Recon_loss: 0.047, indep loss:  -2.188, rf loss: 1.469\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 70\n",
      "Recon_loss: 0.047, indep loss:  -2.186, rf loss: 1.549\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 80\n",
      "Recon_loss: 0.047, indep loss:  -2.193, rf loss: 1.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 90\n",
      "Recon_loss: 0.047, indep loss:  -2.196, rf loss: 1.668\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 100\n",
      "Recon_loss: 0.047, indep loss:  -2.196, rf loss: 1.651\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 110\n",
      "Recon_loss: 0.047, indep loss:  -2.194, rf loss: 1.665\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 120\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.709\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 130\n",
      "Recon_loss: 0.048, indep loss:  -2.201, rf loss: 1.690\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 140\n",
      "Recon_loss: 0.048, indep loss:  -2.202, rf loss: 1.630\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 150\n",
      "Recon_loss: 0.048, indep loss:  -2.204, rf loss: 1.632\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 160\n",
      "Recon_loss: 0.048, indep loss:  -2.207, rf loss: 1.651\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 170\n",
      "Recon_loss: 0.048, indep loss:  -2.213, rf loss: 1.674\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 180\n",
      "Recon_loss: 0.048, indep loss:  -2.215, rf loss: 1.680\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 190\n",
      "Recon_loss: 0.048, indep loss:  -2.216, rf loss: 1.703\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 200\n",
      "Recon_loss: 0.048, indep loss:  -2.216, rf loss: 1.682\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 210\n",
      "Recon_loss: 0.048, indep loss:  -2.218, rf loss: 1.666\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 220\n",
      "Recon_loss: 0.048, indep loss:  -2.215, rf loss: 1.650\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 230\n",
      "Recon_loss: 0.048, indep loss:  -2.215, rf loss: 1.641\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 240\n",
      "Recon_loss: 0.048, indep loss:  -2.217, rf loss: 1.629\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 250\n",
      "Recon_loss: 0.048, indep loss:  -2.218, rf loss: 1.624\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 260\n",
      "Recon_loss: 0.048, indep loss:  -2.216, rf loss: 1.635\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 270\n",
      "Recon_loss: 0.048, indep loss:  -2.215, rf loss: 1.641\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 280\n",
      "Recon_loss: 0.048, indep loss:  -2.213, rf loss: 1.621\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 290\n",
      "Recon_loss: 0.048, indep loss:  -2.213, rf loss: 1.628\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 300\n",
      "Recon_loss: 0.048, indep loss:  -2.210, rf loss: 1.651\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 310\n",
      "Recon_loss: 0.048, indep loss:  -2.209, rf loss: 1.620\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 320\n",
      "Recon_loss: 0.048, indep loss:  -2.209, rf loss: 1.615\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 330\n",
      "Recon_loss: 0.048, indep loss:  -2.208, rf loss: 1.625\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 340\n",
      "Recon_loss: 0.048, indep loss:  -2.209, rf loss: 1.626\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 350\n",
      "Recon_loss: 0.048, indep loss:  -2.211, rf loss: 1.642\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 360\n",
      "Recon_loss: 0.048, indep loss:  -2.214, rf loss: 1.650\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 370\n",
      "Recon_loss: 0.048, indep loss:  -2.214, rf loss: 1.659\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 380\n",
      "Recon_loss: 0.048, indep loss:  -2.214, rf loss: 1.653\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 390\n",
      "Recon_loss: 0.048, indep loss:  -2.215, rf loss: 1.651\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 400\n",
      "Recon_loss: 0.048, indep loss:  -2.215, rf loss: 1.670\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 410\n",
      "Recon_loss: 0.048, indep loss:  -2.214, rf loss: 1.669\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 420\n",
      "Recon_loss: 0.048, indep loss:  -2.214, rf loss: 1.660\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 430\n",
      "Recon_loss: 0.048, indep loss:  -2.213, rf loss: 1.664\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 440\n",
      "Recon_loss: 0.048, indep loss:  -2.213, rf loss: 1.648\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 450\n",
      "Recon_loss: 0.048, indep loss:  -2.213, rf loss: 1.642\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 43/50, Step: 460\n",
      "Recon_loss: 0.048, indep loss:  -2.214, rf loss: 1.640\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 0\n",
      "Recon_loss: 0.048, indep loss:  -2.141, rf loss: 0.320\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 10\n",
      "Recon_loss: 0.047, indep loss:  -2.171, rf loss: 1.339\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 20\n",
      "Recon_loss: 0.047, indep loss:  -2.164, rf loss: 1.184\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 30\n",
      "Recon_loss: 0.046, indep loss:  -2.157, rf loss: 0.997\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 40\n",
      "Recon_loss: 0.046, indep loss:  -2.176, rf loss: 1.024\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 50\n",
      "Recon_loss: 0.046, indep loss:  -2.187, rf loss: 1.062\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 60\n",
      "Recon_loss: 0.046, indep loss:  -2.191, rf loss: 1.131\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 70\n",
      "Recon_loss: 0.046, indep loss:  -2.194, rf loss: 1.264\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 80\n",
      "Recon_loss: 0.046, indep loss:  -2.198, rf loss: 1.428\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 90\n",
      "Recon_loss: 0.046, indep loss:  -2.200, rf loss: 1.509\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 100\n",
      "Recon_loss: 0.046, indep loss:  -2.197, rf loss: 1.551\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 110\n",
      "Recon_loss: 0.046, indep loss:  -2.195, rf loss: 1.584\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 120\n",
      "Recon_loss: 0.047, indep loss:  -2.198, rf loss: 1.611\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 130\n",
      "Recon_loss: 0.047, indep loss:  -2.199, rf loss: 1.602\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 140\n",
      "Recon_loss: 0.047, indep loss:  -2.197, rf loss: 1.584\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 150\n",
      "Recon_loss: 0.047, indep loss:  -2.198, rf loss: 1.572\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 160\n",
      "Recon_loss: 0.047, indep loss:  -2.200, rf loss: 1.599\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 170\n",
      "Recon_loss: 0.047, indep loss:  -2.203, rf loss: 1.647\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 180\n",
      "Recon_loss: 0.047, indep loss:  -2.206, rf loss: 1.656\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 190\n",
      "Recon_loss: 0.047, indep loss:  -2.207, rf loss: 1.692\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 200\n",
      "Recon_loss: 0.047, indep loss:  -2.207, rf loss: 1.687\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 210\n",
      "Recon_loss: 0.047, indep loss:  -2.209, rf loss: 1.672\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 220\n",
      "Recon_loss: 0.047, indep loss:  -2.207, rf loss: 1.655\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 230\n",
      "Recon_loss: 0.047, indep loss:  -2.206, rf loss: 1.652\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 240\n",
      "Recon_loss: 0.047, indep loss:  -2.208, rf loss: 1.643\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 250\n",
      "Recon_loss: 0.047, indep loss:  -2.208, rf loss: 1.640\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 260\n",
      "Recon_loss: 0.047, indep loss:  -2.207, rf loss: 1.658\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 270\n",
      "Recon_loss: 0.047, indep loss:  -2.206, rf loss: 1.674\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 280\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.659\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 290\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.674\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 300\n",
      "Recon_loss: 0.047, indep loss:  -2.201, rf loss: 1.677\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 310\n",
      "Recon_loss: 0.047, indep loss:  -2.201, rf loss: 1.652\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 320\n",
      "Recon_loss: 0.047, indep loss:  -2.201, rf loss: 1.649\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 330\n",
      "Recon_loss: 0.047, indep loss:  -2.202, rf loss: 1.646\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 340\n",
      "Recon_loss: 0.047, indep loss:  -2.202, rf loss: 1.638\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 350\n",
      "Recon_loss: 0.047, indep loss:  -2.204, rf loss: 1.649\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 360\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.655\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 370\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 380\n",
      "Recon_loss: 0.047, indep loss:  -2.203, rf loss: 1.661\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 390\n",
      "Recon_loss: 0.047, indep loss:  -2.204, rf loss: 1.662\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 400\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.675\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 410\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.670\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 420\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.662\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 430\n",
      "Recon_loss: 0.047, indep loss:  -2.205, rf loss: 1.665\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 440\n",
      "Recon_loss: 0.047, indep loss:  -2.206, rf loss: 1.648\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 450\n",
      "Recon_loss: 0.047, indep loss:  -2.206, rf loss: 1.643\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 44/50, Step: 460\n",
      "Recon_loss: 0.047, indep loss:  -2.209, rf loss: 1.642\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 0\n",
      "Recon_loss: 0.047, indep loss:  -2.152, rf loss: 0.566\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 10\n",
      "Recon_loss: 0.048, indep loss:  -2.173, rf loss: 1.068\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 20\n",
      "Recon_loss: 0.047, indep loss:  -2.170, rf loss: 1.296\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 30\n",
      "Recon_loss: 0.046, indep loss:  -2.151, rf loss: 1.368\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 40\n",
      "Recon_loss: 0.047, indep loss:  -2.160, rf loss: 1.327\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 50\n",
      "Recon_loss: 0.046, indep loss:  -2.168, rf loss: 1.311\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 60\n",
      "Recon_loss: 0.046, indep loss:  -2.167, rf loss: 1.325\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 70\n",
      "Recon_loss: 0.046, indep loss:  -2.166, rf loss: 1.408\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 80\n",
      "Recon_loss: 0.046, indep loss:  -2.171, rf loss: 1.491\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 90\n",
      "Recon_loss: 0.046, indep loss:  -2.171, rf loss: 1.549\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 100\n",
      "Recon_loss: 0.046, indep loss:  -2.170, rf loss: 1.547\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 110\n",
      "Recon_loss: 0.047, indep loss:  -2.171, rf loss: 1.554\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 120\n",
      "Recon_loss: 0.047, indep loss:  -2.176, rf loss: 1.591\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 130\n",
      "Recon_loss: 0.047, indep loss:  -2.180, rf loss: 1.593\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 140\n",
      "Recon_loss: 0.047, indep loss:  -2.180, rf loss: 1.540\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 150\n",
      "Recon_loss: 0.047, indep loss:  -2.184, rf loss: 1.552\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 160\n",
      "Recon_loss: 0.047, indep loss:  -2.188, rf loss: 1.586\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 170\n",
      "Recon_loss: 0.047, indep loss:  -2.192, rf loss: 1.628\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 180\n",
      "Recon_loss: 0.047, indep loss:  -2.194, rf loss: 1.640\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 190\n",
      "Recon_loss: 0.047, indep loss:  -2.193, rf loss: 1.654\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 200\n",
      "Recon_loss: 0.047, indep loss:  -2.193, rf loss: 1.637\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 210\n",
      "Recon_loss: 0.047, indep loss:  -2.194, rf loss: 1.625\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 220\n",
      "Recon_loss: 0.047, indep loss:  -2.192, rf loss: 1.614\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 230\n",
      "Recon_loss: 0.047, indep loss:  -2.191, rf loss: 1.599\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 240\n",
      "Recon_loss: 0.047, indep loss:  -2.193, rf loss: 1.587\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 250\n",
      "Recon_loss: 0.047, indep loss:  -2.195, rf loss: 1.591\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 260\n",
      "Recon_loss: 0.047, indep loss:  -2.195, rf loss: 1.592\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 270\n",
      "Recon_loss: 0.047, indep loss:  -2.194, rf loss: 1.582\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 280\n",
      "Recon_loss: 0.047, indep loss:  -2.195, rf loss: 1.611\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 290\n",
      "Recon_loss: 0.047, indep loss:  -2.196, rf loss: 1.623\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 300\n",
      "Recon_loss: 0.047, indep loss:  -2.193, rf loss: 1.626\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 310\n",
      "Recon_loss: 0.047, indep loss:  -2.193, rf loss: 1.625\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 320\n",
      "Recon_loss: 0.047, indep loss:  -2.194, rf loss: 1.618\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 330\n",
      "Recon_loss: 0.047, indep loss:  -2.194, rf loss: 1.594\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 340\n",
      "Recon_loss: 0.047, indep loss:  -2.196, rf loss: 1.559\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 350\n",
      "Recon_loss: 0.047, indep loss:  -2.198, rf loss: 1.526\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 360\n",
      "Recon_loss: 0.047, indep loss:  -2.200, rf loss: 1.497\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 370\n",
      "Recon_loss: 0.047, indep loss:  -2.200, rf loss: 1.481\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 380\n",
      "Recon_loss: 0.047, indep loss:  -2.199, rf loss: 1.461\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 390\n",
      "Recon_loss: 0.047, indep loss:  -2.199, rf loss: 1.451\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 400\n",
      "Recon_loss: 0.047, indep loss:  -2.199, rf loss: 1.458\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 410\n",
      "Recon_loss: 0.047, indep loss:  -2.198, rf loss: 1.467\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 420\n",
      "Recon_loss: 0.047, indep loss:  -2.199, rf loss: 1.473\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 430\n",
      "Recon_loss: 0.047, indep loss:  -2.200, rf loss: 1.493\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 440\n",
      "Recon_loss: 0.047, indep loss:  -2.202, rf loss: 1.498\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 450\n",
      "Recon_loss: 0.047, indep loss:  -2.204, rf loss: 1.505\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 45/50, Step: 460\n",
      "Recon_loss: 0.047, indep loss:  -2.207, rf loss: 1.512\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  -2.167, rf loss: 1.285\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 10\n",
      "Recon_loss: 0.046, indep loss:  -2.191, rf loss: 1.681\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 20\n",
      "Recon_loss: 0.046, indep loss:  -2.185, rf loss: 1.526\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 30\n",
      "Recon_loss: 0.045, indep loss:  -2.180, rf loss: 1.462\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 40\n",
      "Recon_loss: 0.046, indep loss:  -2.192, rf loss: 1.612\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 50\n",
      "Recon_loss: 0.045, indep loss:  -2.196, rf loss: 1.644\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 60\n",
      "Recon_loss: 0.045, indep loss:  -2.194, rf loss: 1.636\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 70\n",
      "Recon_loss: 0.045, indep loss:  -2.190, rf loss: 1.680\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 80\n",
      "Recon_loss: 0.045, indep loss:  -2.193, rf loss: 1.730\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 90\n",
      "Recon_loss: 0.045, indep loss:  -2.189, rf loss: 1.736\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 100\n",
      "Recon_loss: 0.045, indep loss:  -2.188, rf loss: 1.737\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 110\n",
      "Recon_loss: 0.045, indep loss:  -2.189, rf loss: 1.765\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 120\n",
      "Recon_loss: 0.046, indep loss:  -2.194, rf loss: 1.782\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 130\n",
      "Recon_loss: 0.046, indep loss:  -2.196, rf loss: 1.769\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 140\n",
      "Recon_loss: 0.046, indep loss:  -2.193, rf loss: 1.754\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 150\n",
      "Recon_loss: 0.046, indep loss:  -2.198, rf loss: 1.717\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 160\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.726\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 170\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.746\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 180\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.762\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 190\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.779\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 200\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.781\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 210\n",
      "Recon_loss: 0.046, indep loss:  -2.212, rf loss: 1.749\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 220\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.718\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 230\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.716\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 240\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.708\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 250\n",
      "Recon_loss: 0.046, indep loss:  -2.212, rf loss: 1.703\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 260\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.709\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 270\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.715\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 280\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.708\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 290\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.710\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 300\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.707\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 310\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.680\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 320\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.686\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 330\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.688\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 340\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.683\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 350\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.688\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 360\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.700\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 370\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.707\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 380\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.703\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 390\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.699\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 400\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.707\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 410\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.698\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 420\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.692\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 430\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.699\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 440\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.680\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 450\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.663\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 46/50, Step: 460\n",
      "Recon_loss: 0.046, indep loss:  -2.212, rf loss: 1.655\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  -2.177, rf loss: 0.916\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 10\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.302\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 20\n",
      "Recon_loss: 0.046, indep loss:  -2.193, rf loss: 1.547\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 30\n",
      "Recon_loss: 0.045, indep loss:  -2.181, rf loss: 1.727\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 40\n",
      "Recon_loss: 0.046, indep loss:  -2.188, rf loss: 1.499\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 50\n",
      "Recon_loss: 0.046, indep loss:  -2.194, rf loss: 1.445\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 60\n",
      "Recon_loss: 0.045, indep loss:  -2.191, rf loss: 1.449\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 70\n",
      "Recon_loss: 0.045, indep loss:  -2.194, rf loss: 1.491\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 80\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.587\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 90\n",
      "Recon_loss: 0.046, indep loss:  -2.204, rf loss: 1.616\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 100\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.594\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 110\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.598\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 120\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.632\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 130\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.617\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 140\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.561\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 150\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.569\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 160\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.591\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 170\n",
      "Recon_loss: 0.046, indep loss:  -2.214, rf loss: 1.621\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 180\n",
      "Recon_loss: 0.046, indep loss:  -2.214, rf loss: 1.635\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 190\n",
      "Recon_loss: 0.046, indep loss:  -2.214, rf loss: 1.652\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 200\n",
      "Recon_loss: 0.046, indep loss:  -2.212, rf loss: 1.645\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 210\n",
      "Recon_loss: 0.046, indep loss:  -2.213, rf loss: 1.617\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 220\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.596\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 230\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.596\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 240\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.585\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 250\n",
      "Recon_loss: 0.046, indep loss:  -2.212, rf loss: 1.569\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 260\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.580\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 270\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.587\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 280\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.590\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 290\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.606\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 300\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.609\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 310\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.579\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 320\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.583\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 330\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.593\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 340\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.601\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 350\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.615\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 360\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.611\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 370\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.620\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 380\n",
      "Recon_loss: 0.047, indep loss:  -2.209, rf loss: 1.622\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 390\n",
      "Recon_loss: 0.047, indep loss:  -2.209, rf loss: 1.621\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 400\n",
      "Recon_loss: 0.047, indep loss:  -2.208, rf loss: 1.625\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 410\n",
      "Recon_loss: 0.047, indep loss:  -2.208, rf loss: 1.623\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 420\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.619\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 430\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.629\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 440\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.607\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 450\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.602\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 47/50, Step: 460\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.608\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  -2.180, rf loss: 0.208\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 10\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 0.386\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 20\n",
      "Recon_loss: 0.046, indep loss:  -2.191, rf loss: 0.799\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 30\n",
      "Recon_loss: 0.045, indep loss:  -2.185, rf loss: 1.207\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 40\n",
      "Recon_loss: 0.045, indep loss:  -2.187, rf loss: 1.214\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 50\n",
      "Recon_loss: 0.045, indep loss:  -2.194, rf loss: 1.256\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 60\n",
      "Recon_loss: 0.045, indep loss:  -2.191, rf loss: 1.286\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 70\n",
      "Recon_loss: 0.045, indep loss:  -2.192, rf loss: 1.344\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 80\n",
      "Recon_loss: 0.045, indep loss:  -2.201, rf loss: 1.407\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 90\n",
      "Recon_loss: 0.045, indep loss:  -2.199, rf loss: 1.467\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 100\n",
      "Recon_loss: 0.045, indep loss:  -2.198, rf loss: 1.478\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 110\n",
      "Recon_loss: 0.045, indep loss:  -2.198, rf loss: 1.480\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 120\n",
      "Recon_loss: 0.046, indep loss:  -2.205, rf loss: 1.505\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 130\n",
      "Recon_loss: 0.046, indep loss:  -2.205, rf loss: 1.499\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 140\n",
      "Recon_loss: 0.046, indep loss:  -2.201, rf loss: 1.441\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 150\n",
      "Recon_loss: 0.046, indep loss:  -2.201, rf loss: 1.463\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 160\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.494\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 170\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.524\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 180\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.535\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 190\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.548\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 200\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.545\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 210\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.515\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 220\n",
      "Recon_loss: 0.046, indep loss:  -2.205, rf loss: 1.489\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 230\n",
      "Recon_loss: 0.046, indep loss:  -2.205, rf loss: 1.500\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 240\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.504\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 250\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.486\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 260\n",
      "Recon_loss: 0.046, indep loss:  -2.209, rf loss: 1.505\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 270\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.525\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 280\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.519\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 290\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.528\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 300\n",
      "Recon_loss: 0.046, indep loss:  -2.205, rf loss: 1.545\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 310\n",
      "Recon_loss: 0.046, indep loss:  -2.204, rf loss: 1.522\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 320\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.525\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 330\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.520\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 340\n",
      "Recon_loss: 0.046, indep loss:  -2.205, rf loss: 1.524\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 350\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.547\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 360\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.559\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 370\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.568\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 380\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.561\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 390\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.562\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 400\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.572\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 410\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.563\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 420\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.558\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 430\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.568\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 440\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.538\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 450\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.525\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 48/50, Step: 460\n",
      "Recon_loss: 0.046, indep loss:  -2.208, rf loss: 1.530\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 0\n",
      "Recon_loss: 0.046, indep loss:  -2.158, rf loss: 0.828\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 10\n",
      "Recon_loss: 0.046, indep loss:  -2.173, rf loss: 1.272\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 20\n",
      "Recon_loss: 0.046, indep loss:  -2.162, rf loss: 1.485\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 30\n",
      "Recon_loss: 0.045, indep loss:  -2.160, rf loss: 1.558\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 40\n",
      "Recon_loss: 0.046, indep loss:  -2.168, rf loss: 1.413\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 50\n",
      "Recon_loss: 0.045, indep loss:  -2.178, rf loss: 1.377\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 60\n",
      "Recon_loss: 0.045, indep loss:  -2.173, rf loss: 1.383\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 70\n",
      "Recon_loss: 0.045, indep loss:  -2.171, rf loss: 1.423\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 80\n",
      "Recon_loss: 0.045, indep loss:  -2.183, rf loss: 1.481\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 90\n",
      "Recon_loss: 0.045, indep loss:  -2.186, rf loss: 1.487\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 100\n",
      "Recon_loss: 0.045, indep loss:  -2.187, rf loss: 1.499\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 110\n",
      "Recon_loss: 0.045, indep loss:  -2.189, rf loss: 1.524\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 120\n",
      "Recon_loss: 0.046, indep loss:  -2.197, rf loss: 1.527\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 130\n",
      "Recon_loss: 0.046, indep loss:  -2.197, rf loss: 1.530\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 140\n",
      "Recon_loss: 0.046, indep loss:  -2.194, rf loss: 1.486\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 150\n",
      "Recon_loss: 0.046, indep loss:  -2.195, rf loss: 1.491\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 160\n",
      "Recon_loss: 0.046, indep loss:  -2.197, rf loss: 1.508\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 170\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.526\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 180\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.539\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 190\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.558\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 200\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.559\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 210\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.540\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 220\n",
      "Recon_loss: 0.046, indep loss:  -2.201, rf loss: 1.521\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 230\n",
      "Recon_loss: 0.046, indep loss:  -2.200, rf loss: 1.527\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 240\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.528\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 250\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.516\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 260\n",
      "Recon_loss: 0.046, indep loss:  -2.203, rf loss: 1.538\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 270\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.547\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 280\n",
      "Recon_loss: 0.046, indep loss:  -2.200, rf loss: 1.550\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 290\n",
      "Recon_loss: 0.046, indep loss:  -2.199, rf loss: 1.558\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 300\n",
      "Recon_loss: 0.046, indep loss:  -2.197, rf loss: 1.569\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 310\n",
      "Recon_loss: 0.046, indep loss:  -2.196, rf loss: 1.552\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 320\n",
      "Recon_loss: 0.046, indep loss:  -2.197, rf loss: 1.538\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 330\n",
      "Recon_loss: 0.046, indep loss:  -2.197, rf loss: 1.534\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 340\n",
      "Recon_loss: 0.046, indep loss:  -2.199, rf loss: 1.525\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 350\n",
      "Recon_loss: 0.046, indep loss:  -2.201, rf loss: 1.533\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 360\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.538\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 370\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.545\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 380\n",
      "Recon_loss: 0.046, indep loss:  -2.201, rf loss: 1.542\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 390\n",
      "Recon_loss: 0.046, indep loss:  -2.201, rf loss: 1.538\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 400\n",
      "Recon_loss: 0.046, indep loss:  -2.200, rf loss: 1.553\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 410\n",
      "Recon_loss: 0.046, indep loss:  -2.200, rf loss: 1.549\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 420\n",
      "Recon_loss: 0.046, indep loss:  -2.200, rf loss: 1.544\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 430\n",
      "Recon_loss: 0.046, indep loss:  -2.200, rf loss: 1.551\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 440\n",
      "Recon_loss: 0.046, indep loss:  -2.201, rf loss: 1.530\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 450\n",
      "Recon_loss: 0.046, indep loss:  -2.202, rf loss: 1.524\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 49/50, Step: 460\n",
      "Recon_loss: 0.046, indep loss:  -2.204, rf loss: 1.528\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 0\n",
      "Recon_loss: 0.045, indep loss:  -2.178, rf loss: 0.388\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 10\n",
      "Recon_loss: 0.046, indep loss:  -2.192, rf loss: 0.965\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 20\n",
      "Recon_loss: 0.045, indep loss:  -2.176, rf loss: 1.264\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 30\n",
      "Recon_loss: 0.044, indep loss:  -2.170, rf loss: 1.411\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 40\n",
      "Recon_loss: 0.045, indep loss:  -2.186, rf loss: 1.341\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 50\n",
      "Recon_loss: 0.045, indep loss:  -2.194, rf loss: 1.328\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 60\n",
      "Recon_loss: 0.045, indep loss:  -2.194, rf loss: 1.321\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 70\n",
      "Recon_loss: 0.044, indep loss:  -2.189, rf loss: 1.380\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 80\n",
      "Recon_loss: 0.045, indep loss:  -2.199, rf loss: 1.441\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 90\n",
      "Recon_loss: 0.045, indep loss:  -2.197, rf loss: 1.463\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 100\n",
      "Recon_loss: 0.045, indep loss:  -2.196, rf loss: 1.462\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 110\n",
      "Recon_loss: 0.045, indep loss:  -2.194, rf loss: 1.484\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 120\n",
      "Recon_loss: 0.045, indep loss:  -2.199, rf loss: 1.492\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 130\n",
      "Recon_loss: 0.045, indep loss:  -2.199, rf loss: 1.488\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 140\n",
      "Recon_loss: 0.045, indep loss:  -2.195, rf loss: 1.445\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 150\n",
      "Recon_loss: 0.045, indep loss:  -2.196, rf loss: 1.444\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 160\n",
      "Recon_loss: 0.045, indep loss:  -2.197, rf loss: 1.476\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 170\n",
      "Recon_loss: 0.045, indep loss:  -2.204, rf loss: 1.498\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 180\n",
      "Recon_loss: 0.046, indep loss:  -2.207, rf loss: 1.509\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 190\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.538\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 200\n",
      "Recon_loss: 0.046, indep loss:  -2.206, rf loss: 1.525\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 210\n",
      "Recon_loss: 0.045, indep loss:  -2.206, rf loss: 1.511\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 220\n",
      "Recon_loss: 0.045, indep loss:  -2.205, rf loss: 1.500\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 230\n",
      "Recon_loss: 0.045, indep loss:  -2.203, rf loss: 1.473\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 240\n",
      "Recon_loss: 0.045, indep loss:  -2.206, rf loss: 1.472\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 250\n",
      "Recon_loss: 0.045, indep loss:  -2.209, rf loss: 1.477\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 260\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.469\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 270\n",
      "Recon_loss: 0.045, indep loss:  -2.210, rf loss: 1.457\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 280\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.479\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 290\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.486\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 300\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.470\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 310\n",
      "Recon_loss: 0.045, indep loss:  -2.209, rf loss: 1.475\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 320\n",
      "Recon_loss: 0.045, indep loss:  -2.209, rf loss: 1.467\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 330\n",
      "Recon_loss: 0.045, indep loss:  -2.208, rf loss: 1.432\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 340\n",
      "Recon_loss: 0.045, indep loss:  -2.209, rf loss: 1.398\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 350\n",
      "Recon_loss: 0.045, indep loss:  -2.211, rf loss: 1.371\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 360\n",
      "Recon_loss: 0.045, indep loss:  -2.211, rf loss: 1.349\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 370\n",
      "Recon_loss: 0.046, indep loss:  -2.211, rf loss: 1.343\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 380\n",
      "Recon_loss: 0.046, indep loss:  -2.210, rf loss: 1.330\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 390\n",
      "Recon_loss: 0.045, indep loss:  -2.211, rf loss: 1.331\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 400\n",
      "Recon_loss: 0.045, indep loss:  -2.210, rf loss: 1.345\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 410\n",
      "Recon_loss: 0.045, indep loss:  -2.210, rf loss: 1.358\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 420\n",
      "Recon_loss: 0.045, indep loss:  -2.210, rf loss: 1.368\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 430\n",
      "Recon_loss: 0.045, indep loss:  -2.210, rf loss: 1.389\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 440\n",
      "Recon_loss: 0.045, indep loss:  -2.210, rf loss: 1.385\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 450\n",
      "Recon_loss: 0.045, indep loss:  -2.211, rf loss: 1.398\n",
      "Learning rate = 0.0010000\n",
      "Epoch: 50/50, Step: 460\n",
      "Recon_loss: 0.045, indep loss:  -2.213, rf loss: 1.418\n",
      "Learning rate = 0.0010000\n",
      "Finished training \n",
      "Running test\n",
      "Test results: \n",
      "Recon_loss: 0.055, indep loss:  -2.078, rf loss:  0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 144 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()\n",
    "test()\n",
    "analyze_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKiNmoXBMtMj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colored_mnist_official.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "059f8d94a03b45f4a40821f86a5e4c9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06afab79fa1c442d90f6cf5087f3e036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef5a4fdd3b394448ab6c013ee57ef751",
       "IPY_MODEL_1f5684552cce4dd7b7347b347dfd9111",
       "IPY_MODEL_690f7236232647edac94410517b353ed"
      ],
      "layout": "IPY_MODEL_468c17e39ec94dad8adf9afdde3d5031"
     }
    },
    "0729bb3bb62a454e97b022937b43eccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "07c6ea46c0914961aaa09c3169138c29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "085e1367ef574fde834e3b3374a3c44b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b7288a520524de08369c8195f551b83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cbd5b04b52240249d575aaabf32325b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f5684552cce4dd7b7347b347dfd9111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea9381ea8cc54a09ba0563329b392f01",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_241b5ac4e4bf4299916008ccd6bacd0d",
      "value": 1648877
     }
    },
    "241b5ac4e4bf4299916008ccd6bacd0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2735329eb8604d3985c1338f15dc1485": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f22e059a79941cd902bc6a8d69e526d",
      "placeholder": "",
      "style": "IPY_MODEL_d4e76e837a67478da414b83715fcec77",
      "value": ""
     }
    },
    "2cdb4e7d07004e52a7eb5aa19bc9b1c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43664a167f1441b5acc49a977ec9f3d8",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bf5e5bac61f4074912e07b8835a9877",
      "value": 9912422
     }
    },
    "3ee9005f19e1487badbca2a0fb56e926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7797b219acb24972bd9d3fc73a5f02eb",
       "IPY_MODEL_caf7c781afb144aea11f55d00803d579",
       "IPY_MODEL_88e6ced06df54b78aa4c640bd166947a"
      ],
      "layout": "IPY_MODEL_97e68bbbded248b4847dd68e671f1639"
     }
    },
    "3f5c2df058ed416aab452a372d86b932": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb4818042a884cd79889ac3bd870d1d9",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c908669a28914cd4b35d533b24b1b609",
      "value": 4542
     }
    },
    "43664a167f1441b5acc49a977ec9f3d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "453e3f74074541a5bf7dd3107126dbdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "468c17e39ec94dad8adf9afdde3d5031": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bf5e5bac61f4074912e07b8835a9877": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c26850f3d224fb6a41bb2a5aab7e6ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c325172ff6c4fa0a3bafb3c88cb30af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2735329eb8604d3985c1338f15dc1485",
       "IPY_MODEL_3f5c2df058ed416aab452a372d86b932",
       "IPY_MODEL_ae07b1b46cad458ebed30f7abfffe81a"
      ],
      "layout": "IPY_MODEL_d879e05d49e04c759891ff856176dbc4"
     }
    },
    "5f2ae79e6e5b4cd7bcd441cb090b304a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "690f7236232647edac94410517b353ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_981e8216f2a642709e891f6c50afa893",
      "placeholder": "",
      "style": "IPY_MODEL_e78c22417bf544d0afd8544588f6e8c8",
      "value": " 1649664/? [00:00&lt;00:00, 15501859.45it/s]"
     }
    },
    "7797b219acb24972bd9d3fc73a5f02eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebeb44ef3da04e879145997deb565194",
      "placeholder": "",
      "style": "IPY_MODEL_0b7288a520524de08369c8195f551b83",
      "value": ""
     }
    },
    "7f22e059a79941cd902bc6a8d69e526d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84875cd4269846eb9c97d5edad9f6e99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f2ae79e6e5b4cd7bcd441cb090b304a",
      "placeholder": "",
      "style": "IPY_MODEL_0729bb3bb62a454e97b022937b43eccd",
      "value": ""
     }
    },
    "86753a841f9e42dc89ba8d92859d694d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "870765b396d846ea88a82b745e150ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88e6ced06df54b78aa4c640bd166947a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f3f030bbbbc497cafeae60a9f15ecf6",
      "placeholder": "",
      "style": "IPY_MODEL_96e083b76fa347bbb31a9deced69217a",
      "value": " 29696/? [00:00&lt;00:00, 534984.63it/s]"
     }
    },
    "96e083b76fa347bbb31a9deced69217a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97e68bbbded248b4847dd68e671f1639": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "981e8216f2a642709e891f6c50afa893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f3f030bbbbc497cafeae60a9f15ecf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae07b1b46cad458ebed30f7abfffe81a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_059f8d94a03b45f4a40821f86a5e4c9f",
      "placeholder": "",
      "style": "IPY_MODEL_453e3f74074541a5bf7dd3107126dbdb",
      "value": " 5120/? [00:00&lt;00:00, 111848.11it/s]"
     }
    },
    "be485c3ab8d34f139f99f2a74ec1d167": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c908669a28914cd4b35d533b24b1b609": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "caf7c781afb144aea11f55d00803d579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be485c3ab8d34f139f99f2a74ec1d167",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_085e1367ef574fde834e3b3374a3c44b",
      "value": 28881
     }
    },
    "cb4818042a884cd79889ac3bd870d1d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4e76e837a67478da414b83715fcec77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d879e05d49e04c759891ff856176dbc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e78c22417bf544d0afd8544588f6e8c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea9381ea8cc54a09ba0563329b392f01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebeb44ef3da04e879145997deb565194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef5a4fdd3b394448ab6c013ee57ef751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_870765b396d846ea88a82b745e150ce8",
      "placeholder": "",
      "style": "IPY_MODEL_4c26850f3d224fb6a41bb2a5aab7e6ab",
      "value": ""
     }
    },
    "f1e2253f7ecf402e9b1ebaaeb4ca3e6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84875cd4269846eb9c97d5edad9f6e99",
       "IPY_MODEL_2cdb4e7d07004e52a7eb5aa19bc9b1c0",
       "IPY_MODEL_f81cc9c50ede4eeca01be1485bbf525a"
      ],
      "layout": "IPY_MODEL_07c6ea46c0914961aaa09c3169138c29"
     }
    },
    "f81cc9c50ede4eeca01be1485bbf525a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86753a841f9e42dc89ba8d92859d694d",
      "placeholder": "",
      "style": "IPY_MODEL_1cbd5b04b52240249d575aaabf32325b",
      "value": " 9913344/? [00:00&lt;00:00, 44110400.37it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
